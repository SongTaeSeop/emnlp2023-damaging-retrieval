{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9908fbb",
   "metadata": {},
   "source": [
    "# modeling14-1-sentence-level-classifier-from-scratch\n",
    "- modeling sentence-classifier\n",
    "- sentence-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29855b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac45451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from util import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad256998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoModel, \n",
    "    AutoConfig, \n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments \n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46390c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc62740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71b094",
   "metadata": {},
   "source": [
    "# DataLoader & Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = ['This framework generates embeddings for each input sentence',\n",
    "#     'Sentences are passed as a list of string.',\n",
    "#     'The quick brown fox jumps over the lazy dog.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.encode(sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding.shape)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_exclude_indecisve/sequence_exclude_no_answer_exclude_indecisve_ctx100id_split_train_1.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.open_json(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35bf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequential_data(data):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "        question_ = instance['question']\n",
    "        ctxs_ = instance['ctxs']\n",
    "        em_pattern_ = instance['em_pattern']\n",
    "        id_ = instance['id']\n",
    "\n",
    "        ctx_lst = []\n",
    "        for context in ctxs_:\n",
    "            input_ = 'question: ' + question_ + ', '\\\n",
    "                     ' title: ' + context['title'] + ', '\\\n",
    "                     ' context : ' + context['text']\n",
    "            ctx_lst.append(input_)\n",
    "\n",
    "        template = {\n",
    "            'id' : id_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "            'ctx' : ctx_lst\n",
    "\n",
    "        }\n",
    "        output.append(template)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train_data = prepare_sequential_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(seq_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b299de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(seq_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34b3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pprint(vars(embedding_model))\n",
    "# max_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535cdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'word_embedding_dimension': 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cbcd73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vars(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2418103",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62544896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, instances, model, shuffle = True):\n",
    "#         if shuffle:\n",
    "#             random.shuffle(instances)\n",
    "#         self.instances = instances\n",
    "#         self.model = model\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.instances)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "#         em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "        \n",
    "#         result = {\n",
    "#             'input_embedding' : input_,\n",
    "#             'em_pattern' : em_pattern_\n",
    "#         }\n",
    "\n",
    "#         return result\n",
    "    \n",
    "class SentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, model, shuffle=True):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "        em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "\n",
    "        result = {\n",
    "            'input_embedding': input_,\n",
    "            'em_pattern': em_pattern_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe937256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceClassificationDataset(seq_train_data, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c82794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2656c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sentence_padding(embedding, cur_max_seq, device):\n",
    "#     if embedding.shape[0] < cur_max_seq:\n",
    "#         zero_pad = torch.full(size=(cur_max_seq-embedding.shape[0], embedding.shape[1]), fill_value = -100).to(device=device)\n",
    "#         print(f'zero_pad.shape : {zero_pad.shape}')\n",
    "#         return torch.concat([embedding, zero_pad]).to(device=device)\n",
    "#     else:\n",
    "#         return embedding[:cur_max_seq, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13983025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get max number of sentence in a batch\n",
    "# train_lst = []\n",
    "# label_lst = []\n",
    "# max_seq_lst = []\n",
    "# for i in range(0, batch_size):\n",
    "#     train_lst.append(train_dataset[i]['input_embedding'])\n",
    "#     label = train_dataset[i]['em_pattern']\n",
    "#     label_lst.append(label)\n",
    "#     max_seq_lst.append(label.shape[0])\n",
    "# max_seq_len = max(max_seq_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09333c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lst = [d['input_embedding'] for d in batch]\n",
    "# label_lst = [d['em_pattern'] for d in batch]\n",
    "# max_seq_lst = max([d['em_pattern'].shape[0] for d in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max_seq_lst)\n",
    "# print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cac904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_lst:\n",
    "#     print(type(i))\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c385017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_train_lst = []\n",
    "# for embedding in train_lst:\n",
    "#     if embedding.shape[0] < max_seq_len:\n",
    "#         post_pad = torch.full(size=(max_seq_len-embedding.shape[0], embedding.shape[1]), fill_value = -100)\n",
    "#         padding_train_lst.append(torch.concat([embedding, post_pad]))\n",
    "#     else:\n",
    "#         padding_train_lst.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ = torch.stack(padding_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51308bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a97901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_[3,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padding_train_lst[3].shape)\n",
    "# print(padding_train_lst[3][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97880c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_label_lst = []\n",
    "# for label in label_lst:\n",
    "#     if label.shape[0] < max_seq_len:\n",
    "#         post_pad = torch.full(size=(max_seq_len-label.shape[0], ), fill_value = -100)\n",
    "#         torch.concat([label, post_pad])\n",
    "#         padding_label_lst.append(torch.concat([label, post_pad]))\n",
    "#     else:\n",
    "#         padding_label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padding_label_lst[4].shape)\n",
    "# print(padding_label_lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67064cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_ = torch.stack(padding_label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce39717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    train_lst = [b['input_embedding'] for b in batch]\n",
    "    label_lst = [b['em_pattern'] for b in batch]\n",
    "    seq_len_lst = [b['em_pattern'].shape[0] for b in batch]\n",
    "    max_seq_len = max(seq_len_lst)\n",
    "    \n",
    "    padding_train_lst = []\n",
    "    for embedding in train_lst:\n",
    "        if embedding.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len-embedding.shape[0], embedding.shape[1]), fill_value = -100)\n",
    "            padding_train_lst.append(torch.concat([embedding, post_pad]))\n",
    "        else:\n",
    "            padding_train_lst.append(embedding)\n",
    "            \n",
    "    inputs = torch.stack(padding_train_lst)\n",
    "    \n",
    "    padding_label_lst = []\n",
    "    for label in label_lst:\n",
    "        if label.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len-label.shape[0], ), fill_value = -100)\n",
    "            torch.concat([label, post_pad])\n",
    "            padding_label_lst.append(torch.concat([label, post_pad]))\n",
    "        else:\n",
    "            padding_label_lst.append(label)\n",
    "            \n",
    "    labels = torch.stack(padding_label_lst)\n",
    "    \n",
    "    return {\n",
    "        'inputs' : inputs,\n",
    "        'labels' : labels,\n",
    "        'sequence_len' : torch.tensor(seq_len_lst)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b78465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                  shuffle=False,\n",
    "                                  collate_fn=custom_collate,\n",
    "                                  batch_size=batch_size,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch1 = next(train_iter)\n",
    "# print(batch1['inputs'].shape)\n",
    "# print(batch1['labels'].shape)\n",
    "# print(batch1['sequence_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = batch1['inputs']\n",
    "# y = batch1['labels']\n",
    "# seq_len = batch1['sequence_len']\n",
    "# print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214622ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(seq_len.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977749f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch1['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch1['inputs'][3][-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc79f7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87905c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceLSTM(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_size, num_labels, drop_out_rate):\n",
    "        super(SentenceLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_labels = num_labels\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
    "                            hidden_size=self.embedding_size,\n",
    "                            num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "        # Classifier Layers\n",
    "        self.dropout = nn.Dropout(self.drop_out_rate)\n",
    "        self.dense = nn.Linear(self.embedding_size, self.embedding_size)\n",
    "        self.out_proj = nn.Linear(self.embedding_size, self.num_labels)\n",
    "\n",
    "        # Initializing layers\n",
    "        self.out_proj.apply(self._init_weights)\n",
    "        self.dense.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs, sequence_length_lst):\n",
    "        packed_input = pack_padded_sequence(inputs, sequence_length_lst.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        output_packed, (h, c) = self.lstm(packed_input)\n",
    "\n",
    "        padded_output, lengths = pad_packed_sequence(output_packed, batch_first=True)\n",
    "\n",
    "        # classifier\n",
    "        x = self.dropout(padded_output)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38b3e3",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packed_input = pack_padded_sequence(x, seq_len, batch_first=True, enforce_sorted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # packed_input\n",
    "# packed_input.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038319c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lstm = nn.LSTM(384, 384, batch_first=True)\n",
    "# # test_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch X length X Dimension\n",
    "# output_packed, (h, c) = test_lstm(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch X length X Dimension \n",
    "# padded_output, lengths = pad_packed_sequence(output_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dda648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padded_output.shape, lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_out_rate = 0.2\n",
    "# dropout = nn.Dropout(drop_out_rate)\n",
    "# dense = nn.Linear(384, 384)\n",
    "# out_proj = nn.Linear(384, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = dropout(padded_output)\n",
    "# x = dense(x)\n",
    "# x = torch.tanh(x)\n",
    "# x = dropout(x)\n",
    "# x = out_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83772650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_2(yhat, y, ignore_index=-100):\n",
    "    # Merge batch and sequence dimension into one\n",
    "    y = y.view(-1)\n",
    "    yhat = F.log_softmax(yhat, dim=-1).view(-1, yhat.shape[-1])\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = y != ignore_index\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    y_nonpad = y[nonpad_mask]\n",
    "    yhat_nonpad = yhat[nonpad_mask]\n",
    "    \n",
    "    # Get the model's probability of the correct class\n",
    "    prob = yhat_nonpad[range(yhat_nonpad.shape[0]), y_nonpad]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = (- prob).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96753fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(logits, labels, ignore_index=-100):\n",
    "    # Merge batch and sequence dimension into one\n",
    "    # (Batch, Length, label) -> (Batch x Length, label)\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    # (Batch, Length, label) -> (Batch x Length, label) \n",
    "    logits = F.log_softmax(logits, dim=-1).view(-1, logits.shape[-1])\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = labels != ignore_index\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    labels_nonpad = labels[nonpad_mask]\n",
    "    logits_nonpad = logits[nonpad_mask]\n",
    "    \n",
    "    # Get the model's probability of the correct class\n",
    "    prob = logits_nonpad[range(logits_nonpad.shape[0]), labels_nonpad]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = (- prob).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6914699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a6670",
   "metadata": {},
   "source": [
    "### 1. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e43835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_1 = criterion(x, y)\n",
    "# print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afd207",
   "metadata": {},
   "source": [
    "### 2. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = criterion_2(x, y)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabef11c",
   "metadata": {},
   "source": [
    "### 3. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# loss = criterion(x.view(-1, 2), y.view(-1))\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7066d4e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     outputs = model(batch['inputs'], batch['sequence_len'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.shape)\n",
    "# print(batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.is_cuda)\n",
    "# print(batch['labels'].is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_1 = criterion(outputs, batch['labels'])\n",
    "# print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['labels'].view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.view(-1, outputs.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# loss = criterion(outputs.view(-1, outputs.shape[-1]), batch['labels'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2260e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe91541",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa79933",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2076e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff69ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file_path = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_exclude_indecisve/sequence_exclude_no_answer_exclude_indecisve_ctx100id_split_dev_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = utils.open_json(eval_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b731298",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = utils.prepare_sequential_data(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be26635",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = SentenceClassificationDataset(seq_train_data, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                              shuffle = False,\n",
    "                              collate_fn=custom_collate,\n",
    "                              batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving from cpu to gpu\n",
    "model, eval_dataloader = accelerator.prepare(\n",
    "        model, eval_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da48f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = 0\n",
    "model.eval()\n",
    "samples_seen = 0\n",
    "prediction_lst = []\n",
    "reference_lst = []\n",
    "\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch['inputs'], batch['sequence_len'])\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda()\n",
    "        eval_loss = criterion(logits.view(-1, 2), batch['labels'].view(-1))\n",
    "    \n",
    "    eval_loss += eval_loss.detach().float()\n",
    "    \n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    references = batch['labels']\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = references != -100\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    references = references[nonpad_mask]\n",
    "    predictions = predictions[nonpad_mask]\n",
    "    \n",
    "    predictions, references = accelerator.gather((predictions, references))\n",
    "    # If we are in a multiprocess environment, the last batch has duplicates\n",
    "    if accelerator.num_processes > 1:\n",
    "        if step == len(eval_dataloader) - 1:\n",
    "            predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "        else:\n",
    "            samples_seen += references.shape[0]\n",
    "            \n",
    "    metric_acc.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "    metric_pre.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_re.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_f1.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    eval_progress_bar.update(1)\n",
    "    prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "    reference_lst.extend(references.detach().cpu().tolist())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric_acc.compute()\n",
    "eval_metric_pre = metric_pre.compute()\n",
    "eval_metric_re = metric_re.compute()\n",
    "eval_metric_f1 = metric_f1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_metric)\n",
    "print(eval_metric_pre)\n",
    "print(eval_metric_re)\n",
    "print(eval_metric_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de222bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a392da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e64df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ce9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra\n",
    "prediction_np = np.array(prediction_lst)\n",
    "reference_np = np.array(reference_lst)\n",
    "y_actu = pd.Series(reference_np, name='Actual')\n",
    "y_pred = pd.Series(prediction_np, name='Predicted')\n",
    "\n",
    "reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "rev_accuracy = accuracy_score(reversey_actu, reversey_pred)\n",
    "rev_precision = precision_score(reversey_actu, reversey_pred)\n",
    "rev_recall = recall_score(reversey_actu, reversey_pred)\n",
    "rev_f1 = f1_score(reversey_actu, reversey_pred)\n",
    "\n",
    "# logger.info(f\"rev Evaluation at Epoch : {epoch} Total Step : {steps}\")\n",
    "# logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "# logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "# logger.info(f\"Epoch : {epoch} Step : {steps}\")\n",
    "# logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "result_rev_log = {\n",
    "    \"eval_rev_accuracy\": rev_accuracy,\n",
    "    \"eval_rev_precision\": rev_precision,\n",
    "    \"eval_rev_recall\": rev_recall,\n",
    "    \"eval_rev_f1\": rev_f1,\n",
    "    \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "#     \"epoch\": epoch,\n",
    "#     \"step\": steps,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43681108",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result_rev_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4a3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bff254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b883c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(references.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc459de",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = references.view(-1)\n",
    "predictions = predictions.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eef576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30070a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpad_mask = references != -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nonpad_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24726579",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = references[nonpad_mask]\n",
    "predictions = predictions[nonpad_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b002201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(batch['sequence_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2385b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeec9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad8740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
