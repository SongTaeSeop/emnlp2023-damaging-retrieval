{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9908fbb",
   "metadata": {},
   "source": [
    "# modeling14-3-FiD-encoder-sentence-level-classifier-saving-mean-pooling-embedding\n",
    "- modeling sentence-classifier\n",
    "- sentence-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29855b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac45451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from util import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad256998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoModel, \n",
    "    AutoConfig, \n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments \n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from FiD.src.model import FiDT5\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from src.data import BinaryCustomDatasetShuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46390c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b71b094",
   "metadata": {},
   "source": [
    "## Get FiD Encoder Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3411ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_file = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_partial_decisive/sequence_exclude_no_answer_partial_decisive_ctx100id_split_train_1.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = utils.open_json(testing_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ffa9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c40eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequential_decisive_data(data):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "        question_ = instance['question']\n",
    "        decisive_ctxs_ = instance['decisive_ctxs']\n",
    "        decisive_em_pattern_ = instance['decisive_em_pattern']\n",
    "        id_ = instance['id']\n",
    "\n",
    "        ctx_lst = []\n",
    "        for decisive_ctxs in decisive_ctxs_:\n",
    "            input_ = 'question: ' + question_ + ', '\\\n",
    "                     ' title: ' + decisive_ctxs['title'] + ', '\\\n",
    "                     ' context : ' + decisive_ctxs['text']\n",
    "            ctx_lst.append(input_)\n",
    "\n",
    "        template = {\n",
    "            'id' : id_,\n",
    "            'em_pattern' : decisive_em_pattern_,\n",
    "            'ctx' : ctx_lst\n",
    "\n",
    "        }\n",
    "        output.append(template)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequential_data(data):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "        question_ = instance['question']\n",
    "        ctxs_ = instance['ctxs']\n",
    "        em_pattern_ = instance['em_pattern']\n",
    "        id_ = instance['id']\n",
    "\n",
    "        ctx_lst = []\n",
    "        for context in ctxs_:\n",
    "            input_ = 'question: ' + question_ + ', '\\\n",
    "                     ' title: ' + context['title'] + ', '\\\n",
    "                     ' context : ' + context['text']\n",
    "            ctx_lst.append(input_)\n",
    "\n",
    "        template = {\n",
    "            'id' : id_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "            'ctx' : ctx_lst\n",
    "\n",
    "        }\n",
    "        output.append(template)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'decisive' in testing_file:\n",
    "    print('decisive')\n",
    "    seq_train_data = utils.prepare_sequential_decisive_data(testing_data)\n",
    "else:\n",
    "    print('not decisive')\n",
    "    seq_train_data = utils.prepare_sequential_data(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_train_data = prepare_sequential_data(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb10fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "model_name_or_path = '/data/philhoon-relevance/FiD/pretrained_models/nq_reader_large'\n",
    "max_seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea67cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
    "embedding_model = FiDT5.from_pretrained(model_name_or_path)\n",
    "fid_encoder = embedding_model.encoder.encoder\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63477452",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(seq_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd972473",
   "metadata": {},
   "source": [
    "======================== Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(seq_train_data[1].keys())\n",
    "# print(len(seq_train_data[1]['ctx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\n",
    "            seq_train_data[0]['ctx'],\n",
    "            return_tensors=\"pt\", \n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b832be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['input_ids'].shape)\n",
    "print(output['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78add05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = fid_encoder(output['input_ids'], output['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632779bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = output['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ef56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = embedding.last_hidden_state\n",
    "print(token_embeddings.shape)\n",
    "print(attention_mask.shape)\n",
    "print(attention_mask.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_mask_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a976c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cafc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mask = input_mask_expanded.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb46605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mask = torch.clamp(sum_mask, min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = pooled = sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e958422",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "sum_mask = input_mask_expanded.sum(1)\n",
    "sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "pooled = sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154c04f",
   "metadata": {},
   "source": [
    "======================== Testing End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_encoder.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e186584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_encoder.eval()\n",
    "new_instance = []\n",
    "for instance in tqdm(seq_train_data):\n",
    "    input_ = tokenizer(instance['ctx'],\n",
    "                       return_tensors=\"pt\",\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       add_special_tokens=True,\n",
    "                       max_length=max_seq_length)\n",
    "    \n",
    "    input_ids = input_['input_ids'].to(device)\n",
    "    attention_mask = input_['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding = fid_encoder(input_ids, attention_mask)\n",
    "        token_embeddings = embedding.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_pooled = sum_embeddings / sum_mask\n",
    "\n",
    "    mean_pooled_cpu = mean_pooled.detach().cpu()\n",
    "    em_pattern_ = torch.tensor([int(i) for i in instance['em_pattern']])\n",
    "\n",
    "    result = {\n",
    "        'input_embedding': mean_pooled_cpu,\n",
    "        'em_pattern': em_pattern_\n",
    "    }\n",
    "    new_instance.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa6494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(new_instance[i]['input_embedding'].shape)\n",
    "print(new_instance[i]['em_pattern'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ab698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_exclude_indecisve/testing-sequence_exclude_no_answer_exclude_indecisve_ctx100id_split_train_1.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(new_instance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b170671",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1fc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcaf807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, model, tokenizer, shuffle=True):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = self.tokenizer(self.instances[idx]['ctx'], \n",
    "                               return_tensors=\"pt\", \n",
    "                               padding=True,\n",
    "                               truncation=True,\n",
    "                               add_special_tokens=True,\n",
    "                               max_length=max_seq_length)\n",
    "        attention_mask = input_['attention_mask']\n",
    "        embedding = self.model(input_['input_ids'], attention_mask)\n",
    "        mean_pooled = embedding.last_hidden_state.sum(axis = -1) / attention_mask.sum(axis=-1).unsqueeze(-1)\n",
    "        \n",
    "        em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "\n",
    "        result = {\n",
    "            'input_embedding': mean_pooled,\n",
    "            'em_pattern': em_pattern_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = EncoderSentenceClassificationDataset(seq_train_data, fid_encoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde34168",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seq_train_data[i]['ctx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = testing_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data['input_embedding'].shape)\n",
    "print(test_data['em_pattern'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6b418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9c222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218dfa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98684a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55b26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edcc5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade839f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f3936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab22ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b475cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac6dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d83110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19778e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6163e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c19bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793f330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BinaryCustomDatasetShuffle\n",
    "#         output = self.tokenizer(\n",
    "#             input_,\n",
    "#             # return_tensors=\"pt\", will be applied later through collator\n",
    "#             # padding=True, will be padded later through collate\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length)\n",
    "\n",
    "testing_dataset = BinaryCustomDatasetShuffle(testing_data, tokenizer=tokenizer,\n",
    "                                 max_length=max_seq_length, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fde435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataloader = DataLoader(testing_dataset,\n",
    "                                  shuffle=False,\n",
    "                                  collate_fn=data_collator,\n",
    "                                  batch_size=2,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204819a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = iter(testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699383cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_input = next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testing_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d58b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "model_name_or_path = '/data/philhoon-relevance/FiD/pretrained_models/nq_reader_large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
    "model_class = FiDT5\n",
    "embedding_model = model_class.from_pretrained(model_name_or_path)\n",
    "fid_encoder = embedding_model.encoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6834266",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = fid_encoder(testing_input['input_ids'], testing_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999571ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86172b",
   "metadata": {},
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0078f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(vars(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c5e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b4517c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a2fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94889a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a10a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d300a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e7e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12d3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c302cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9abf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588f52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae0f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc34da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = ['This framework generates embeddings for each input sentence',\n",
    "#     'Sentences are passed as a list of string.',\n",
    "#     'The quick brown fox jumps over the lazy dog.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = sentence_model.encode(sentences, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence, embedding in zip(sentences, embeddings):\n",
    "#     print(\"Sentence:\", sentence)\n",
    "#     print(\"Embedding:\", embedding.shape)\n",
    "#     print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_exclude_indecisve/sequence_exclude_no_answer_exclude_indecisve_ctx100id_split_train_1.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.open_json(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35bf7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequential_data(data):\n",
    "    output = []\n",
    "    for instance in data:\n",
    "        question_ = instance['question']\n",
    "        ctxs_ = instance['ctxs']\n",
    "        em_pattern_ = instance['em_pattern']\n",
    "        id_ = instance['id']\n",
    "\n",
    "        ctx_lst = []\n",
    "        for context in ctxs_:\n",
    "            input_ = 'question: ' + question_ + ', '\\\n",
    "                     ' title: ' + context['title'] + ', '\\\n",
    "                     ' context : ' + context['text']\n",
    "            ctx_lst.append(input_)\n",
    "\n",
    "        template = {\n",
    "            'id' : id_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "            'ctx' : ctx_lst\n",
    "\n",
    "        }\n",
    "        output.append(template)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train_data = prepare_sequential_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(seq_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b299de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(seq_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34b3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pprint(vars(embedding_model))\n",
    "# max_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'word_embedding_dimension': 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cbcd73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vars(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8504513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = '/data/philhoon-relevance/FiD/pretrained_models/nq_reader_large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58313caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c48a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52df145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = FiDT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = model_class.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_encoder = embedding_model.encoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(['hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5bdcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fid_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e426c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.convert_ids_to_tokens(inputs['input_ids'], batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_train_data[0]['em_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b370e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = seq_train_data[0]['ctx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a699fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65283a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.keys("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {key: val for key, val in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617353d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output['input_ids']))\n",
    "print(len(output['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a80b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._pad_token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6695daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(vars(tokenizer.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427275e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model(**item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ac379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a464f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3af367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab179773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderSentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, model, tokenizer,shuffle=True):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.instances = instances\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        output = self.tokenizer(self.instances[idx]['ctx'], \n",
    "                                truncation=True, \n",
    "                                padding=True,\n",
    "                                add_special_tokens=True, \n",
    "                                max_length = self.max_seq_length)\n",
    "        \n",
    "#         input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "#         em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "\n",
    "        result = {\n",
    "            'input_embedding': input_,\n",
    "            'em_pattern': em_pattern_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d572937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCustomDatasetPredictionShuffle(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, tokenizer, max_length, shuffle = False):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = 'question: ' + self.instances[idx]['question'] + ', '\\\n",
    "                 ' title: ' + self.instances[idx]['ctx']['title'] + ', '\\\n",
    "                 ' context : ' + self.instances[idx]['ctx']['text']\n",
    "        output = self.tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length)\n",
    "\n",
    "        item = {key: val for key, val in output.items()}\n",
    "        # item['labels'] = torch.tensor(int(self.instances[idx]['em']))\n",
    "        item['labels'] = torch.tensor(int(self.instances[idx]['binary_inference']))\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d3390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e232c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, model, shuffle=True):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "        em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "\n",
    "        result = {\n",
    "            'input_embedding': input_,\n",
    "            'em_pattern': em_pattern_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07802820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea98b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb491afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8f959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e24b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78512287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da801d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62544896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, instances, model, shuffle = True):\n",
    "#         if shuffle:\n",
    "#             random.shuffle(instances)\n",
    "#         self.instances = instances\n",
    "#         self.model = model\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.instances)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "#         em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "        \n",
    "#         result = {\n",
    "#             'input_embedding' : input_,\n",
    "#             'em_pattern' : em_pattern_\n",
    "#         }\n",
    "\n",
    "#         return result\n",
    "    \n",
    "class SentenceClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, model, shuffle=True):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = torch.from_numpy(self.model.encode(self.instances[idx]['ctx'], show_progress_bar=False))\n",
    "        em_pattern_ = torch.tensor([int(i) for i in self.instances[idx]['em_pattern']])\n",
    "\n",
    "        result = {\n",
    "            'input_embedding': input_,\n",
    "            'em_pattern': em_pattern_\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe937256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceClassificationDataset(seq_train_data, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c82794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2656c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sentence_padding(embedding, cur_max_seq, device):\n",
    "#     if embedding.shape[0] < cur_max_seq:\n",
    "#         zero_pad = torch.full(size=(cur_max_seq-embedding.shape[0], embedding.shape[1]), fill_value = -100).to(device=device)\n",
    "#         print(f'zero_pad.shape : {zero_pad.shape}')\n",
    "#         return torch.concat([embedding, zero_pad]).to(device=device)\n",
    "#     else:\n",
    "#         return embedding[:cur_max_seq, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13983025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get max number of sentence in a batch\n",
    "# train_lst = []\n",
    "# label_lst = []\n",
    "# max_seq_lst = []\n",
    "# for i in range(0, batch_size):\n",
    "#     train_lst.append(train_dataset[i]['input_embedding'])\n",
    "#     label = train_dataset[i]['em_pattern']\n",
    "#     label_lst.append(label)\n",
    "#     max_seq_lst.append(label.shape[0])\n",
    "# max_seq_len = max(max_seq_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09333c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lst = [d['input_embedding'] for d in batch]\n",
    "# label_lst = [d['em_pattern'] for d in batch]\n",
    "# max_seq_lst = max([d['em_pattern'].shape[0] for d in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max_seq_lst)\n",
    "# print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cac904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_lst:\n",
    "#     print(type(i))\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c385017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_train_lst = []\n",
    "# for embedding in train_lst:\n",
    "#     if embedding.shape[0] < max_seq_len:\n",
    "#         post_pad = torch.full(size=(max_seq_len-embedding.shape[0], embedding.shape[1]), fill_value = -100)\n",
    "#         padding_train_lst.append(torch.concat([embedding, post_pad]))\n",
    "#     else:\n",
    "#         padding_train_lst.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7058aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ = torch.stack(padding_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51308bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a97901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_[3,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padding_train_lst[3].shape)\n",
    "# print(padding_train_lst[3][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97880c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding_label_lst = []\n",
    "# for label in label_lst:\n",
    "#     if label.shape[0] < max_seq_len:\n",
    "#         post_pad = torch.full(size=(max_seq_len-label.shape[0], ), fill_value = -100)\n",
    "#         torch.concat([label, post_pad])\n",
    "#         padding_label_lst.append(torch.concat([label, post_pad]))\n",
    "#     else:\n",
    "#         padding_label_lst.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padding_label_lst[4].shape)\n",
    "# print(padding_label_lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67064cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_ = torch.stack(padding_label_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce39717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    train_lst = [b['input_embedding'] for b in batch]\n",
    "    label_lst = [b['em_pattern'] for b in batch]\n",
    "    seq_len_lst = [b['em_pattern'].shape[0] for b in batch]\n",
    "    max_seq_len = max(seq_len_lst)\n",
    "    \n",
    "    padding_train_lst = []\n",
    "    for embedding in train_lst:\n",
    "        if embedding.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len-embedding.shape[0], embedding.shape[1]), fill_value = -100)\n",
    "            padding_train_lst.append(torch.concat([embedding, post_pad]))\n",
    "        else:\n",
    "            padding_train_lst.append(embedding)\n",
    "            \n",
    "    inputs = torch.stack(padding_train_lst)\n",
    "    \n",
    "    padding_label_lst = []\n",
    "    for label in label_lst:\n",
    "        if label.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len-label.shape[0], ), fill_value = -100)\n",
    "            torch.concat([label, post_pad])\n",
    "            padding_label_lst.append(torch.concat([label, post_pad]))\n",
    "        else:\n",
    "            padding_label_lst.append(label)\n",
    "            \n",
    "    labels = torch.stack(padding_label_lst)\n",
    "    \n",
    "    return {\n",
    "        'inputs' : inputs,\n",
    "        'labels' : labels,\n",
    "        'sequence_len' : torch.tensor(seq_len_lst)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b78465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                  shuffle=False,\n",
    "                                  collate_fn=custom_collate,\n",
    "                                  batch_size=batch_size,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da5684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch1 = next(train_iter)\n",
    "# print(batch1['inputs'].shape)\n",
    "# print(batch1['labels'].shape)\n",
    "# print(batch1['sequence_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = batch1['inputs']\n",
    "# y = batch1['labels']\n",
    "# seq_len = batch1['sequence_len']\n",
    "# print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214622ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(seq_len.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977749f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch1['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch1['inputs'][3][-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc79f7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87905c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceLSTM(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_size, num_labels, drop_out_rate):\n",
    "        super(SentenceLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_labels = num_labels\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
    "                            hidden_size=self.embedding_size,\n",
    "                            num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "        # Classifier Layers\n",
    "        self.dropout = nn.Dropout(self.drop_out_rate)\n",
    "        self.dense = nn.Linear(self.embedding_size, self.embedding_size)\n",
    "        self.out_proj = nn.Linear(self.embedding_size, self.num_labels)\n",
    "\n",
    "        # Initializing layers\n",
    "        self.out_proj.apply(self._init_weights)\n",
    "        self.dense.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs, sequence_length_lst):\n",
    "        packed_input = pack_padded_sequence(inputs, sequence_length_lst.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        output_packed, (h, c) = self.lstm(packed_input)\n",
    "\n",
    "        padded_output, lengths = pad_packed_sequence(output_packed, batch_first=True)\n",
    "\n",
    "        # classifier\n",
    "        x = self.dropout(padded_output)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38b3e3",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packed_input = pack_padded_sequence(x, seq_len, batch_first=True, enforce_sorted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc3cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # packed_input\n",
    "# packed_input.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038319c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lstm = nn.LSTM(384, 384, batch_first=True)\n",
    "# # test_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch X length X Dimension\n",
    "# output_packed, (h, c) = test_lstm(packed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch X length X Dimension \n",
    "# padded_output, lengths = pad_packed_sequence(output_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dda648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(padded_output.shape, lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_out_rate = 0.2\n",
    "# dropout = nn.Dropout(drop_out_rate)\n",
    "# dense = nn.Linear(384, 384)\n",
    "# out_proj = nn.Linear(384, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = dropout(padded_output)\n",
    "# x = dense(x)\n",
    "# x = torch.tanh(x)\n",
    "# x = dropout(x)\n",
    "# x = out_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83772650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_2(yhat, y, ignore_index=-100):\n",
    "    # Merge batch and sequence dimension into one\n",
    "    y = y.view(-1)\n",
    "    yhat = F.log_softmax(yhat, dim=-1).view(-1, yhat.shape[-1])\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = y != ignore_index\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    y_nonpad = y[nonpad_mask]\n",
    "    yhat_nonpad = yhat[nonpad_mask]\n",
    "    \n",
    "    # Get the model's probability of the correct class\n",
    "    prob = yhat_nonpad[range(yhat_nonpad.shape[0]), y_nonpad]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = (- prob).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96753fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(logits, labels, ignore_index=-100):\n",
    "    # Merge batch and sequence dimension into one\n",
    "    # (Batch, Length, label) -> (Batch x Length, label)\n",
    "    labels = labels.view(-1)\n",
    "    \n",
    "    # (Batch, Length, label) -> (Batch x Length, label) \n",
    "    logits = F.log_softmax(logits, dim=-1).view(-1, logits.shape[-1])\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = labels != ignore_index\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    labels_nonpad = labels[nonpad_mask]\n",
    "    logits_nonpad = logits[nonpad_mask]\n",
    "    \n",
    "    # Get the model's probability of the correct class\n",
    "    prob = logits_nonpad[range(logits_nonpad.shape[0]), labels_nonpad]\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = (- prob).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6914699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a6670",
   "metadata": {},
   "source": [
    "### 1. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e43835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_1 = criterion(x, y)\n",
    "# print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afd207",
   "metadata": {},
   "source": [
    "### 2. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = criterion_2(x, y)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabef11c",
   "metadata": {},
   "source": [
    "### 3. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# loss = criterion(x.view(-1, 2), y.view(-1))\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7066d4e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     outputs = model(batch['inputs'], batch['sequence_len'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.shape)\n",
    "# print(batch['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs.is_cuda)\n",
    "# print(batch['labels'].is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_1 = criterion(outputs, batch['labels'])\n",
    "# print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['labels'].view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.view(-1, outputs.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "# loss = criterion(outputs.view(-1, outputs.shape[-1]), batch['labels'].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2260e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe91541",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa79933",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2076e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceLSTM(num_layers=2, embedding_size=384, num_labels=2, drop_out_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff69ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file_path = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/sequence_exclude_no_answer_exclude_indecisve/sequence_exclude_no_answer_exclude_indecisve_ctx100id_split_dev_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = utils.open_json(eval_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b731298",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = utils.prepare_sequential_data(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be26635",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = SentenceClassificationDataset(seq_train_data, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                              shuffle = False,\n",
    "                              collate_fn=custom_collate,\n",
    "                              batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving from cpu to gpu\n",
    "model, eval_dataloader = accelerator.prepare(\n",
    "        model, eval_dataloader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da48f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = 0\n",
    "model.eval()\n",
    "samples_seen = 0\n",
    "prediction_lst = []\n",
    "reference_lst = []\n",
    "\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch['inputs'], batch['sequence_len'])\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda()\n",
    "        eval_loss = criterion(logits.view(-1, 2), batch['labels'].view(-1))\n",
    "    \n",
    "    eval_loss += eval_loss.detach().float()\n",
    "    \n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    references = batch['labels']\n",
    "    \n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = references != -100\n",
    "    \n",
    "    # Slice out non-pad values\n",
    "    references = references[nonpad_mask]\n",
    "    predictions = predictions[nonpad_mask]\n",
    "    \n",
    "    predictions, references = accelerator.gather((predictions, references))\n",
    "    # If we are in a multiprocess environment, the last batch has duplicates\n",
    "    if accelerator.num_processes > 1:\n",
    "        if step == len(eval_dataloader) - 1:\n",
    "            predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "        else:\n",
    "            samples_seen += references.shape[0]\n",
    "            \n",
    "    metric_acc.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "    metric_pre.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_re.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_f1.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    eval_progress_bar.update(1)\n",
    "    prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "    reference_lst.extend(references.detach().cpu().tolist())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric_acc.compute()\n",
    "eval_metric_pre = metric_pre.compute()\n",
    "eval_metric_re = metric_re.compute()\n",
    "eval_metric_f1 = metric_f1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_metric)\n",
    "print(eval_metric_pre)\n",
    "print(eval_metric_re)\n",
    "print(eval_metric_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de222bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a392da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e64df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ce9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra\n",
    "prediction_np = np.array(prediction_lst)\n",
    "reference_np = np.array(reference_lst)\n",
    "y_actu = pd.Series(reference_np, name='Actual')\n",
    "y_pred = pd.Series(prediction_np, name='Predicted')\n",
    "\n",
    "reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "rev_accuracy = accuracy_score(reversey_actu, reversey_pred)\n",
    "rev_precision = precision_score(reversey_actu, reversey_pred)\n",
    "rev_recall = recall_score(reversey_actu, reversey_pred)\n",
    "rev_f1 = f1_score(reversey_actu, reversey_pred)\n",
    "\n",
    "# logger.info(f\"rev Evaluation at Epoch : {epoch} Total Step : {steps}\")\n",
    "# logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "# logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "# logger.info(f\"Epoch : {epoch} Step : {steps}\")\n",
    "# logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "result_rev_log = {\n",
    "    \"eval_rev_accuracy\": rev_accuracy,\n",
    "    \"eval_rev_precision\": rev_precision,\n",
    "    \"eval_rev_recall\": rev_recall,\n",
    "    \"eval_rev_f1\": rev_f1,\n",
    "    \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "#     \"epoch\": epoch,\n",
    "#     \"step\": steps,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43681108",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result_rev_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4a3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bff254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b883c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(references.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc459de",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = references.view(-1)\n",
    "predictions = predictions.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eef576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30070a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpad_mask = references != -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nonpad_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24726579",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = references[nonpad_mask]\n",
    "predictions = predictions[nonpad_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1373e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(references.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b002201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(batch['sequence_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2385b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeec9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad8740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
