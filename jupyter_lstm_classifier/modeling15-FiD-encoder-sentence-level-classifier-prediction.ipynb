{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9908fbb",
   "metadata": {},
   "source": [
    "# modeling15-FiD-encoder-sentence-level-classifier-prediction\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dce998",
   "metadata": {},
   "source": [
    "## CHECKING PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ac701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b63ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dfdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "import heapq\n",
    "import pickle\n",
    "import pathlib\n",
    "import shutil\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "from src.data import (\n",
    "    BinaryCustomDatasetShuffle,\n",
    "    BinarySentenceDataset,\n",
    "    BinaryCustomDatasetDecisiveBinaryGold,\n",
    "    BinaryCustomDatasetPredictionShuffle,\n",
    "    SentenceClassificationDataset,\n",
    "    EncoderSentenceClassificationDataset\n",
    ")\n",
    "\n",
    "import re\n",
    "from functools import partial\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "import argparse\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments, CustomTrainingArguments\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FiD.src.model import FiDT5\n",
    "from src.model import SentenceLSTM\n",
    "\n",
    "NEW_LINE = \"\\n\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "DATASET_MAPPING = {\n",
    "    \"BinaryCustomDatasetShuffle\" : BinaryCustomDatasetShuffle,\n",
    "    \"BinarySentenceDataset\" : BinarySentenceDataset,\n",
    "    'BinaryCustomDatasetDecisiveBinaryGold' : BinaryCustomDatasetDecisiveBinaryGold,\n",
    "    'BinaryCustomDatasetPredictionShuffle' : BinaryCustomDatasetPredictionShuffle,\n",
    "    'SentenceClassificationDataset' : SentenceClassificationDataset,\n",
    "    'EncoderSentenceClassificationDataset' : EncoderSentenceClassificationDataset\n",
    "}\n",
    "EMBEDDING_ARC_MAPPING = {\n",
    "    \"SentenceTransformer\" : SentenceTransformer,\n",
    "     \"FiDT5\" : FiDT5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9e159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch, padding):\n",
    "    train_lst = [b['input_embedding'] for b in batch]\n",
    "    label_lst = [b['em_pattern'] for b in batch]\n",
    "    seq_len_lst = [b['em_pattern'].shape[0] for b in batch]\n",
    "    max_seq_len = max(seq_len_lst)\n",
    "\n",
    "    padding_train_lst = []\n",
    "    for embedding in train_lst:\n",
    "        if embedding.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len - embedding.shape[0], embedding.shape[1]), fill_value=padding)\n",
    "            # post_pad = torch.full(size=(max_seq_len - embedding.shape[0], embedding.shape[1]), fill_value=-100)\n",
    "            padding_train_lst.append(torch.concat([embedding, post_pad]))\n",
    "        else:\n",
    "            padding_train_lst.append(embedding)\n",
    "\n",
    "    inputs = torch.stack(padding_train_lst)\n",
    "\n",
    "    padding_label_lst = []\n",
    "    for label in label_lst:\n",
    "        if label.shape[0] < max_seq_len:\n",
    "            post_pad = torch.full(size=(max_seq_len - label.shape[0],), fill_value=padding)\n",
    "            # post_pad = torch.full(size=(max_seq_len - label.shape[0],), fill_value=-100)\n",
    "            torch.concat([label, post_pad])\n",
    "            padding_label_lst.append(torch.concat([label, post_pad]))\n",
    "        else:\n",
    "            padding_label_lst.append(label)\n",
    "\n",
    "    labels = torch.stack(padding_label_lst)\n",
    "\n",
    "    return {\n",
    "        'inputs': inputs,\n",
    "        'labels': labels,\n",
    "        'sequence_len': torch.tensor(seq_len_lst)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7a415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = HfArgumentParser((ModelArguments, DataTrainingArguments, CustomTrainingArguments))\n",
    "\n",
    "# model_args, data_args, train_args = parser.parse_args_into_dataclasses([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17e3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2085b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c23199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict = vars(train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d3d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa08fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='sentence_encoder_predict')\n",
    "\n",
    "parser.add_argument('--config_path', default='/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive' ,type=str)\n",
    "parser.add_argument('--model_path', default='step_2160', type=str)\n",
    "parser.add_argument('--eval_file', default='/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.pickle', type=str)\n",
    "parser.add_argument('--original_eval_file', default='/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.json', type=str)\n",
    "parser.add_argument('--per_device_eval_batch_size', default=32, type=int)\n",
    "# parser.add_argument('--model_name_or_path', type=str, required=True)\n",
    "\n",
    "\n",
    "# eval_file = '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.pickle'\n",
    "\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1396410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive\n",
      "step_2160\n",
      "/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.pickle\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(args.config_path)\n",
    "print(args.model_path)\n",
    "print(args.eval_file)\n",
    "print(args.per_device_eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ed75",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687c9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_include_all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa74a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args_path = os.path.join(args.config_path, 'data_args.json')\n",
    "model_args_path = os.path.join(args.config_path, 'model_args.json')\n",
    "train_args_path = os.path.join(args.config_path, 'train_args.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fd3f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = utils.open_json(data_args_path)\n",
    "model_args = utils.open_json(model_args_path)\n",
    "train_args = utils.open_json(train_args_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7466dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba27606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e47897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc33a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_args['num_layers'])\n",
    "# print(model_args['embedding'])\n",
    "# print(data_args['num_labels'])\n",
    "# print(train_args['drop_out_rate'])\n",
    "# print(train_args['padding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74563a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_layers = train_args['num_layers']\n",
    "args.embedding = model_args['embedding']\n",
    "args.num_labels = data_args['num_labels']\n",
    "args.drop_out_rate = train_args['drop_out_rate']\n",
    "args.padding = train_args['padding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6772b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "1024\n",
      "2\n",
      "0.2\n",
      "-100\n"
     ]
    }
   ],
   "source": [
    "print(args.num_layers)\n",
    "print(args.embedding)\n",
    "print(args.num_labels)\n",
    "print(args.drop_out_rate)\n",
    "print(args.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be17e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c011c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceLSTM(num_layers = args.num_layers, \n",
    "#                      embedding_size = args.embedding, \n",
    "#                      num_labels = args.num_labels,\n",
    "#                      drop_out_rate = args.drop_out_rate\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad024477",
   "metadata": {},
   "source": [
    "## Loading model from Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03e55b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive/step_2160/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_saved_path = os.path.join(args.config_path, args.model_path, 'pytorch_model.bin')\n",
    "args.model_saved_path = model_saved_path\n",
    "print(args.model_saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c710a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict_ = torch.load(args.model_saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2813dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(state_dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf193db",
   "metadata": {},
   "source": [
    "## Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acdfb7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.pickle\n"
     ]
    }
   ],
   "source": [
    "print(args.eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac661658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(args.eval_file, 'rb') as f:\n",
    "#     eval_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69acae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset = EncoderSentenceClassificationDataset(eval_data, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce104cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataloader = DataLoader(eval_dataset,\n",
    "#                              shuffle=False,\n",
    "#                              collate_fn=partial(custom_collate, padding=args.padding),\n",
    "#                              batch_size=args.per_device_eval_batch_size,\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54562b8b",
   "metadata": {},
   "source": [
    "## Implementation torch script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f4e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f7d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one log on every process with the configuration for debugging.\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43157af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2023 11:22:03 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(accelerator.state, main_process_only=False)\n",
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b136653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive/step_2160/test_prediction\n"
     ]
    }
   ],
   "source": [
    "args.output_dir = os.path.join(args.config_path, args.model_path, 'test_prediction')\n",
    "print(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1078b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process and args.output_dir is not None:\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acc38d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceLSTM(num_layers = args.num_layers, \n",
    "                     embedding_size = args.embedding, \n",
    "                     num_labels = args.num_labels,\n",
    "                     drop_out_rate = args.drop_out_rate\n",
    "                    )\n",
    "\n",
    "state_dict_ = torch.load(args.model_saved_path)\n",
    "model.load_state_dict(state_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "183075ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.eval_file, 'rb') as f:\n",
    "    eval_data = pickle.load(f)\n",
    "\n",
    "eval_dataset = EncoderSentenceClassificationDataset(eval_data, shuffle = False)\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=partial(custom_collate, padding=args.padding),\n",
    "                             batch_size=args.per_device_eval_batch_size,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80e52ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in random.sample(range(len(eval_dataset)), 5):\n",
    "#     logger.info(f\"Sample {index} of the eval set: {eval_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d20f7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare everything with our `accelerator`.\n",
    "model, eval_dataloader = accelerator.prepare(\n",
    "    model, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9f7ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metric function\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1621168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2023 11:22:17 - INFO - __main__ - ***** Running evaluation *****\n",
      "01/10/2023 11:22:17 - INFO - __main__ -   Num examples = 3610\n",
      "01/10/2023 11:22:17 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
      "01/10/2023 11:22:17 - INFO - __main__ -   Steps = 114\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "logger.info(\"***** Running evaluation *****\")\n",
    "logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {args.per_device_eval_batch_size}\")\n",
    "logger.info(f\"  Steps = {math.ceil(len(eval_dataset) / args.per_device_eval_batch_size) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff4fd9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2023 11:22:18 - INFO - __main__ -   Saving training_args = {'config_path': '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive', 'model_path': 'step_2160', 'eval_file': '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.pickle', 'original_eval_file': '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.json', 'per_device_eval_batch_size': 32, 'num_layers': 12, 'embedding': 1024, 'num_labels': 2, 'drop_out_rate': 0.2, 'padding': -100, 'model_saved_path': '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive/step_2160/pytorch_model.bin', 'output_dir': '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive/step_2160/test_prediction'}\n"
     ]
    }
   ],
   "source": [
    "args_dict = vars(args)\n",
    "logger.info(f\"  Saving training_args = {args_dict}\")\n",
    "with open(os.path.join(args.output_dir, \"prediction_args.json\"), \"w\") as f:\n",
    "    json.dump(args_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96d06a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b688500c7f7740e4a409c0b3f35dc4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2946cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = 0\n",
    "model.eval()\n",
    "samples_seen = 0\n",
    "prediction_lst = []\n",
    "reference_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baa2bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch['inputs'], batch['sequence_len'])\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=args.padding).cuda()\n",
    "        loss = criterion(logits.view(-1, logits.shape[-1]), batch['labels'].view(-1))\n",
    "\n",
    "    \n",
    "    eval_loss += loss.detach().float()\n",
    "\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    references = batch['labels']\n",
    "\n",
    "    # Get mask for target values != padding index\n",
    "    nonpad_mask = references != args.padding\n",
    "\n",
    "    # Slice out non-pad values\n",
    "    references = references[nonpad_mask]\n",
    "    predictions = predictions[nonpad_mask]\n",
    "\n",
    "    predictions, references = accelerator.gather((predictions, references))\n",
    "    # If we are in a multiprocess environment, the last batch has duplicates\n",
    "    if accelerator.num_processes > 1:\n",
    "        if step == len(eval_dataloader) - 1:\n",
    "            predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "        else:\n",
    "            samples_seen += references.shape[0]\n",
    "\n",
    "    metric_acc.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_pre.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_re.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_f1.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    eval_progress_bar.update(1)\n",
    "    prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "    reference_lst.extend(references.detach().cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab24da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/10/2023 11:22:34 - INFO - __main__ - Accuracy : 0.48325484764542936 Precision : 0.5339932736848785\n",
      "01/10/2023 11:22:34 - INFO - __main__ - Recall : 0.2192577461412596 F1 : 0.31087156488620116\n",
      "01/10/2023 11:22:34 - INFO - __main__ - Eval_loss : 1.3341707212735066\n",
      "01/10/2023 11:22:34 - INFO - __main__ - rev_Accuracy : 0.48325484764542936 rev_Precision : 0.4690880742722489\n",
      "01/10/2023 11:22:34 - INFO - __main__ - rev_Recall : 0.782853729789826 rev_F1 : 0.5866524264186146\n",
      "01/10/2023 11:22:34 - INFO - __main__ - Eval_loss : 1.3341707212735066\n"
     ]
    }
   ],
   "source": [
    "eval_metric = metric_acc.compute()\n",
    "eval_metric_pre = metric_pre.compute()\n",
    "eval_metric_re = metric_re.compute()\n",
    "eval_metric_f1 = metric_f1.compute()\n",
    "\n",
    "logger.info(f\"Accuracy : {eval_metric['accuracy']} Precision : {eval_metric_pre['precision']}\")\n",
    "logger.info(f\"Recall : {eval_metric_re['recall']} F1 : {eval_metric_f1['f1']}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "result_log = {\n",
    "    \"eval_accuracy\": eval_metric['accuracy'],\n",
    "    \"eval_precision\": eval_metric_pre['precision'],\n",
    "    \"eval_recall\": eval_metric_re['recall'],\n",
    "    \"eval_f1\": eval_metric_f1['f1'],\n",
    "    \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "}\n",
    "\n",
    "output_result_path = os.path.join(args.output_dir, f\"prediction_results.json\")\n",
    "with open(output_result_path, \"w\") as f:\n",
    "    json.dump(result_log, f, indent=4)\n",
    "\n",
    "## Extra\n",
    "prediction_np = np.array(prediction_lst)\n",
    "reference_np = np.array(reference_lst)\n",
    "y_actu = pd.Series(reference_np, name='Actual')\n",
    "y_pred = pd.Series(prediction_np, name='Predicted')\n",
    "\n",
    "reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "rev_accuracy = accuracy_score(reversey_actu, reversey_pred)\n",
    "rev_precision = precision_score(reversey_actu, reversey_pred)\n",
    "rev_recall = recall_score(reversey_actu, reversey_pred)\n",
    "rev_f1 = f1_score(reversey_actu, reversey_pred)\n",
    "\n",
    "logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "result_rev_log = {\n",
    "    \"eval_rev_accuracy\": rev_accuracy,\n",
    "    \"eval_rev_precision\": rev_precision,\n",
    "    \"eval_rev_recall\": rev_recall,\n",
    "    \"eval_rev_f1\": rev_f1,\n",
    "    \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "}\n",
    "\n",
    "output_result_path = os.path.join(args.output_dir, f\"prediction_rev_results.json\")\n",
    "with open(output_result_path, \"w\") as f:\n",
    "    json.dump(result_rev_log, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e79f9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_np = np.array(prediction_lst)\n",
    "reference_np = np.array(reference_lst)\n",
    "\n",
    "prediction_np = prediction_np.reshape((-1,100))\n",
    "reference_np = reference_np.reshape((-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e9111c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction_np.shape)\n",
    "# print(reference_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81e5f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_eval_data = utils.open_json(args.original_eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2aee2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_eval_file[0]['em_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81d16dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.json'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.original_eval_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c62c93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins, p_, r_ in zip(original_eval_data, prediction_np, reference_np):\n",
    "    reference_em = ''.join([str(i) for i in r_.tolist()])\n",
    "    if reference_em != ins['em_pattern']:\n",
    "        logger.info(f\"Reference EM Not Matching Instance EM\")\n",
    "    else:\n",
    "        prediction_em = ''.join([str(i) for i in p_.tolist()])\n",
    "    ins['sentence_inference'] = prediction_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13603a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predcition_output_path = os.path.join(args.output_dir, 'ctx100id_test_prediction.json')\n",
    "with open(predcition_output_path, \"w\") as f:\n",
    "    json.dump(original_eval_data, f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3d075",
   "metadata": {},
   "source": [
    "## ===================================\n",
    "### Testing Decisive Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_eval_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b92777",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_eval_data[0]['conversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definite_pos_neg_2(test_em):\n",
    "    positive_pos = []\n",
    "    negative_pos = []\n",
    "    \n",
    "    # pos\n",
    "    if test_em.startswith('1'):\n",
    "        positive_pos.append(0)\n",
    "    iter_ = re.finditer(r'01', test_em)\n",
    "    for m in iter_:\n",
    "        pos_ = m.start() + 1\n",
    "        positive_pos.append(pos_)\n",
    "        \n",
    "        # extra\n",
    "#         neg_ = m.start()\n",
    "#         negative_pos.append(neg_)\n",
    "        \n",
    "    # neg\n",
    "    iter_ = re.finditer(r'10', test_em)\n",
    "    for m in iter_:\n",
    "        pos_ = m.start() + 1\n",
    "        if pos_ not in negative_pos:\n",
    "            negative_pos.append(pos_)\n",
    "    \n",
    "    return positive_pos, negative_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33103107",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "cnt_ref = 0\n",
    "for ins in original_eval_data:\n",
    "    if ins['em_pattern'] == '0'*100:\n",
    "        cnt += 1\n",
    "    if ins['cumulative_em'] == '1' and ins['sentence_inference'] == '0'*100:\n",
    "        cnt_ref += 1\n",
    "print(cnt)\n",
    "print(cnt_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76580ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8880756",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decisive_ref = []\n",
    "decisive_pred = []\n",
    "for ins in original_eval_data:\n",
    "    positive_pos, negative_pos = get_definite_pos_neg_2(ins['em_pattern'])\n",
    "    decisive_merge = positive_pos + negative_pos\n",
    "    decisive_em_pattern_ref = [int(ins['em_pattern'][d]) for d in decisive_merge]\n",
    "    decisive_em_pattern_pred = [int(ins['sentence_inference'][d]) for d in decisive_merge]\n",
    "    \n",
    "    decisive_ref.extend(decisive_em_pattern_ref)\n",
    "    decisive_pred.extend(decisive_em_pattern_pred)\n",
    "#     print(ins['em_pattern'])\n",
    "#     print(decisive_merge)\n",
    "#     print(decisive_em_pattern)\n",
    "#     print('===')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(decisive_ref))\n",
    "print(len(decisive_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_np = np.array(decisive_pred)\n",
    "reference_np = np.array(decisive_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ed9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e1ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = pd.Series(reference_np, name='Actual')\n",
    "y_pred = pd.Series(prediction_np, name='Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "# reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "rev_accuracy = accuracy_score(y_actu, y_pred)\n",
    "rev_precision = precision_score(y_actu, y_pred)\n",
    "rev_recall = recall_score(y_actu, y_pred)\n",
    "rev_f1 = f1_score(y_actu, y_pred)\n",
    "\n",
    "logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1029f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "rev_accuracy = accuracy_score(reversey_actu, reversey_pred)\n",
    "rev_precision = precision_score(reversey_actu, reversey_pred)\n",
    "rev_recall = recall_score(reversey_actu, reversey_pred)\n",
    "rev_f1 = f1_score(reversey_actu, reversey_pred)\n",
    "\n",
    "logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_eval_data[i]['em_pattern'])\n",
    "print(original_eval_data[i]['sentence_inference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9f282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db72c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(original_eval_data[i]['cumulative_em']))\n",
    "print(original_eval_data[i]['sentence_inference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ffc08",
   "metadata": {},
   "source": [
    "## ==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94e43c",
   "metadata": {},
   "source": [
    "# Get top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eea92896",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f975683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68fdf482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/FiD-Encoder-lstm-12layers-sequence_exclude_no_answer_partial_decisive\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27a2ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbabf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = path.glob('*/*[0-9]_results.json')\n",
    "# pprint(len(list(files)))\n",
    "# pprint(list(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9eafd26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_result = []\n",
    "\n",
    "for file in files:\n",
    "    step = str(file).split('/')[-2]\n",
    "    result = utils.open_json(file)\n",
    "    step_result.append(result)\n",
    "    \n",
    "# pprint(step_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04893373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3380: 0, 2640: 0, 3640: 0, 3381: 0, 2160: 0, 2380: 0, 1980: 0, 2200: 0, 2880: 0, 3000: 0, 1960: 0, 2360: 0, 3360: 0, 3580: 0, 1920: 0, 2220: 0, 2480: 0, 2400: 0, 2780: 0, 2240: 0}\n"
     ]
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for dict_ins in step_result:\n",
    "    score_dict[dict_ins['step']] = 0\n",
    "print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "811408ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = len(step_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d257ca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sorted(step_result, key=lambda x: x['eval_accuracy'], reverse = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81c8fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by(result, key, top_k, score_dict):\n",
    "    newlist = sorted(result, key=lambda d: d[key], reverse = True) \n",
    "    print(f'sorting by {key}')\n",
    "    for dic_ in newlist[:top_k]:\n",
    "        print(f\"step : {dic_['step']}, key : {dic_[key]}\")\n",
    "    for dic_, score_ in zip(newlist, list(range(len(step_result) ,0 , -1))):\n",
    "        score_dict[dic_['step']] += score_\n",
    "    print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3b91279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_accuracy\n",
      "step : 2160, key : 0.8049915397631133\n",
      "step : 2400, key : 0.8045685279187818\n",
      "step : 2880, key : 0.8032994923857868\n",
      "step : 2220, key : 0.8032994923857868\n",
      "step : 2200, key : 0.8028764805414551\n",
      "step : 2360, key : 0.8028764805414551\n",
      "step : 3360, key : 0.8028764805414551\n",
      "step : 2780, key : 0.8028764805414551\n",
      "step : 2240, key : 0.8024534686971235\n",
      "step : 3380, key : 0.8020304568527918\n",
      "step : 1980, key : 0.8020304568527918\n",
      "step : 1960, key : 0.8020304568527918\n",
      "step : 3580, key : 0.8020304568527918\n",
      "step : 1920, key : 0.8020304568527918\n",
      "step : 2480, key : 0.8020304568527918\n",
      "step : 2640, key : 0.8016074450084603\n",
      "step : 3640, key : 0.8016074450084603\n",
      "step : 3381, key : 0.8016074450084603\n",
      "step : 2380, key : 0.8016074450084603\n",
      "step : 3000, key : 0.8016074450084603\n",
      "{3380: 11, 2640: 5, 3640: 4, 3381: 3, 2160: 20, 2380: 2, 1980: 10, 2200: 16, 2880: 18, 3000: 1, 1960: 9, 2360: 15, 3360: 14, 3580: 8, 1920: 7, 2220: 17, 2480: 6, 2400: 19, 2780: 13, 2240: 12}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_accuracy', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cd815a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_f1\n",
      "step : 2240, key : 0.832796276405299\n",
      "step : 2200, key : 0.8314037626628076\n",
      "step : 2220, key : 0.8303538854432688\n",
      "step : 2400, key : 0.8292682926829268\n",
      "step : 2880, key : 0.8292324641939038\n",
      "step : 3000, key : 0.8283937065495792\n",
      "step : 1920, key : 0.8283198826118855\n",
      "step : 2160, key : 0.8279208659947742\n",
      "step : 3360, key : 0.8277900960827791\n",
      "step : 3381, key : 0.8273831431726169\n",
      "step : 1960, key : 0.8266666666666667\n",
      "step : 1980, key : 0.8264094955489615\n",
      "step : 2360, key : 0.8262490678598061\n",
      "step : 2780, key : 0.8261194029850747\n",
      "step : 2480, key : 0.8258928571428571\n",
      "step : 3380, key : 0.8257632166790767\n",
      "step : 2640, key : 0.8257153474544779\n",
      "step : 3580, key : 0.8243243243243243\n",
      "step : 2380, key : 0.8230856280648812\n",
      "step : 3640, key : 0.8229520573801434\n",
      "{3380: 16, 2640: 9, 3640: 5, 3381: 14, 2160: 33, 2380: 4, 1980: 19, 2200: 35, 2880: 34, 3000: 16, 1960: 19, 2360: 23, 3360: 26, 3580: 11, 1920: 21, 2220: 35, 2480: 12, 2400: 36, 2780: 20, 2240: 32}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_f1', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5e9e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_precision\n",
      "step : 3640, key : 0.8128262490678598\n",
      "step : 2380, key : 0.8123603871928519\n",
      "step : 3580, key : 0.8097345132743363\n",
      "step : 2160, key : 0.8088986141502553\n",
      "step : 2780, key : 0.8068513119533528\n",
      "step : 2360, key : 0.8064046579330422\n",
      "step : 3380, key : 0.8047895500725689\n",
      "step : 2480, key : 0.8043478260869565\n",
      "step : 2640, key : 0.8033261026753434\n",
      "step : 1980, key : 0.8025936599423631\n",
      "step : 2400, key : 0.8025751072961373\n",
      "step : 1960, key : 0.8017241379310345\n",
      "step : 3360, key : 0.8011444921316166\n",
      "step : 2880, key : 0.7978798586572439\n",
      "step : 3381, key : 0.7977288857345636\n",
      "step : 1920, key : 0.7961918194640338\n",
      "step : 3000, key : 0.7943859649122808\n",
      "step : 2220, key : 0.7941381716678297\n",
      "step : 2200, key : 0.7891483516483516\n",
      "step : 2240, key : 0.7831649831649832\n",
      "{3380: 30, 2640: 21, 3640: 25, 3381: 20, 2160: 50, 2380: 23, 1980: 30, 2200: 37, 2880: 41, 3000: 20, 1960: 28, 2360: 38, 3360: 34, 3580: 29, 1920: 26, 2220: 38, 2480: 25, 2400: 46, 2780: 36, 2240: 33}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_precision', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bef47370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_recall\n",
      "step : 2240, key : 0.8891437308868502\n",
      "step : 2200, key : 0.8784403669724771\n",
      "step : 2220, key : 0.8700305810397554\n",
      "step : 3000, key : 0.8654434250764526\n",
      "step : 2880, key : 0.8631498470948012\n",
      "step : 1920, key : 0.8631498470948012\n",
      "step : 3381, key : 0.8593272171253823\n",
      "step : 2400, key : 0.8577981651376146\n",
      "step : 3360, key : 0.8562691131498471\n",
      "step : 1960, key : 0.8532110091743119\n",
      "step : 1980, key : 0.8516819571865444\n",
      "step : 2640, key : 0.849388379204893\n",
      "step : 2480, key : 0.8486238532110092\n",
      "step : 3380, key : 0.8478593272171254\n",
      "step : 2160, key : 0.8478593272171254\n",
      "step : 2360, key : 0.8470948012232415\n",
      "step : 2780, key : 0.8463302752293578\n",
      "step : 3580, key : 0.8394495412844036\n",
      "step : 2380, key : 0.8340978593272171\n",
      "step : 3640, key : 0.8333333333333334\n",
      "{3380: 37, 2640: 30, 3640: 26, 3381: 34, 2160: 56, 2380: 25, 1980: 40, 2200: 56, 2880: 57, 3000: 37, 1960: 39, 2360: 43, 3360: 46, 3580: 32, 1920: 41, 2220: 56, 2480: 33, 2400: 59, 2780: 40, 2240: 53}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_recall', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75b04845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by(result, key, top_k, score_dict):\n",
    "    newlist = sorted(result, key=lambda d: d[key], reverse = True) \n",
    "    print(f'sorting by {key}')\n",
    "    for dic_ in newlist[:top_k]:\n",
    "        print(f\"step : {dic_['step']}, key : {dic_[key]}\")\n",
    "    for dic_, score_ in zip(newlist, list(range(len(step_result) ,0 , -1))):\n",
    "        score_dict[dic_['step']] += score_\n",
    "    print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1952b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2400 : scores : 59\n",
      "step 2880 : scores : 57\n",
      "step 2160 : scores : 56\n",
      "step 2200 : scores : 56\n",
      "step 2220 : scores : 56\n",
      "step 2240 : scores : 53\n",
      "step 3360 : scores : 46\n",
      "step 2360 : scores : 43\n",
      "step 1920 : scores : 41\n",
      "step 1980 : scores : 40\n",
      "step 2780 : scores : 40\n",
      "step 1960 : scores : 39\n",
      "step 3380 : scores : 37\n",
      "step 3000 : scores : 37\n",
      "step 3381 : scores : 34\n",
      "step 2480 : scores : 33\n",
      "step 3580 : scores : 32\n",
      "step 2640 : scores : 30\n",
      "step 3640 : scores : 26\n",
      "step 2380 : scores : 25\n"
     ]
    }
   ],
   "source": [
    "sorted_score_dict = sorted(score_dict.items(), key=lambda x:x[1], reverse = True)\n",
    "for k, v in sorted_score_dict:\n",
    "    print(f'step {k} : scores : {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9310b8d",
   "metadata": {},
   "source": [
    "## Reverse REsult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c350c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = path.glob('*/*rev_results.json')\n",
    "# pprint(list(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49878cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_result = []\n",
    "\n",
    "for file in files:\n",
    "    step = str(file).split('/')[-2]\n",
    "    result = utils.open_json(file)\n",
    "    step_result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5ce270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for dict_ins in step_result:\n",
    "    score_dict[dict_ins['step']] = 0\n",
    "# print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f1d86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = len(step_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bebfee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_rev_accuracy\n",
      "step : 2160, key : 0.8049915397631133\n",
      "step : 2400, key : 0.8045685279187818\n",
      "step : 2880, key : 0.8032994923857868\n",
      "step : 2220, key : 0.8032994923857868\n",
      "step : 2200, key : 0.8028764805414551\n",
      "step : 2360, key : 0.8028764805414551\n",
      "step : 3360, key : 0.8028764805414551\n",
      "step : 2780, key : 0.8028764805414551\n",
      "step : 2240, key : 0.8024534686971235\n",
      "step : 3380, key : 0.8020304568527918\n",
      "step : 1980, key : 0.8020304568527918\n",
      "step : 1960, key : 0.8020304568527918\n",
      "step : 3580, key : 0.8020304568527918\n",
      "step : 1920, key : 0.8020304568527918\n",
      "step : 2480, key : 0.8020304568527918\n",
      "step : 2640, key : 0.8016074450084603\n",
      "step : 3640, key : 0.8016074450084603\n",
      "step : 3381, key : 0.8016074450084603\n",
      "step : 2380, key : 0.8016074450084603\n",
      "step : 3000, key : 0.8016074450084603\n",
      "{3380: 11, 2640: 5, 3640: 4, 3381: 3, 2160: 20, 2380: 2, 1980: 10, 2200: 16, 2880: 18, 3000: 1, 1960: 9, 2360: 15, 3360: 14, 3580: 8, 1920: 7, 2220: 17, 2480: 6, 2400: 19, 2780: 13, 2240: 12}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_rev_accuracy', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1d532ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_rev_precision\n",
      "step : 2240, key : 0.8350398179749715\n",
      "step : 2200, key : 0.8248898678414097\n",
      "step : 2220, key : 0.8174006444683136\n",
      "step : 3000, key : 0.8125665601703941\n",
      "step : 2880, key : 0.8113804004214963\n",
      "step : 1920, key : 0.8107822410147991\n",
      "step : 2400, key : 0.8074534161490683\n",
      "step : 3381, key : 0.8073298429319372\n",
      "step : 3360, key : 0.8053830227743272\n",
      "step : 1960, key : 0.8024691358024691\n",
      "step : 1980, key : 0.8012295081967213\n",
      "step : 2160, key : 0.7995971802618328\n",
      "step : 2640, key : 0.799184505606524\n",
      "step : 2480, key : 0.7987804878048781\n",
      "step : 3380, key : 0.7981744421906694\n",
      "step : 2360, key : 0.797979797979798\n",
      "step : 2780, key : 0.7973790322580645\n",
      "step : 3580, key : 0.7916666666666666\n",
      "step : 2380, key : 0.7874632713026445\n",
      "step : 3640, key : 0.7869012707722385\n",
      "{3380: 17, 2640: 13, 3640: 5, 3381: 16, 2160: 29, 2380: 4, 1980: 20, 2200: 35, 2880: 34, 3000: 18, 1960: 20, 2360: 20, 3360: 26, 3580: 11, 1920: 22, 2220: 35, 2480: 13, 2400: 33, 2780: 17, 2240: 32}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_rev_precision', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bd645e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_rev_recall\n",
      "step : 3640, key : 0.7623106060606061\n",
      "step : 2380, key : 0.7613636363636364\n",
      "step : 3580, key : 0.7556818181818182\n",
      "step : 2160, key : 0.7518939393939394\n",
      "step : 2780, key : 0.7490530303030303\n",
      "step : 2360, key : 0.7481060606060606\n",
      "step : 3380, key : 0.7452651515151515\n",
      "step : 2480, key : 0.7443181818181818\n",
      "step : 2640, key : 0.7424242424242424\n",
      "step : 1980, key : 0.740530303030303\n",
      "step : 1960, key : 0.7386363636363636\n",
      "step : 2400, key : 0.7386363636363636\n",
      "step : 3360, key : 0.7367424242424242\n",
      "step : 3381, key : 0.7301136363636364\n",
      "step : 2880, key : 0.7291666666666666\n",
      "step : 1920, key : 0.7263257575757576\n",
      "step : 3000, key : 0.7225378787878788\n",
      "step : 2220, key : 0.7206439393939394\n",
      "step : 2200, key : 0.709280303030303\n",
      "step : 2240, key : 0.6950757575757576\n",
      "{3380: 31, 2640: 25, 3640: 25, 3381: 23, 2160: 46, 2380: 23, 1980: 31, 2200: 37, 2880: 40, 3000: 22, 1960: 30, 2360: 35, 3360: 34, 3580: 29, 1920: 27, 2220: 38, 2480: 26, 2400: 42, 2780: 33, 2240: 33}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_rev_recall', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "406f6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting by eval_rev_f1\n",
      "step : 2160, key : 0.7750122010736944\n",
      "step : 3640, key : 0.7744107744107743\n",
      "step : 2380, key : 0.7741935483870969\n",
      "step : 3580, key : 0.7732558139534884\n",
      "step : 2780, key : 0.7724609375\n",
      "step : 2360, key : 0.772238514173998\n",
      "step : 2400, key : 0.7715133531157269\n",
      "step : 3380, key : 0.7708129285014692\n",
      "step : 2480, key : 0.7705882352941177\n",
      "step : 2640, key : 0.7697594501718213\n",
      "step : 1980, key : 0.7696850393700787\n",
      "step : 3360, key : 0.7695351137487635\n",
      "step : 1960, key : 0.7692307692307692\n",
      "step : 2880, key : 0.7680798004987531\n",
      "step : 3381, key : 0.7667826951765291\n",
      "step : 1920, key : 0.7662337662337662\n",
      "step : 2220, key : 0.7659788626069453\n",
      "step : 3000, key : 0.7649122807017544\n",
      "step : 2200, key : 0.7627291242362524\n",
      "step : 2240, key : 0.7586563307493539\n",
      "{3380: 44, 2640: 36, 3640: 44, 3381: 29, 2160: 66, 2380: 41, 1980: 41, 2200: 39, 2880: 47, 3000: 25, 1960: 38, 2360: 50, 3360: 43, 3580: 46, 1920: 32, 2220: 42, 2480: 38, 2400: 56, 2780: 49, 2240: 34}\n"
     ]
    }
   ],
   "source": [
    "sort_by(step_result, 'eval_rev_f1', top_n, score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7375b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by(result, key, top_k, score_dict):\n",
    "    newlist = sorted(result, key=lambda d: d[key], reverse = True) \n",
    "    print(f'sorting by {key}')\n",
    "    for dic_ in newlist[:top_k]:\n",
    "        print(f\"step : {dic_['step']}, key : {dic_[key]}\")\n",
    "    for dic_, score_ in zip(newlist, list(range(len(step_result) ,0 , -1))):\n",
    "        score_dict[dic_['step']] += score_\n",
    "    print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "587648de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2160 : scores : 66\n",
      "step 2400 : scores : 56\n",
      "step 2360 : scores : 50\n",
      "step 2780 : scores : 49\n",
      "step 2880 : scores : 47\n",
      "step 3580 : scores : 46\n",
      "step 3380 : scores : 44\n",
      "step 3640 : scores : 44\n",
      "step 3360 : scores : 43\n",
      "step 2220 : scores : 42\n",
      "step 2380 : scores : 41\n",
      "step 1980 : scores : 41\n",
      "step 2200 : scores : 39\n",
      "step 1960 : scores : 38\n",
      "step 2480 : scores : 38\n",
      "step 2640 : scores : 36\n",
      "step 2240 : scores : 34\n",
      "step 1920 : scores : 32\n",
      "step 3381 : scores : 29\n",
      "step 3000 : scores : 25\n"
     ]
    }
   ],
   "source": [
    "sorted_score_dict = sorted(score_dict.items(), key=lambda x:x[1], reverse = True)\n",
    "for k, v in sorted_score_dict:\n",
    "    print(f'step {k} : scores : {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced9e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af50c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
