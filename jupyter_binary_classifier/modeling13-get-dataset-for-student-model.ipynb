{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86601ea",
   "metadata": {},
   "source": [
    "# modeling13-get-dataset-for-student-model\n",
    "\n",
    "- Get dataset for student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b5b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from util import utils\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0dd99",
   "metadata": {},
   "source": [
    "# Dev Prediction file\n",
    "- Original FiD Dataset  \n",
    "        Train  \n",
    "        Dev   \n",
    "        Test  \n",
    "    \n",
    "\n",
    "- Teacher Binray Classification Dataset\n",
    "        Train   \n",
    "        Dev -> Train/Dev   \n",
    "        Test  \n",
    "\n",
    "    \n",
    "- Student Binary Classfication Dataset\n",
    "        Train   \n",
    "        Dev \n",
    "            Train\n",
    "            Dev -> Train/Dev\n",
    "        Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af3248",
   "metadata": {},
   "source": [
    "## Get Prediction of Teacher model on Dev\n",
    "    - Get the gold model\n",
    "    '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction/prediction.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7d5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction/prediction.json\n"
     ]
    }
   ],
   "source": [
    "input_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction'\n",
    "input_file = 'prediction.json'\n",
    "input_file_path = os.path.join(input_path, input_file)\n",
    "print(input_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfa4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = utils.open_json(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3ea3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1704"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6eaf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'question': 'who sings does he love me with reba',\n",
       " 'ctx': {'id': '11828866',\n",
       "  'title': 'Does He Love You',\n",
       "  'text': 'Does He Love You \"Does He Love You\" is a song written by Sandy Knox and Billy Stritch, and recorded as a duet by American country music artists Reba McEntire and Linda Davis. It was released in August 1993 as the first single from Reba\\'s album \"Greatest Hits Volume Two\". It is one of country music\\'s several songs about a love triangle. \"Does He Love You\" was written in 1982 by Billy Stritch. He recorded it with a trio in which he performed at the time, because he wanted a song that could be sung by the other two members'},\n",
       " 'em': '1',\n",
       " 'answers': ['Linda Davis'],\n",
       " 'gold': 'Linda Davis',\n",
       " 'inference': 'Linda Davis',\n",
       " 'binary_inference': '1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40a86a",
   "metadata": {},
   "source": [
    "## Check Original Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_gold_dev = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_dev_1.json'\n",
    "# binary_gold_train = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_train_1.json'\n",
    "\n",
    "# binary_gold_dev = utils.open_json(binary_gold_dev)\n",
    "# binary_gold_train = utils.open_json(binary_gold_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b85d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(binary_gold_dev))\n",
    "# print(len(binary_gold_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d866d",
   "metadata": {},
   "source": [
    "## Split by 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65155e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f66bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(prediction_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction'\n",
    "output_directory = '5-fold'\n",
    "output_path_directory = os.path.join(output_path, output_directory)\n",
    "print(output_path_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_path_directory, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a52796",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(prediction_data)):\n",
    "    output_path_i = output_path_directory + f'/{i+1}'\n",
    "    os.makedirs(output_path_i, exist_ok = True)\n",
    "    train_file_name = f'prediction_split_train_{i+1}.json'\n",
    "    test_file_name = f'prediction_split_dev_{i+1}.json'\n",
    "    \n",
    "    train_path = os.path.join(output_path_i, train_file_name)\n",
    "    test_path = os.path.join(output_path_i, test_file_name)\n",
    "    \n",
    "    print(f'train_path : {train_path}')\n",
    "    print(f'dev_path : {test_path}')\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index[:10]}\")\n",
    "    print(f\"  Test:  index={test_index[:10]}\")\n",
    "    train_split = [prediction_data[j] for j in train_index]\n",
    "    test_split = [prediction_data[j] for j in test_index]\n",
    "    print(f'size of train : {len(train_split)}')\n",
    "    print(f'size of dev : {len(test_split)}')\n",
    "    \n",
    "    utils.save_json(train_split, train_path)\n",
    "    utils.save_json(test_split, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae9f17",
   "metadata": {},
   "source": [
    "# Get Train & Dev dataset fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0deb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction/5-fold/1/prediction_split_train_1.json'\n",
    "dev_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/dev_prediction/5-fold/1/prediction_split_dev_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e3860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.open_json(train_path)\n",
    "dev_data = utils.open_json(dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6486023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676712b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b7fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 65,\n",
       " 'question': 'who plays caroline on the bold and beautiful',\n",
       " 'ctx': {'id': '7171602',\n",
       "  'title': 'Barbara Crampton',\n",
       "  'text': '\"Guiding Light\" from 1993 to 1995 and left when her contract expired and when she got engaged to L.A.-based actor and director Kristoffer Tabori in April 1995. By September of the same year, their engagement was called off. In 1995, Crampton starred in \"Castle Freak\". From 1995 to 1998, Crampton portrayed Maggie Forrester on \"The Bold and the Beautiful\". In 1996, Crampton portrayed Carol in \"Space Truckers\". In 1997, Crampton guest starred on \"The Nanny\". The following year, she guest starred on \"Party of Five\" and starred in the film \"The Godson\". In 1999, Crampton guest starred on the television'},\n",
       " 'em': '1',\n",
       " 'answers': ['Linsey Godfrey'],\n",
       " 'gold': 'Linsey Godfrey',\n",
       " 'inference': 'Linsey Godfrey',\n",
       " 'binary_inference': '0'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d69ec7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total instanes 1363\n",
      "0 instanes 90\n",
      "1 instanes 251\n",
      "0 ratio 0.06603081438004402\n",
      "1 instanes 0.18415260454878943\n"
     ]
    }
   ],
   "source": [
    "cnt1_ = 0\n",
    "cnt0_ = 0\n",
    "\n",
    "for ins in dev_data:\n",
    "    if ins['binary_inference'] == '1':\n",
    "        cnt1_ += 1\n",
    "    else:\n",
    "        cnt0_ += 1\n",
    "print(f'total instanes {len(train_data)}')\n",
    "print(f'0 instanes {cnt0_}')\n",
    "print(f'1 instanes {cnt1_}')\n",
    "\n",
    "print(f'0 ratio {cnt0_/len(train_data)}')\n",
    "print(f'1 instanes {cnt1_/len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59213dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242051e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cd2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acdb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import BinaryCustomDatasetShuffle, BinaryCustomDatasetPredictionShuffle\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1301a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7aa6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BinaryCustomDatasetPredictionShuffle(train_data, tokenizer, max_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ef25c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 40018, 35, 54, 22707, 473, 37, 657, 162, 19, 5898, 102, 6, 1437, 1270, 35, 8901, 91, 3437, 370, 6, 1437, 5377, 4832, 8901, 91, 3437, 370, 22, 27847, 91, 3437, 370, 113, 16, 10, 2214, 1982, 30, 10234, 12996, 8, 7835, 312, 46313, 6, 8, 2673, 25, 10, 4279, 594, 30, 470, 247, 930, 3528, 1223, 3178, 1509, 30495, 1885, 8, 9369, 2505, 4, 85, 21, 703, 11, 830, 9095, 25, 5, 78, 881, 31, 1223, 3178, 18, 2642, 22, 19065, 990, 35865, 18071, 1596, 845, 85, 16, 65, 9, 247, 930, 18, 484, 3686, 59, 10, 657, 29884, 4, 22, 27847, 91, 3437, 370, 113, 21, 1982, 11, 12910, 30, 7835, 312, 46313, 4, 91, 2673, 24, 19, 10, 8566, 11, 61, 37, 3744, 23, 5, 86, 6, 142, 37, 770, 10, 2214, 14, 115, 28, 26115, 30, 5, 97, 80, 453, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a44118a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>question: who sings does he love me with reba,  title: Does He Love You,  context : Does He Love You \"Does He Love You\" is a song written by Sandy Knox and Billy Stritch, and recorded as a duet by American country music artists Reba McEntire and Linda Davis. It was released in August 1993 as the first single from Reba\\'s album \"Greatest Hits Volume Two\". It is one of country music\\'s several songs about a love triangle. \"Does He Love You\" was written in 1982 by Billy Stritch. He recorded it with a trio in which he performed at the time, because he wanted a song that could be sung by the other two members</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(train_dataset[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f026b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6ba16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a6f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe6a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6a078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55517a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3184b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c49f712c",
   "metadata": {},
   "source": [
    "## Get dataset for incremental Test\n",
    "- from the output from modeling11-nli-binaryclassifier-modeling-from-scratch-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b45a1",
   "metadata": {},
   "source": [
    "## Incremental Testing Setting\n",
    "\n",
    "### 3 Method (Check out README.md)\n",
    "\n",
    "### Method 2 (2nd method of in README.md)\n",
    "    - The sooner, The better approach\n",
    "      - Keep the Positive Context in order\n",
    "    - Since we testing it, let's keep sample size of 5\n",
    "    - When there is no Exact Mathcing during the incremental inference e.g.) em_pattern = '00000'\n",
    "        - Keep the whole context so that those cases will have False on Exact Match values\n",
    "        \n",
    "    - Patterns: \n",
    "        - first 1 : positive\n",
    "        - first 0 : irrelevant \n",
    "            - we know that first is the positive context that includes answer\n",
    "            - with that perspective, it is relevant in theory\n",
    "            - ; however, dataset is created via BLEU score on two different corpus.\n",
    "            - If FiD does not correctly infer the output, \n",
    "            - context what we concieved of artificial positive context is actually irrelevant to the query.\n",
    "            - Also when realistic scenario, we don't know whether the first context contains the answer\n",
    "        - 01 pattern : Positive \n",
    "        - 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "        - 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "        - 10 pattern : Damaging\n",
    "        \n",
    "        - 11 pattern : relevant vs positive\n",
    "            Strict Positive\n",
    "                Under strict rule : consider it as relevant ?(or irrelevant?)\n",
    "                                in terms of strictly limiting the number of positive passages\n",
    "            Naive Positive\n",
    "                Under naive rule : consider it as positive\n",
    "                                in that this would increase the number of positive passages\n",
    "                \n",
    "        - A00 pattern : irrelevant vs damaging\n",
    "            if '1' does not occured in A, currnet passage is irrelevant\n",
    "            if '1' occurred in A, current passage is damaging either irrelevant \n",
    "                Strict Damaging\n",
    "                    Under strict rule : consider it as irrelevnat \n",
    "                                    in terms of strictly limiting the number of damaging passage\n",
    "                Naive Damaging\n",
    "                    Under naive rule : consider it as damaging \n",
    "                                    in that this would increase the number of damaging passages\n",
    "        \n",
    "    - Options1 : Removes only damaging\n",
    "    - Options2 : Removes damaging + irrelevant\n",
    "    - Options3 : Removes damaging + relevant\n",
    "    - Options4 : Removes damaging + irrelevant + relevnat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3933d",
   "metadata": {},
   "source": [
    "# Input\n",
    "    - result from 5-1\n",
    "    - /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2e864",
   "metadata": {},
   "source": [
    "# Trials\n",
    "    - Need to check FiD input when there are less ctxs than n_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e70256",
   "metadata": {},
   "source": [
    "# Binary Classification Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "input_file = f'/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/fid-encoder-adpative-decisive-trial7/step_360/intact_prediction/prediction.json'\n",
    "input_data = utils.open_json(input_file)\n",
    "pprint((input_data[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c63fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_id = {}\n",
    "for ins in input_data:\n",
    "    if ins['id'] not in predict_id:\n",
    "        predict_id[ins['id']] = str(ins['binary_inference'])\n",
    "    else:\n",
    "        predict_id[ins['id']] += str(ins['binary_inference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predict_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60873d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predict_id[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089262b2",
   "metadata": {},
   "source": [
    "# Binary Classification Output File -> DPR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_test_json = '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/ctx100id.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e985a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_test_data = utils.open_json(dpr_test_json)\n",
    "print(dpr_test_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ed386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins in dpr_test_data:\n",
    "    prediction_em_pattern = predict_id[ins['id']]\n",
    "    ins['prediction_em_pattern'] = prediction_em_pattern\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c32b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dpr_test_data[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb00866",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/fid-encoder-adpative-decisive-trial7/step_360/intact_prediction'\n",
    "output_file_name = 'ctx100id_prediction_em.json'\n",
    "output_file_path = os.path.join(output_path, output_file_name)\n",
    "print(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7689ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_json(dpr_test_data, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a294aa",
   "metadata": {},
   "source": [
    "# Method Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa293b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_on_prediction(input_file, option, option_p, option_d, sample_size):\n",
    "    '''\n",
    "    input_file : incremental inference result from FiD from KILT-5-1\n",
    "        path : /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json\n",
    "        \n",
    "    output : FiD input json format\n",
    "    \n",
    "    option(required) : removing strategies\n",
    "        op1 : removes damages only\n",
    "        op2 : removes damaging + irrelevant\n",
    "        op3 : removes damaging + relevant\n",
    "        op4 : removes damaging + irrelevant + relevant\n",
    "        \n",
    "    option_p(required) : positive passage selection options\n",
    "        strict : strict positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is relevant\n",
    "        naive : naive positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is positive\n",
    "                \n",
    "    option_d(required) : damaging passage selection options\n",
    "        strict : strict negative\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is irrelevant\n",
    "        naive : naive damaging\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is damaging\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    output_format = []\n",
    "    null_em = '0' * sample_size\n",
    "    \n",
    "    # 'strict', 'naive'  \n",
    "    # option_p = 'naive'\n",
    "    # option_d = 'naive'\n",
    "    # option = 'op4'\n",
    "\n",
    "    for id_, instance in enumerate(input_file,1):\n",
    "        template_dict = {}\n",
    "        if 'id' in instance.keys():\n",
    "            template_dict['id'] = instance['id']\n",
    "        else:\n",
    "            template_dict['id'] = str(id_)\n",
    "        template_dict['answers'] = instance['answers']\n",
    "        template_dict['question'] = instance['question']\n",
    "#         template_dict['em_pattern'] = instance['em_pattern']\n",
    "        template_dict['em_pattern'] = instance['em_pattern']\n",
    "        template_dict['prediction_em_pattern'] = instance['prediction_em_pattern']\n",
    "\n",
    "        em_pattern = instance['prediction_em_pattern']\n",
    "\n",
    "        # when there is at least one EM in the accumulated inference\n",
    "        if em_pattern != null_em:   \n",
    "            new_ctx = []\n",
    "\n",
    "            # relevant vs positive\n",
    "            positve_ctx_lst = []\n",
    "            relevant_ctx_lst = []\n",
    "\n",
    "            # irrelevant vs damaging\n",
    "            damaging_ctx_lst = []\n",
    "            irrelevant_ctx_lst = []\n",
    "\n",
    "\n",
    "            for idx_, ctx in enumerate(instance['ctxs']):\n",
    "\n",
    "                # checking current em\n",
    "                cur_em = em_pattern[idx_]\n",
    "                pre_em_pattern = em_pattern[:idx_]\n",
    "\n",
    "\n",
    "                # first 1 : positive\n",
    "                if not pre_em_pattern and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # first 0 : irrelevant\n",
    "                elif not pre_em_pattern and cur_em == '0':\n",
    "                    irrelevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "                # 01 pattern : positive \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # 10 pattern : damaging\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '0':\n",
    "                    damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                # 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '1':\n",
    "                    if option_p == 'strict':\n",
    "                        relevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    elif option_p == 'naive':\n",
    "                        positve_ctx_lst.append(ctx)\n",
    "\n",
    "                    else:\n",
    "                        print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                        return \n",
    "\n",
    "                # 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '0':\n",
    "                    # if '1' does not occured in A, currnet passage is irrelevant\n",
    "                    if not '1' in pre_em_pattern:\n",
    "                        irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    # if '1' occurred in A, \n",
    "                    else:\n",
    "                        # strict : consider it as irrelevnat \n",
    "                        if option_d == 'strict':\n",
    "                            irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                        # naive : consider it as damaging \n",
    "                        elif option_d == 'naive':\n",
    "                            damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                        else:\n",
    "                            print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                            return \n",
    "\n",
    "            # op1 removes damages only\n",
    "            if option == 'op1':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "\n",
    "            # op2 removes damaging + irrelevant\n",
    "            elif option == 'op2':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "\n",
    "            # op3 : Removes damaging + relevant\n",
    "            elif option == 'op3':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "            # op4 : Removes damaging + irrelevant + relevant\n",
    "            elif option == 'op4':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "\n",
    "            else:\n",
    "                print('option should be op1, op2, op3, op4')\n",
    "                return \n",
    "\n",
    "            template_dict['ctxs'] = new_ctx\n",
    "            output_format.append(template_dict)\n",
    "\n",
    "        # when there is no EM in the accumulated inference\n",
    "        else:\n",
    "            template_dict['ctxs']= instance['ctxs']\n",
    "            output_format.append(template_dict)\n",
    "    \n",
    "    print('==============instance finished======================')\n",
    "    return output_format\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9790bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option_dict = {\n",
    "#     'op1' : 'remove_damage',\n",
    "#     'op2' : 'remove_damage_irrelevant',\n",
    "#     'op3' : 'remove_damage_relevant',\n",
    "#     'op4' : 'remove_damage_irrelevant_relevant',\n",
    "# }\n",
    "# option = 'op4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op1, op2 are duplicates\n",
    "method_option_dict = {\n",
    "    'op3' : 'remove_damage_relevant',\n",
    "    'op4' : 'remove_damage_irrelevant_relevant',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_p_dict = {\n",
    "    'strict' : 'strict_positive',\n",
    "    'naive' : 'naive_positive',\n",
    "}\n",
    "# option_p = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_d_dict = {\n",
    "    'strict' : 'strict_damaging',\n",
    "    'naive' : 'naive_damaging',\n",
    "}\n",
    "# option_d = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = utils.open_json('/data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json')\n",
    "# output_path = '/data/philhoon-relevance/FiD/open_domain_data/NQ_KILT_BM25_SELECTION'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac45fe",
   "metadata": {},
   "source": [
    "# TEST set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/fid-encoder-adpative-decisive-trial7/step_360/intact_prediction/ctx100id_prediction_em.json'\n",
    "input_ = utils.open_json(input_file)\n",
    "len(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/fid-encoder-adpative-decisive-trial7/step_360/intact_prediction/selection_methods'\n",
    "\n",
    "print(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44845de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ba6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8cb1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for o_ in method_option_dict.keys():\n",
    "    for op in option_p_dict.keys():\n",
    "        for od in option_d_dict.keys():\n",
    "            option = o_\n",
    "            option_p = op\n",
    "            option_d = od\n",
    "            \n",
    "            if option == 'op4' and option_p == 'strict' and option_d == 'strict':\n",
    "                continue\n",
    "            if option == 'op4' and option_p == 'naive' and option_d == 'strict':\n",
    "                continue \n",
    "            \n",
    "            filename = f'{option_p_dict[option_p]}_{option_d_dict[option_d]}_{method_option_dict[option]}.json'\n",
    "\n",
    "            output_file = os.path.join(output_path, filename)\n",
    "            output_format = build_data_on_prediction(input_, option, option_p, option_d, sample_size)\n",
    "            \n",
    "            utils.save_json(output_format, output_file)\n",
    "            print(f'{filename} save on \\n {output_path}')\n",
    "#             print(f'option : {option}')\n",
    "#             print(f'option_p : {option_p}')\n",
    "#             print(f'option_d : {option_d}')\n",
    "#             print(f'filename : {filename}')\n",
    "#             print(f'output_file : {output_file}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e4db1",
   "metadata": {},
   "source": [
    "- Method3. '00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>000  (__0.73651__)     \n",
    "\n",
    "- Method4. '00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000 (_0.73611_)    \n",
    "\n",
    "- Method1. '00011011000'  -> 000<span style=\"color:red\">1</span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span><span style=\"color:red\">1</span>000 (0.71130)    \n",
    "\n",
    "- Method2. '00011011000'  -> 000<span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000  (0.70972)        \n",
    "- Method6. '00011011000'  -> <span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>10<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span> (0.68609)    \n",
    "\n",
    "- Method5. '00011011000'  -> <span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span>    (0.68452) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db221c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_dict = {'strict_positive_strict_damaging_remove_damage_relevant.json' : 'Method6', \n",
    "'strict_positive_naive_damaging_remove_damage_relevant.json' : 'Method4', \n",
    "'naive_positive_strict_damaging_remove_damage_relevant.json' : 'Method5', \n",
    "'naive_positive_naive_damaging_remove_damage_relevant.json' : 'Method3', \n",
    "'strict_positive_naive_damaging_remove_damage_irrelevant_relevant.json' : 'Method2', \n",
    "'naive_positive_naive_damaging_remove_damage_irrelevant_relevant.json' : 'Method1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c5498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b97d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee7935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cd83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1213e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb76e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bd25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0817a486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d03d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path= '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1/step_320/intact_prediction/selection_methods'\n",
    "# method 2\n",
    "test_file = 'strict_positive_naive_damaging_remove_damage_irrelevant_relevant.json'\n",
    "test_file_path = os.path.join(test_path, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = utils.open_json(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2777b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f29388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for instance in test_data:\n",
    "    print(instance['em_pattern'])\n",
    "    print(instance['prediction_em_pattern'])\n",
    "    print(len(instance['ctxs']))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83117cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1905a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fb824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba14baa2",
   "metadata": {},
   "source": [
    "## NQ dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "input_file = f'/data/philhoon-relevance/FiD/results/NQ_DPR/DEV/incremental_result_{sample_size}/ctx{sample_size}.json'\n",
    "output_path = f'/data/philhoon-relevance/FiD/open_domain_data/NQ_DPR_DEV_SELECTION/ctx_{sample_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9746045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = utils.open_json(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45554375",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad569e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o_ in method_option_dict.keys():\n",
    "    for op in option_p_dict.keys():\n",
    "        for od in option_d_dict.keys():\n",
    "            option = o_\n",
    "            option_p = op\n",
    "            option_d = od\n",
    "            \n",
    "            if option == 'op4' and option_p == 'strict' and option_d == 'strict':\n",
    "                continue\n",
    "            if option == 'op4' and option_p == 'naive' and option_d == 'strict':\n",
    "                continue \n",
    "            \n",
    "            filename = f'{option_p_dict[option_p]}_{option_d_dict[option_d]}_{method_option_dict[option]}.json'\n",
    "\n",
    "            output_file = os.path.join(output_path, filename)\n",
    "            output_format = build_data(input_, option, option_p, option_d, sample_size)\n",
    "            \n",
    "            utils.save_json(output_format, output_file)\n",
    "            print(f'{filename} save on \\n {output_path}')\n",
    "#             print(f'option : {option}')\n",
    "#             print(f'option_p : {option_p}')\n",
    "#             print(f'option_d : {option_d}')\n",
    "#             print(f'filename : {filename}')\n",
    "#             print(f'output_file : {output_file}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d292b",
   "metadata": {},
   "source": [
    "# Method explanation\n",
    "- Redundancies in selection strategies -> remove them -> 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768e084",
   "metadata": {},
   "source": [
    "#### Method1. Include passages that corresponds to 1s\n",
    "- all __option2__ belong to this case\n",
    "- option4_naive_naive, option4_naive_strict\n",
    "\n",
    "'00011011000'  -> 000<span style=\"color:red\">1</span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span><span style=\"color:red\">1</span>000  \n",
    "- red 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffe64a",
   "metadata": {},
   "source": [
    "#### Method2. Include passages that corresponds to first 1s\n",
    "- option4_strict_naive, option4_strict_strcit \n",
    "\n",
    "'00011011000'  -> \n",
    "000<span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000  \n",
    "- red 1s\n",
    "- removing consecutive passages when the previous output is correct as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e48f2",
   "metadata": {},
   "source": [
    "#### Method3. Include passages that corresponds to 1s + Included First appeared consecutive 0s\n",
    "- option1_naive_naive, option1_strict_naive\n",
    "- option3_naive_naive\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>000  \n",
    "- red 1s and blue 0s\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80226855",
   "metadata": {},
   "source": [
    "#### Method4. Include passages that corresponds to first 1s + Included First appeared consecutive 0s\n",
    "- option3_strict_naive\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000  \n",
    "- red 1s and blue 0s\n",
    "- removing consecutive passages when the previous output is correct as well\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239a92",
   "metadata": {},
   "source": [
    "#### Method5. Include passages that corresponds to 1s + Remove only damaging\n",
    "- option1_naive_strict, option1_strict_strict\n",
    "- option3_naive_strict\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:blue\">0</span><span style=\"color:blue\"><span style=\"color:blue\">0</span><span style=\"color:blue\"> \n",
    "- red 1s and blue 0s\n",
    "- only removes damaging passages for comparison with Method3, Method4\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e22f7",
   "metadata": {},
   "source": [
    "#### Method6. Include passages that corresponds to first 1s  + Remove only damaging\n",
    "- option3_strict_strict\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>10<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span>\n",
    "- red 1s and blue 0s\n",
    "- removing consecutive passages when the previous output is correct as well\n",
    "- only removes damaging passages for comparison with Method3, Method4\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b546c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- option1, option2 are not needed\n",
    "- Method1 : option4_naive_naive\n",
    "- Method2 : option4_strict_naive \n",
    "- Method3 : option3_naive_naive\n",
    "- Method4 : option3_strict_naive\n",
    "- Method5 : option3_naive_strict\n",
    "- Method6 : option3_strict_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cad32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f004d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
