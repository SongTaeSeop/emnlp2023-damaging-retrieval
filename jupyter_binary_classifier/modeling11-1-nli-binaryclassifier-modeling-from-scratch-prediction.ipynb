{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9908fbb",
   "metadata": {},
   "source": [
    "# modeling11-nli-binaryclassifier-modeling-from-scratch-prediction\n",
    "- making prediction script for binary_classifier_predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e558e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "import heapq\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "from src.data import (\n",
    "    BinaryCustomDatasetShuffle,\n",
    "    BinarySentenceDataset,\n",
    "    BinaryCustomDatasetDecisiveBinaryGold,\n",
    ")\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments, CustomTrainingArguments\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "NEW_LINE = \"\\n\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "DATASET_MAPPING = {\n",
    "    \"BinaryCustomDatasetShuffle\" : BinaryCustomDatasetShuffle,\n",
    "    \"BinarySentenceDataset\" : BinarySentenceDataset,\n",
    "    'BinaryCustomDatasetDecisiveBinaryGold' : BinaryCustomDatasetDecisiveBinaryGold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/bin/bash\n",
    "\n",
    "# #echo $SLURM_ARRAY_TASK_ID\n",
    "# #export i=$SLURM_ARRAY_TASK_ID\n",
    "# #echo $CUDA_VISIBLE_DEVICES\n",
    "# export gpu_=$CUDA_VISIBLE_DEVICES\n",
    "\n",
    "# # decisive_binary_gold_data\n",
    "# CUDA_VISIBLE_DEVICES=\"$gpu_\" python binary_classifier_predict.py \\\n",
    "# --do_train False \\\n",
    "# --do_eval True \\\n",
    "# --do_predict True \\\n",
    "# --per_device_eval_batch_size 128 \\\n",
    "# --prediction_model_name_or_path /data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1 \\\n",
    "# --prediction_model_step 380 \\\n",
    "# --max_seq_length 200 \\\n",
    "# --eval_file /data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_dev_1.json \\\n",
    "# --dataset_class BinaryCustomDatasetDecisiveBinaryGold \\\n",
    "# --num_labels 2 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataTrainingArguments, CustomTrainingArguments)\n",
    ")\n",
    "model_args, data_args, train_args = parser.parse_args_into_dataclasses([])\n",
    "# os.environ['WANDB_PROJECT'] = model_args.wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(model_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94867319",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(data_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d6004",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(vars(train_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.do_train = False\n",
    "train_args.do_eval = True\n",
    "train_args.do_predict = True\n",
    "train_args.per_device_eval_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args.prediction_model_name_or_path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1'\n",
    "model_args.prediction_model_step = '320'\n",
    "model_args.max_seq_length = 200\n",
    "model_args.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb75b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_args.prediction_model_name_or_path)\n",
    "print(model_args.prediction_model_step)\n",
    "print(model_args.max_seq_length)\n",
    "print(model_args.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev set prediction\n",
    "data_args.intact_eval = False\n",
    "data_args.eval_file = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_dev_1.json'\n",
    "\n",
    "# Test set prediction (following input format)\n",
    "# data_args.intact_eval = False\n",
    "# data_args.eval_file = '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/binary_decisive_format_ctx100id_test.json'\n",
    "\n",
    "# Whole Test Set prediction (Whole Naive set - DPR binary format)\n",
    "# data_args.intact_eval = True\n",
    "# data_args.eval_file = '/data/philhoon-relevance/binary-classification/NQ-TEST-DPR/binary_decisive_gold_ctx100id_test.json'\n",
    "\n",
    "# data_args.dataset_class = 'BinarySentenceDataset'\n",
    "data_args.dataset_class = 'BinaryCustomDatasetDecisiveBinaryGold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7352955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_args.eval_file)\n",
    "print(data_args.dataset_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42282fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(accelerator.state, main_process_only=False)\n",
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a354d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_args.intact_eval:\n",
    "    train_args.output_dir = os.path.join(model_args.prediction_model_name_or_path,\n",
    "                                         f'step_{model_args.prediction_model_step}', 'partial_prediction')\n",
    "else:\n",
    "    train_args.output_dir = os.path.join(model_args.prediction_model_name_or_path,\n",
    "                                         f'step_{model_args.prediction_model_step}', 'intact_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process and train_args.output_dir is not None:\n",
    "    os.makedirs(train_args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_args.prediction_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e6503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_args.prediction_model_name_or_path, num_labels=data_args.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85881d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_args.prediction_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(vars(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_path = os.path.join(model_args.prediction_model_name_or_path, f'step_{model_args.prediction_model_step}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823290dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        pytorch_model_path,\n",
    "        config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = data_args.eval_file\n",
    "eval_data = utils.open_json(eval_file)\n",
    "DataSetClass = DATASET_MAPPING[data_args.dataset_class]\n",
    "eval_dataset = DataSetClass(eval_data, tokenizer=tokenizer,\n",
    "                            max_length=model_args.max_seq_length, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c725b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in random.sample(range(len(eval_dataset)), 5):\n",
    "#     logger.info(f\"Sample {index} of the eval set: {eval_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=data_collator,\n",
    "                             batch_size=train_args.per_device_eval_batch_size,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_dataloader = accelerator.prepare(\n",
    "    model, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad525c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f88128",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"***** Running evaluation *****\")\n",
    "logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {train_args.per_device_eval_batch_size}\")\n",
    "logger.info(f\"  Steps = {math.ceil(len(eval_dataset)/train_args.per_device_eval_batch_size) + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model_args, data_args, train_args\n",
    "train_dict = vars(train_args)\n",
    "logger.info(f\"  Saving training_args = {train_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, \"train_args.json\"), \"w\") as f:\n",
    "    json.dump(train_dict, f)\n",
    "\n",
    "model_dict = vars(model_args)\n",
    "logger.info(f\"  Saving model_args = {model_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, \"model_args.json\"), \"w\") as f:\n",
    "    json.dump(model_dict, f)\n",
    "\n",
    "data_dict = vars(data_args)\n",
    "logger.info(f\"  Saving data_args = {data_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, \"data_args.json\"), \"w\") as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss = 0\n",
    "model.eval()\n",
    "samples_seen = 0\n",
    "prediction_lst = []\n",
    "reference_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "    if train_args.with_tracking:\n",
    "        eval_loss += loss.detach().float()\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "    # If we are in a multiprocess environment, the last batch has duplicates\n",
    "    if accelerator.num_processes > 1:\n",
    "        if step == len(eval_dataloader) - 1:\n",
    "            predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "        else:\n",
    "            samples_seen += references.shape[0]\n",
    "    \n",
    "    metric_acc.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_pre.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_re.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    metric_f1.add_batch(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )\n",
    "    eval_progress_bar.update(1)\n",
    "    prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "    reference_lst.extend(references.detach().cpu().tolist())\n",
    "#     print(f'predictions : {predictions}')\n",
    "#     print(f'prediction_lst : {prediction_lst}')\n",
    "#     print(f'references : {references}')\n",
    "#     print(f'eval_loss : {eval_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fafa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric_acc.compute()\n",
    "eval_metric_pre = metric_pre.compute()\n",
    "eval_metric_re = metric_re.compute()\n",
    "eval_metric_f1 = metric_f1.compute()\n",
    "\n",
    "logger.info(f\"Accuracy : {eval_metric['accuracy']} Precision : {eval_metric_pre['precision']}\")\n",
    "logger.info(f\"Recall : {eval_metric_re['recall']} F1 : {eval_metric_f1['f1']}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = {\n",
    "    \"eval_accuracy\": eval_metric['accuracy'],\n",
    "    \"eval_precision\": eval_metric_pre['precision'],\n",
    "    \"eval_recall\": eval_metric_re['recall'],\n",
    "    \"eval_f1\": eval_metric_f1['f1'],\n",
    "    \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result_path = os.path.join(train_args.output_dir, 'result.json')\n",
    "with open(output_result_path, \"w\") as f:\n",
    "    json.dump(result_log, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff409a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dede458",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_np = np.array(prediction_lst)\n",
    "reference_np = np.array(reference_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins, p_, r_ in zip(eval_data, prediction_np, reference_np):\n",
    "    if str(r_) != ins['em']:\n",
    "        logger.info(f\"Not Matching Instance\")\n",
    "    ins['binary_inference'] = str(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predcition_output_path = os.path.join(train_args.output_dir, 'prediction.json')\n",
    "with open(predcition_output_path, \"w\") as f:\n",
    "    json.dump(eval_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d643f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predcition_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15dddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af6163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c9af90",
   "metadata": {},
   "source": [
    "## Get top-3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/philhoon-relevance/binary-classification/results/NQ-DEV-DPR/5-fold/1/roberta-decisive_binary_gold_data_trial1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96eda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1568ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = path.glob('*/*.json')\n",
    "# pprint(list(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_result = []\n",
    "\n",
    "for file in files:\n",
    "    step = str(file).split('/')[-2]\n",
    "    result = utils.open_json(file)\n",
    "    step_result.append(result)\n",
    "    \n",
    "pprint(step_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a622a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by(result, key, top_k):\n",
    "    newlist = sorted(result, key=lambda d: d[key], reverse = True) \n",
    "    print(f'sorting by {key}')\n",
    "    for dic_ in newlist[:top_k]:\n",
    "        print(f\"step : {dic_['step']}, key : {dic_[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff68aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fef0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by(step_result, 'eval_accuracy', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f08be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by(step_result, 'eval_f1', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by(step_result, 'eval_precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by(step_result, 'eval_recall', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by(step_result, 'eval_loss', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/30/2022 03:18:32 - INFO - __main__ - Accuracy : 0.843587640142193 Precision : 0.9129472519365548\n",
    "# 12/30/2022 03:18:32 - INFO - __main__ - Recall : 0.880469583778015 F1 : 0.896414342629482\n",
    "# 12/30/2022 03:18:32 - INFO - __main__ - Eval_loss : 0.4741322724715523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e929d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe1594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082818fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "y_actu = pd.Series(reference_np, name='Actual')\n",
    "y_pred = pd.Series(prediction_np, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ins, p_, r_ in zip(eval_data, prediction_np, reference_np):\n",
    "    if str(r_) != ins['em']:\n",
    "        logger.info(f\"Not Matching Instance\")\n",
    "        break\n",
    "    ins['binary_inference'] = str(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predcition_output_path = os.path.join(train_args.output_dir, 'prediction.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(predcition_output_path, \"w\") as f:\n",
    "    json.dump(eval_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b3688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0de60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99551e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751c78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64cdbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f815c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b547c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b61520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6296b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = metric_acc.compute()\n",
    "eval_metric_pre = metric_pre.compute()\n",
    "eval_metric_re = metric_re.compute()\n",
    "eval_metric_f1 = metric_f1.compute()\n",
    "\n",
    "logger.info(f\"Accuracy : {eval_metric['accuracy']} Precision : {eval_metric_pre['precision']}\")\n",
    "logger.info(f\"Recall : {eval_metric_re['recall']} F1 : {eval_metric_f1['f1']}\")\n",
    "logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99078b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b21264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3ff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee0811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcfdfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d0f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bce5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574bdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c0530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Eval\n",
    "if train_args.do_train:\n",
    "    print('This script does not support train. Use binary_classifier.py for training')\n",
    "    train(model_args, data_args, train_args)\n",
    "    exit()\n",
    "# Eval & Prediction only\n",
    "if not train_args.do_train:\n",
    "    eval(model_args, data_args, train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import BinaryCustomDatasetShuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7292457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoModel, \n",
    "    AutoConfig, \n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments \n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCustomDatasetShuffle(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, tokenizer, max_length, shuffle = False):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = 'question: ' + self.instances[idx]['question'] + \\\n",
    "                 ' title: ' + self.instances[idx]['ctx']['title'] + \\\n",
    "                 ' context : ' + self.instances[idx]['ctx']['text']\n",
    "        output = self.tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length)\n",
    "\n",
    "        item = {key: val for key, val in output.items()}\n",
    "        # item['labels'] = torch.tensor(int(self.instances[idx]['em']))\n",
    "        item['labels'] = int(self.instances[idx]['em'])\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'roberta-large'\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed884cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_or_path, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f384d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_mismatched_sizes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba87a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        config=config,\n",
    "        ignore_mismatched_sizes=ignore_mismatched_sizes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e89593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/data/philhoon-relevance/binary-classification/\\\n",
    "NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json'\n",
    "eval_file = '/data/philhoon-relevance/binary-classification/\\\n",
    "NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776df27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.open_json(train_file)\n",
    "eval_data = utils.open_json(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fde6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec963609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BinaryCustomDatasetShuffle(train_data, tokenizer = tokenizer, \\\n",
    "                                           max_length = max_length, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = BinaryCustomDatasetShuffle(eval_data, tokenizer = tokenizer, \\\n",
    "                                           max_length = max_length, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47026d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e92816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              shuffle = True,\n",
    "                              collate_fn=data_collator,\n",
    "                              batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                              shuffle = True,\n",
    "                              collate_fn=data_collator,\n",
    "                              batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a77035",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2a0d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer_grouped_parameters[0][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba674bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_type='linear'\n",
    "num_warmup_steps = 0\n",
    "# max_train_steps = \n",
    "num_train_epochs = 5\n",
    "gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81266a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8961a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "        name=lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d33b38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch_size = per_device_train_batch_size * accelerator.num_processes * gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c96172",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(max_train_steps), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b459680",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch = 0\n",
    "with_tracking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897061",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointing_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(starting_epoch, num_train_epochs):\n",
    "    model.train()\n",
    "    if with_tracking:\n",
    "        total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        if with_tracking:\n",
    "            total_loss += loss.detach().float()\n",
    "            \n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        \n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps += 1\n",
    "            \n",
    "        if isinstance(checkpointing_steps, int):\n",
    "            if completed_steps % checkpointing_steps == 0:\n",
    "                output_dir = f\"step_{completed_steps }\"\n",
    "                if output_dir is not None:\n",
    "                    output_dir = os.path.join(args.output_dir, output_dir)\n",
    "                accelerator.save_state(output_dir)\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "                break\n",
    "                \n",
    "                \n",
    "    model.eval()\n",
    "    samples_seen = 0\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "         with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1) \n",
    "        predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        \n",
    "        if accelerator.num_processes > 1:\n",
    "            if step == len(eval_dataloader) - 1:\n",
    "                predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "                references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            else:\n",
    "                samples_seen += references.shape[0]\n",
    "        \n",
    "        metric.add_batch(\n",
    "                predictions=predictions,\n",
    "                references=references,\n",
    "            )\n",
    "        \n",
    "        eval_metric = metric.compute()\n",
    "        logger.info(f\"epoch {epoch}: {eval_metric}\")\n",
    "        \n",
    "        if args.with_tracking:\n",
    "            accelerator.log(\n",
    "                {\n",
    "                    \"accuracy\" : eval_metric,\n",
    "                    \"train_loss\": total_loss.item() / len(train_dataloader),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": completed_steps,\n",
    "                },\n",
    "                step=completed_steps,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f588f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448447fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.num_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18636963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7522dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    ")\n",
    "args = [\"--model_name_or_path\", 'allenai/longformer-large-4096', '--output_dir', './']\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b309f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f31db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ebdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        num_labels=model_args.num_labels,\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    )\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df813504",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_args.do_train:\n",
    "    instances, cut_off, total_questions = preprocessing_data(\n",
    "        data_args.train_file, \n",
    "        data_args.sample_size, \n",
    "        data_args.position)\n",
    "    \n",
    "    train_instance = instances[data_args.dev_size:]\n",
    "    dev_instance = instances[:data_args.dev_size]\n",
    "    \n",
    "    train_dataset = CustomDataset(train_instance, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    dev_dataset = CustomDataset(train_instance, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    \n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "if training_args.do_eval:\n",
    "    instances, cut_off, total_questions = preprocessing_data(\n",
    "        data_args.test_file, \n",
    "        data_args.sample_size, \n",
    "        data_args.position)\n",
    "    \n",
    "    test_dataset = CustomDataset(instances, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metric function\n",
    "metric = evaluate.load(\"xnli\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize Trainer\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer, \n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_train else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=30)]\n",
    ")\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "    \n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "    max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7e951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fc78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df12bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.dataset_name = a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed523bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a498d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e978cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )\n",
    "    \n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
