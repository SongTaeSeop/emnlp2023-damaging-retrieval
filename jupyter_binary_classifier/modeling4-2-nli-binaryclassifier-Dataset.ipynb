{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cc73b0",
   "metadata": {},
   "source": [
    "# modeling4-2-nli-binaryclassifier-BinaryInferenceDataset\n",
    "- CustomDataset Class for Binray input\n",
    "- New CustomDatset following for  \n",
    "    __modeling6-3-nli-binaryclassifier-datapreprocessing-checkingoutput-adding gold__  \n",
    "    __Converting each data into binary dataset3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8532130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoModel, \n",
    "    AutoConfig, \n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from util.arguments import ModelArguments, DataTrainingArguments \n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from util import utils\n",
    "# from transformers.models.longformer impor LongformerForSequenceClassification, LongformerSequenceClassifierOutput\n",
    "# from transformers.modeling_outputs import LongformerSequenceClassifierOutput\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55306e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )\n",
    "# parser.parse_args_into_dataclasses([])\n",
    "# args = [\"--foo\", \"1\", \"--baz\", \"quux\", \"--bar\", \"0.5\"]\n",
    "args = [\"--model_name_or_path\", 'roberta-large', '--output_dir', './']\n",
    "# (example,) = parser.parse_args_into_dataclasses(args, look_for_args_file=False)\n",
    "# args = parser.parse_args(args=[])\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args)\n",
    "# print(model_args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7a7253",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_args : \n",
      " \n",
      "ModelArguments(model_architecture='roberta-large', model_name_or_path='roberta-large', git_tag='v1.1', config_name=None, tokenizer_name=None, max_seq_length=200)\n",
      "data_args : \n",
      " \n",
      "DataTrainingArguments(data='NQ-DEV-DPR/5-fold/1', train_file='/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json', eval_file='/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json', num_labels=2, overwrite_cache=False, pad_to_max_length=False, dataset_class='BinaryCustomDatasetShuffle')\n",
      "training_args : \n",
      " \n",
      "DataTrainingArguments(data='NQ-DEV-DPR/5-fold/1', train_file='/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json', eval_file='/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/binary_data/binary_ex_ctx100id_split_train_1_partial.json', num_labels=2, overwrite_cache=False, pad_to_max_length=False, dataset_class='BinaryCustomDatasetShuffle')\n"
     ]
    }
   ],
   "source": [
    "print(f'model_args : \\n ')\n",
    "pprint(model_args)\n",
    "print(f'data_args : \\n ')\n",
    "pprint(data_args)\n",
    "print(f'training_args : \\n ')\n",
    "pprint(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f14e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "MY_DICT = {'key' : 'value'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbef502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--output_dir'], dest='output_dir', nargs=None, const=None, default='output directory', type=<class 'str'>, choices=None, help='output directory', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-s', '--seed', type=int, default=42, help='random seed (default : 42)')\n",
    "parser.add_argument('-m', '--model', type=str, default='BaseModel', help='model type (default:BaseModel)')\n",
    "parser.add_argument('--train-dataset', type=str, default='NQ', help='train dataset (default:Natural Question)')\n",
    "parser.add_argument('--eval_dataset', type=str, default='NQ', help='eval dataset (default:Natural Question)')\n",
    "parser.add_argument('--output_dir', type=str, default='output directory', help='output directory')\n",
    "# parser.add_argument('--cache_directory', type = str, default = '', help='default transformer cahce directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad13a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939bf8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4582d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce6cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d63a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# config file are updated when executing .save_pretrained('./')\n",
    "# model architecture depends on model_name\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-large', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "708f5569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST1\n",
    "# model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-large-4096')\n",
    "# model = AutoModel.from_pretrained('allenai/longformer-large-4096')\n",
    "# type(model)\n",
    "\n",
    "# TEST2\n",
    "# Custom LongformerForSequenceClassification\n",
    "# class CustomSequenceClassification(nn.Module):\n",
    "#     def __init__(self, model_name, num_labels):\n",
    "#         super(CustomSequenceClassification, self).__init__()\n",
    "#         self.num_labels = num_labels\n",
    "#         self.model_name = model_name\n",
    "        \n",
    "#         # Base Model Configuration\n",
    "#         self.model = AutoModel.from_pretrained(self.model_name, add_pooling_layer = False)\n",
    "#         self.config = self.model.config\n",
    "        \n",
    "#         # Custom Layers for Sequence Classification\n",
    "#         self.dense = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "#         self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "#         self.out_proj = nn.Linear(self.config.hidden_size, self.num_labels)\n",
    "        \n",
    "#     def forward(self, \n",
    "#                 input_ids=None, \n",
    "#                 attention_mask=None, \n",
    "#                 labels=None):\n",
    "        \n",
    "#         outputs = self.model(\n",
    "#             input_ids=input_ids, \n",
    "#             attention_mask=attention_mask,\n",
    "#         )\n",
    "        \n",
    "#         # outputs[0] -> last hidden layer \n",
    "#         sequence_output = outputs[0]\n",
    "        \n",
    "#         # [batch, sequence, hidden] -> [:, 0, :] -> hidden state of <s> or [CLS] token \n",
    "#         hidden_states = hidden_states[:, 0, :]\n",
    "#         hidden_states = self.dropout(hidden_states)\n",
    "#         hidden_states = self.dense(hidden_states)\n",
    "#         hidden_states = torch.tanh(hidden_states)\n",
    "#         hidden_states = self.dropout(hidden_states)\n",
    "#         logits = self.out_proj(hidden_states)\n",
    "        \n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             # single_label_classification\n",
    "#             loss_fct = CrossEntropyLoss()\n",
    "#             loss = loss_fct(logits.view(-1, self.num_labels), lablels.view(-1))\n",
    "            \n",
    "#         return SequenceClassifierOutput(\n",
    "#             loss=loss, \n",
    "#             logits=logits, \n",
    "#             hidden_states=outputs.hidden_states,\n",
    "#             attentions=outputs.attentions,\n",
    "#             global_attentions=outputs.gloabl_attentions\n",
    "#         )\n",
    "\n",
    "# TEST3\n",
    "# class CustomSequenceClassification(AutoModelForSequenceClassification):\n",
    "#     def __init__(self, model_name, num_labels):\n",
    "#         super().__init__()\n",
    "#         self.model_name = model_name\n",
    "#         self.num_labels = num_labels\n",
    "#         self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.num_labels)\n",
    "        \n",
    "#     def forward(self, \n",
    "#                 input_ids=None, \n",
    "#                 attention_mask=None, \n",
    "#                 labels=None):\n",
    "        \n",
    "#         outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f43504",
   "metadata": {},
   "source": [
    "## nq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba7ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nq_test_file = '/data/philhoon-relevance/KILT/kilt-dpr-retrieval/nq-dev-multikilt.json'\n",
    "# nq_dpr_dev = open_json(nq_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6205e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nq_train_file = '/data/philhoon-relevance/KILT/kilt-dpr-retrieval/nq-train-multikilt.json'\n",
    "# nq_dpr_train = open_json(nq_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00a9f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(nq_dpr_dev))\n",
    "# print(len(nq_dpr_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b576b",
   "metadata": {},
   "source": [
    "# decisive_binary_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bdce2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_file = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR\\\n",
    "/5-fold/1/decisive_binary_gold_data/\\\n",
    "binary_decisive_gold_ctx100id_split_train_1.json'\n",
    "\n",
    "binary_dev_file = '/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/\\\n",
    "5-fold/1/decisive_binary_gold_data/\\\n",
    "binary_decisive_gold_ctx100id_split_dev_1.json'\n",
    "\n",
    "# binary_dev_file = 'binary_ex_ctx100id_split_dev_1.json'\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2447af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_train_1.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c788a56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/philhoon-relevance/binary-classification/NQ-DEV-DPR/5-fold/1/decisive_binary_gold_data/binary_decisive_gold_ctx100id_split_dev_1.json'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_dev_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c6126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train = utils.open_json(binary_train_file)\n",
    "binary_dev = utils.open_json(binary_dev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a98df43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6721\n",
      "1704\n"
     ]
    }
   ],
   "source": [
    "print(len(binary_train))\n",
    "print(len(binary_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce19dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de881fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb03948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4,\n",
       " 'question': 'what is the smallest prime number that is greater than 30',\n",
       " 'ctx': {'id': '2760888',\n",
       "  'title': 'Formula for primes',\n",
       "  'text': 'of equations of degree only 4, but in 58 variables. The first such formula known was established by , who proved that there exists a real number \"A\" such that, if then is a prime number for all positive integers \"n\". If the Riemann hypothesis is true, then the smallest such \"A\" has a value of around 1.3063778838630806904686144926... and is known as Mills\\' constant. This value gives rise to the primes formula_29, formula_30, formula_31, ... Very little is known about the constant \"A\" (not even whether it is rational). This formula has no practical value, because there is no known'},\n",
       " 'em': '1',\n",
       " 'answers': ['31'],\n",
       " 'gold': '31',\n",
       " 'inference': '31'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9380e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for idx, instance in tqdm(enumerate(binary_dev)):\n",
    "#     input_ = 'question: ' + instance['question'] + ', '\\\n",
    "#         ' answer: ' + instance['gold'] + ', '\\\n",
    "#         ' title: ' + instance['ctx']['title'] + ', '\\\n",
    "#         ' context : ' + instance['ctx']['text']\n",
    "    \n",
    "#     output = tokenizer(\n",
    "#             input_, \n",
    "#             # return_tensors=\"pt\", will be applied later through collator\n",
    "#             # padding=True, will be padded later through collate\n",
    "#             truncation=True, \n",
    "#             add_special_tokens=True, \n",
    "#             max_length=max_length)\n",
    "# #     print(input_)\n",
    "# #     print(len(output['input_ids']))\n",
    "#     if len(output['input_ids']) > max_length:\n",
    "#         cnt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e23a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCustomDatasetDecisiveBinaryGold(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, tokenizer, max_length, shuffle = False):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = 'question: ' + self.instances[idx]['question'] + ', '\\\n",
    "            ' answer: ' + self.instances[idx]['gold'] + ', '\\\n",
    "            ' title: ' + self.instances[idx]['ctx']['title'] + ', '\\\n",
    "            ' context : ' + self.instances[idx]['ctx']['text']\n",
    "        output = self.tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length)\n",
    "\n",
    "        item = {key: val for key, val in output.items()}\n",
    "        # item['labels'] = torch.tensor(int(self.instances[idx]['em']))\n",
    "        item['labels'] = int(self.instances[idx]['em'])\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d897f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_decisive_binary_gold = BinaryCustomDatasetDecisiveBinaryGold(binary_train, tokenizer, max_length)\n",
    "dev_decisive_binary_gold = BinaryCustomDatasetDecisiveBinaryGold(binary_dev, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59ea4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dedf9692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 40018, 35, 147, 473, 24, 1067, 59, 5, 18023, 11, 5, 7255, 6, 1437, 1948, 35, 6776, 38, 6, 7162, 132, 6, 1437, 1270, 35, 315, 532, 20795, 6, 1437, 5377, 4832, 315, 532, 20795, 20, 315, 532, 20795, 16, 10, 5044, 13952, 18023, 17171, 30, 6776, 38, 6, 7162, 132, 9, 5, 315, 532, 5879, 6, 61, 982, 35, 22, 28588, 11649, 8, 2228, 34830, 5658, 28, 1553, 33938, 196, 566, 5, 484, 532, 1666, 309, 7, 49, 7091, 31415, 1666, 479, 20, 3031, 2271, 26229, 1258, 5658, 28, 156, 624, 130, 10426, 71, 5, 78, 529, 9, 5, 1148, 9, 5, 315, 532, 6, 8, 624, 358, 7757, 25569, 9, 2724, 10426, 72, 7162, 132, 9, 5, 501, 212, 8352, 982, 35, 22, 28588, 11649, 5658, 28, 1553, 33938, 196, 566, 5, 484, 532, 309, 7, 49, 7091, 1530, 6, 10581, 5, 1086, 346, 9, 5151, 11, 349, 331, 6, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_decisive_binary_gold[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "512eec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'question', ':', 'Ġwhere', 'Ġdoes', 'Ġit', 'Ġtalk', 'Ġabout', 'Ġthe', 'Ġcensus', 'Ġin', 'Ġthe', 'Ġconstitution', ',', 'Ġ', 'Ġanswer', ':', 'ĠArticle', 'ĠI', ',', 'ĠSection', 'Ġ2', ',', 'Ġ', 'Ġtitle', ':', 'ĠUnited', 'ĠStates', 'ĠCensus', ',', 'Ġ', 'Ġcontext', 'Ġ:', 'ĠUnited', 'ĠStates', 'ĠCensus', 'ĠThe', 'ĠUnited', 'ĠStates', 'ĠCensus', 'Ġis', 'Ġa', 'Ġdec', 'ennial', 'Ġcensus', 'Ġmandated', 'Ġby', 'ĠArticle', 'ĠI', ',', 'ĠSection', 'Ġ2', 'Ġof', 'Ġthe', 'ĠUnited', 'ĠStates', 'ĠConstitution', ',', 'Ġwhich', 'Ġstates', ':', 'Ġ\"', 'Represent', 'atives', 'Ġand', 'Ġdirect', 'ĠTaxes', 'Ġshall', 'Ġbe', 'Ġapp', 'ortion', 'ed', 'Ġamong', 'Ġthe', 'Ġseveral', 'ĠStates', 'Ġ...', 'Ġaccording', 'Ġto', 'Ġtheir', 'Ġrespective', 'ĠNumbers', 'Ġ...', 'Ġ.', 'ĠThe', 'Ġactual', 'ĠEn', 'umer', 'ation', 'Ġshall', 'Ġbe', 'Ġmade', 'Ġwithin', 'Ġthree', 'ĠYears', 'Ġafter', 'Ġthe', 'Ġfirst', 'Ġmeeting', 'Ġof', 'Ġthe', 'ĠCongress', 'Ġof', 'Ġthe', 'ĠUnited', 'ĠStates', ',', 'Ġand', 'Ġwithin', 'Ġevery', 'Ġsubsequent', 'ĠTerm', 'Ġof', 'Ġten', 'ĠYears', '.\"', 'ĠSection', 'Ġ2', 'Ġof', 'Ġthe', 'Ġ14', 'th', 'ĠAmendment', 'Ġstates', ':', 'Ġ\"', 'Represent', 'atives', 'Ġshall', 'Ġbe', 'Ġapp', 'ortion', 'ed', 'Ġamong', 'Ġthe', 'Ġseveral', 'ĠStates', 'Ġaccording', 'Ġto', 'Ġtheir', 'Ġrespective', 'Ġnumbers', ',', 'Ġcounting', 'Ġthe', 'Ġwhole', 'Ġnumber', 'Ġof', 'Ġpersons', 'Ġin', 'Ġeach', 'ĠState', ',', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(train_decisive_binary_gold[i]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c5b00b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>question: where does it talk about the census in the constitution,  answer: Article I, Section 2,  title: United States Census,  context : United States Census The United States Census is a decennial census mandated by Article I, Section 2 of the United States Constitution, which states: \"Representatives and direct Taxes shall be apportioned among the several States ... according to their respective Numbers ... . The actual Enumeration shall be made within three Years after the first meeting of the Congress of the United States, and within every subsequent Term of ten Years.\" Section 2 of the 14th Amendment states: \"Representatives shall be apportioned among the several States according to their respective numbers, counting the whole number of persons in each State,</s>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(train_decisive_binary_gold[i]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b715a5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_decisive_binary_gold[i]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243cc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4633f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455484f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6abb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636de3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77350998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(binary_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        texts = (\n",
    "            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(*texts, padding=padding, max_length=args.max_length, truncation=True)\n",
    "\n",
    "        if \"label\" in examples:\n",
    "            if label_to_id is not None:\n",
    "                # Map labels to IDs (not necessary for GLUE tasks)\n",
    "                result[\"labels\"] = [label_to_id[l] for l in examples[\"label\"]]\n",
    "            else:\n",
    "                # In all cases, rename the column to labels because the model will expect that.\n",
    "                result[\"labels\"] = examples[\"label\"]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68474d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySentenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, tokenizer, max_length, shuffle = False):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text1_ = 'question: ' + self.instances[idx]['question']\n",
    "        \n",
    "        text2_ = 'title: ' + self.instances[idx]['ctx']['title'] + \\\n",
    "                    ' context : ' + self.instances[idx]['ctx']['text']\n",
    "        output = self.tokenizer(\n",
    "            text1_, text2_, \n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length)\n",
    "\n",
    "        item = {key: val for key, val in output.items()}\n",
    "        item['labels'] = int(self.instances[idx]['em'])\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c581e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_testing = BinarySentenceDataset(binary_train,\n",
    "    tokenizer,\n",
    "    max_length,\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c034be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_testing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(train_dataset_testing[1]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2396490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca40b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4eea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCustomDatasetShuffle(torch.utils.data.Dataset):\n",
    "    def __init__(self, instances, tokenizer, max_length, shuffle = False):\n",
    "        if shuffle:\n",
    "            random.shuffle(instances)\n",
    "        self.instances = instances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ = 'question: ' + self.instances[idx]['question'] + \\\n",
    "                 ' title: ' + self.instances[idx]['ctx']['title'] + \\\n",
    "                 ' context : ' + self.instances[idx]['ctx']['text']\n",
    "        output = self.tokenizer(\n",
    "            input_,\n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length)\n",
    "\n",
    "        item = {key: val for key, val in output.items()}\n",
    "        # item['labels'] = torch.tensor(int(self.instances[idx]['em']))\n",
    "        item['labels'] = int(self.instances[idx]['em'])\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BinaryCustomDatasetShuffle(binary_train,\n",
    "    tokenizer,\n",
    "    max_length,\n",
    "    False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70eb215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.instances[0]['em']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb53b04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2b098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(binary_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac69b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84954f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = binary_train\n",
    "idx = 0\n",
    "sep_token = tokenizer.sep_token\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058260c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = 'question: ' + instances[idx]['question'] + \\\n",
    "        ' title: ' + instances[idx]['ctx']['title'] + \\\n",
    "        ' context : ' + instances[idx]['ctx']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\n",
    "            input_, \n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True, \n",
    "            add_special_tokens=True, \n",
    "            max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d62a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output['input_ids']))\n",
    "print(output['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(output['input_ids']))\n",
    "print(len(tokenizer.convert_ids_to_tokens(output['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b77c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(output['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ffa25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for idx, instance in tqdm(enumerate(instances)):\n",
    "    input_ = 'question: ' + instance['question'] + \\\n",
    "        ' title: ' + instance['ctx']['title'] + \\\n",
    "        ' context : ' + instance['ctx']['text']\n",
    "    \n",
    "    output = tokenizer(\n",
    "            input_, \n",
    "            # return_tensors=\"pt\", will be applied later through collator\n",
    "            # padding=True, will be padded later through collate\n",
    "            truncation=True, \n",
    "            add_special_tokens=True, \n",
    "            max_length=max_length)\n",
    "    \n",
    "    if len(output['input_ids']) > max_length:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a15a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294780",
   "metadata": {},
   "outputs": [],
   "source": [
    "'question: ' + binary_train[0]['question'] + ' title: ' + binary_train[0]['ctx']['title'] + ' context : ' + binary_train[0]['ctx']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train[0]['ctx']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train[0]['ctx']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de936f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "        tokenizer, \n",
    "        pad_to_multiple_of=8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer implement dataloader inside\n",
    "# data_loader = DataLoader(\n",
    "#     dataset, \n",
    "#     batch_size=8, \n",
    "#     shuffle=True, \n",
    "#     sampler=None,\n",
    "#     batch_sampler=None, \n",
    "#     num_workers=1, \n",
    "#     collate_fn=data_collator,\n",
    "#     pin_memory=False, \n",
    "#     drop_last=False, \n",
    "#     timeout=0,\n",
    "#     worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85db82",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd478dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fa945",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05191f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594be105",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric3 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb38ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
