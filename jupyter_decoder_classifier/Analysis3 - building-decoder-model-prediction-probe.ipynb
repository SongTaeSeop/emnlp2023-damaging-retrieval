{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86601ea",
   "metadata": {},
   "source": [
    "# Analysis3 - Analysis3 - building-decoder-model-prediction-probe\n",
    " - building probing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b5b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from util import utils\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527a272",
   "metadata": {},
   "source": [
    "## Check downstream results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c732a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_path = '/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/sequential-decoder-classifier-batch64X2-lr6e-4-n_layer12-combdata/step_550/result/NQ-TEST/nq-test-ctx20_pred.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d173e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1'\n",
    "path = Path(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7afde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# in_path = '/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1'\n",
    "# path = Path(in_path)\n",
    "\n",
    "# json_file_path = []\n",
    "# for file_path in path.rglob('*_pred.json'):\n",
    "#     print(file_path)\n",
    "#     json_file_path.append(file_path)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed7683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff6179e",
   "metadata": {},
   "source": [
    "## Testing\n",
    "    - /scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_500/result/NQ-TEST/nq-test-ctx60_pred.json\n",
    "    - /scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_250/result/NQ-TEST/nq-test-ctx60_pred.json\n",
    "    \n",
    "    \n",
    "```python\n",
    "find . -type d -name 'nq-test-ctx60_pred.json'\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642feeec",
   "metadata": {},
   "source": [
    "### Model (TEST)\n",
    "### Model checkpoint (step_250)\n",
    "#### Check 'finished.txt' for prediction \n",
    "#### check for '_pred.json' exists\n",
    "#### check for /result/NQ-TEST\n",
    "#### create the probe directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad4b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db9f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = utils.open_json(os.path.join(model_path, 'model_args.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0a1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = model_args['block_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d9e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ef80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lst = path.rglob('*/*ctx*_pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34822ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_100/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_550/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_50/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_400/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_500/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_200/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_300/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_450/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_250/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/TEST/step_150/result/NQ-TEST/nq-test-ctx60_pred.json\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for f in result_lst:\n",
    "    print(f)\n",
    "    # get the pred_json\n",
    "    infer_result = utils.open_json(f)\n",
    "    \n",
    "    # get the paretn path\n",
    "    parent = f.parent.absolute()\n",
    "    \n",
    "    # create 'Probes' directory\n",
    "    probe_path = parent / 'Probes'\n",
    "    os.makedirs(probe_path, exist_ok = True)\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_result = utils.open_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea571aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c44e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_path = parent / 'Probes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(probe_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ffd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op1, op2 are duplicates\n",
    "method_option_dict = {\n",
    "    'op3' : 'remove_damage_relevant',\n",
    "    'op4' : 'remove_damage_irrelevant_relevant',\n",
    "}\n",
    "\n",
    "option_p_dict = {\n",
    "    'strict' : 'strict_positive',\n",
    "    'naive' : 'naive_positive',\n",
    "}\n",
    "# option_p = 'strict'\n",
    "\n",
    "option_d_dict = {\n",
    "    'strict' : 'strict_damaging',\n",
    "    'naive' : 'naive_damaging',\n",
    "}\n",
    "# option_d = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\n",
    " 'naive_positive_naive_damaging_remove_damage_irrelevant_relevant.json' : 'probe1.json',\n",
    " 'strict_positive_naive_damaging_remove_damage_irrelevant_relevant.json' : 'probe2.json',\n",
    " 'naive_positive_naive_damaging_remove_damage_relevant.json' : 'probe3.json',\n",
    " 'strict_positive_naive_damaging_remove_damage_relevant.json' : 'probe4.json',\n",
    " 'naive_positive_strict_damaging_remove_damage_relevant.json' : 'probe5.json',\n",
    " 'strict_positive_strict_damaging_remove_damage_relevant.json' : 'probe6.json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_from_prediction(input_file, option, option_p, option_d, block_size):\n",
    "    '''\n",
    "    input_file : incremental inference result from FiD from KILT-5-1\n",
    "        path : /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json\n",
    "        \n",
    "    output : FiD input json format\n",
    "    \n",
    "    option(required) : removing strategies\n",
    "        op1 : removes damages only\n",
    "        op2 : removes damaging + irrelevant\n",
    "        op3 : removes damaging + relevant\n",
    "        op4 : removes damaging + irrelevant + relevant\n",
    "        \n",
    "    option_p(required) : positive passage selection options\n",
    "        strict : strict positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is relevant\n",
    "        naive : naive positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is positive\n",
    "                \n",
    "    option_d(required) : damaging passage selection options\n",
    "        strict : strict negative\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is irrelevant\n",
    "        naive : naive damaging\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is damaging\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    output_format = []\n",
    "    null_em = '0' * block_size\n",
    "    \n",
    "    # 'strict', 'naive'  \n",
    "    # option_p = 'naive'\n",
    "    # option_d = 'naive'\n",
    "    # option = 'op4'\n",
    "\n",
    "    for id_, instance in enumerate(input_file,1):\n",
    "        template_dict = {}\n",
    "        if 'id' in instance.keys():\n",
    "            template_dict['id'] = instance['id']\n",
    "        else:\n",
    "            template_dict['id'] = str(id_)\n",
    "        template_dict['answers'] = instance['answers']\n",
    "        template_dict['question'] = instance['question']\n",
    "        template_dict['em_pattern'] = instance['pred_em_pattern']\n",
    "        \n",
    "        \n",
    "        # Block_size check\n",
    "        if not len(infer_result[0]['pred_em_pattern']) == block_size:\n",
    "            print('Block Size does not match')\n",
    "            return None\n",
    "        \n",
    "        em_pattern = instance['pred_em_pattern']\n",
    "        \n",
    "        # when there is at least one EM in the accumulated inference\n",
    "        if em_pattern != null_em:   \n",
    "            new_ctx = []\n",
    "\n",
    "            # relevant vs positive\n",
    "            positve_ctx_lst = []\n",
    "            relevant_ctx_lst = []\n",
    "\n",
    "            # irrelevant vs damaging\n",
    "            damaging_ctx_lst = []\n",
    "            irrelevant_ctx_lst = []\n",
    "\n",
    "\n",
    "            for idx_, ctx in enumerate(instance['ctxs'][:block_size]):\n",
    "\n",
    "                # checking current em\n",
    "                cur_em = em_pattern[idx_]\n",
    "                pre_em_pattern = em_pattern[:idx_]\n",
    "\n",
    "\n",
    "                # first 1 : positive\n",
    "                if not pre_em_pattern and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # first 0 : irrelevant\n",
    "                elif not pre_em_pattern and cur_em == '0':\n",
    "                    irrelevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "                # 01 pattern : positive \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # 10 pattern : damaging\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '0':\n",
    "                    damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                # 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '1':\n",
    "                    if option_p == 'strict':\n",
    "                        relevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    elif option_p == 'naive':\n",
    "                        positve_ctx_lst.append(ctx)\n",
    "\n",
    "                    else:\n",
    "                        print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                        return \n",
    "\n",
    "                # 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '0':\n",
    "                    # if '1' does not occured in A, currnet passage is irrelevant\n",
    "                    if not '1' in pre_em_pattern:\n",
    "                        irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    # if '1' occurred in A, \n",
    "                    else:\n",
    "                        # strict : consider it as irrelevnat \n",
    "                        if option_d == 'strict':\n",
    "                            irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                        # naive : consider it as damaging \n",
    "                        elif option_d == 'naive':\n",
    "                            damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                        else:\n",
    "                            print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                            return \n",
    "\n",
    "            # op1 removes damages only\n",
    "            if option == 'op1':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "\n",
    "            # op2 removes damaging + irrelevant\n",
    "            elif option == 'op2':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "\n",
    "            # op3 : Removes damaging + relevant\n",
    "            elif option == 'op3':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "            # op4 : Removes damaging + irrelevant + relevant\n",
    "            elif option == 'op4':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "\n",
    "            else:\n",
    "                print('option should be op1, op2, op3, op4')\n",
    "                return \n",
    "\n",
    "            template_dict['ctxs'] = new_ctx\n",
    "            output_format.append(template_dict)\n",
    "\n",
    "        # when there is no EM in the accumulated inference\n",
    "        else:\n",
    "            template_dict['ctxs']= instance['ctxs']\n",
    "            output_format.append(template_dict)\n",
    "    \n",
    "    print('==============instance finished======================')\n",
    "    return output_format\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_probes(input_, output_path, name_dict):\n",
    "    for o_ in method_option_dict.keys():\n",
    "        for op in option_p_dict.keys():\n",
    "            for od in option_d_dict.keys():\n",
    "                option = o_\n",
    "                option_p = op\n",
    "                option_d = od\n",
    "\n",
    "                if option == 'op4' and option_p == 'strict' and option_d == 'strict':\n",
    "                    continue\n",
    "                if option == 'op4' and option_p == 'naive' and option_d == 'strict':\n",
    "                    continue \n",
    "\n",
    "                filename = f'{option_p_dict[option_p]}_{option_d_dict[option_d]}_{method_option_dict[option]}.json'\n",
    "                n_filename = name_dict[filename] \n",
    "                \n",
    "                output_file = os.path.join(output_path, n_filename)\n",
    "                output_format = build_data_from_prediction(input_, option, option_p, option_d, block_size)\n",
    "\n",
    "                utils.save_json(output_format, output_file)\n",
    "                print(f'{n_filename} save on \\n {output_path}')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bfb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_probes(infer_result, probe_path, name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc76220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Method1 : option4_naive_naive = remove_damage_irrelevant_relevant/naive_positive/naive_damaging\n",
    "# naive_positive_naive_damaging_remove_damage_irrelevant_relevant.json = Probe1\n",
    "\n",
    "# - Method2 : option4_strict_naive = remove_damage_irrelevant_relevant/strict_positive/naive_damaging\n",
    "# strict_positive_naive_damaging_remove_damage_irrelevant_relevant.json = Probe2\n",
    "\n",
    "# - Method3 : option3_naive_naive = remove_damage_relevant/naive_positive/naive_damaging\n",
    "# naive_positive_naive_damaging_remove_damage_relevant = Probe3\n",
    "\n",
    "# - Method4 : option3_strict_naive = remove_damage_relevant/strict_positive/naive_damaging\n",
    "# strict_positive_naive_damaging_remove_damage_relevant = Probe4\n",
    "\n",
    "# - Method5 : option3_naive_strict = remove_damage_relevant/naive_positive/strict_damaging\n",
    "# naive_positive_strict_damaging_remove_damage_relevant = Probe5\n",
    "\n",
    "# - Method6 : option3_strict_strict = remove_damage_relevant/strict_positive/strict_damaging\n",
    "# strict_positive_strict_damaging_remove_damage_relevant = Probe1\n",
    "\n",
    "# option_p_dict = {\n",
    "#     'strict' : 'strict_positive',\n",
    "#     'naive' : 'naive_positive',\n",
    "# }\n",
    "# # option_p = 'strict'\n",
    "\n",
    "# option_d_dict = {\n",
    "#     'strict' : 'strict_damaging',\n",
    "#     'naive' : 'naive_damaging',\n",
    "# }\n",
    "\n",
    "# method_option_dict = {\n",
    "#     'op3' : 'remove_damage_relevant',\n",
    "#     'op4' : 'remove_damage_irrelevant_relevant',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757cf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3058738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb8170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
