{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9908fbb",
   "metadata": {},
   "source": [
    "# Analysis3 - building-decoder-model (gpt2 based) 2\n",
    "- GPT2 based model\n",
    "- embeddings are from FiD-encoder \n",
    "- check the input\n",
    "- creating new dataset only use positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97948bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7c74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "import heapq\n",
    "import pickle\n",
    "import pathlib\n",
    "import shutil\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "from src.data import (\n",
    "    BinaryCustomDatasetShuffle,\n",
    "    BinarySentenceDataset,\n",
    "    BinaryCustomDatasetDecisiveBinaryGold,\n",
    "    BinaryCustomDatasetPredictionShuffle,\n",
    "    SentenceClassificationDataset,\n",
    "    EncoderSentenceClassificationDataset\n",
    ")\n",
    "\n",
    "from functools import partial\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import evaluate\n",
    "from util import utils\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    get_scheduler,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass, asdict\n",
    "from util.arguments import ModelArguments, DataTrainingArguments, CustomTrainingArguments\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FiD.src.model import FiDT5\n",
    "from src.model import SentenceLSTM\n",
    "\n",
    "NEW_LINE = \"\\n\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "DATASET_MAPPING = {\n",
    "    \"BinaryCustomDatasetShuffle\" : BinaryCustomDatasetShuffle,\n",
    "    \"BinarySentenceDataset\" : BinarySentenceDataset,\n",
    "    'BinaryCustomDatasetDecisiveBinaryGold' : BinaryCustomDatasetDecisiveBinaryGold,\n",
    "    'BinaryCustomDatasetPredictionShuffle' : BinaryCustomDatasetPredictionShuffle,\n",
    "    'SentenceClassificationDataset' : SentenceClassificationDataset,\n",
    "    'EncoderSentenceClassificationDataset' : EncoderSentenceClassificationDataset\n",
    "}\n",
    "EMBEDDING_ARC_MAPPING = {\n",
    "    \"SentenceTransformer\" : SentenceTransformer,\n",
    "     \"FiDT5\" : FiDT5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0baa1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definite_pos_neg(test_em):\n",
    "    positive_pos = []\n",
    "    if test_em.startswith('1'):\n",
    "        positive_pos.append(0)\n",
    "    iter_ = re.finditer(r'01', test_em)\n",
    "    for m in iter_:\n",
    "        pos_ = m.start() + 1\n",
    "        positive_pos.append(pos_)\n",
    "\n",
    "    negative_pos = []\n",
    "    iter_ = re.finditer(r'10', test_em)\n",
    "    for m in iter_:\n",
    "        pos_ = m.start() + 1\n",
    "        negative_pos.append(pos_)\n",
    "\n",
    "    return positive_pos, negative_pos\n",
    "\n",
    "\n",
    "def get_semi_pos(test_em):\n",
    "    semi_pos = []\n",
    "    iter_ = re.finditer(r'(?=(11))', test_em)\n",
    "    for m in iter_:\n",
    "        semi_pos_ = m.start() + 1\n",
    "        semi_pos.append(semi_pos_)\n",
    "\n",
    "    return semi_pos\n",
    "\n",
    "def get_semi_neg(test_em, num_undecisive):\n",
    "    semi_neg = []\n",
    "    test_em_temp = test_em[num_undecisive:]\n",
    "    iter_ = re.finditer(r'(?=(00))', test_em_temp)\n",
    "    for m in iter_:\n",
    "        semi_neg_ = m.start() + 1\n",
    "        semi_neg.append(semi_neg_)\n",
    "    semi_neg = [i + num_undecisive for i in semi_neg]\n",
    "    return semi_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d26d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_gelu(x):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
    "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c69523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f147a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        # flash attention make GPU go brrrrr but support is only in PyTorch nightly and still a bit scary\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention') and self.dropout == 0.0\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention atm needs PyTorch nightly and dropout=0.0\")\n",
    "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedb2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = new_gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1a032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9681713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class GPTConfig:\n",
    "#     block_size: int = 200 # block_size = max_token_length, switch to 100 (# of passages)\n",
    "#     num_labels: int = 2\n",
    "#     # vocab_size: int = 50304 GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "#     # won't be used in here\n",
    "#     n_layer: int = 12\n",
    "#     n_head: int = 12\n",
    "#     n_embd: int = 1024 # original is 768, switch to 1024\n",
    "#     dropout: float = 0.0\n",
    "#     bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a20ed",
   "metadata": {},
   "source": [
    "# Damaging Passage Module - Decoder Based (GPT-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Size of models\n",
    "# config_args = {\n",
    "#             'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "#             'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "#             'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "#             'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "#         }[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SentenceGPTConfig:\n",
    "    block_size: int = 100 # block_size represents number_passages\n",
    "    token_length: int = 200 # represents the max_token_length\n",
    "    n_embd: int = 1024 # used to be 768, switch to 1024, switch to FiD encoder embedding \n",
    "    num_labels: int = 2 # labels will be either 0 or 1 (EM_pattern)\n",
    "    n_layer: int = 6\n",
    "    n_head: int = 16 # n_embd % n_head == 0\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f108fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented\n",
    "class SentenceGPT(nn.Module):\n",
    "    \n",
    "    # Compatibility Checked\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # No need for vocab_size\n",
    "        # assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "        \n",
    "        # No NEED for token & positional encoding weights\n",
    "        # n_embd, block_size, n_embde\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            # wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            # wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            embedding_layer = nn.Linear(config.token_length*config.n_embd, config.n_embd, bias = config.bias),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        \n",
    "        # Instead using vocab_size use self.num_labels\n",
    "        # self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.num_labels, bias=False)\n",
    "\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        \n",
    "        # No need for token embedding weights\n",
    "        # self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "    \n",
    "    # Compatibility Checked\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        \n",
    "        # No need for positional embedding weights\n",
    "        # if non_embedding:\n",
    "        #    n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "    \n",
    "    # Compatibility Checked\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    # Compatibility Checked\n",
    "    def forward(self, idx, targets=None):\n",
    "        # Here idx is embedding\n",
    "        # idx -> batch, block_size(num_passages), token_length, n_embd\n",
    "        # device = idx.device\n",
    "        # b, t = idx.size()\n",
    "        # device = idx.device # This is for creating positinal embedding\n",
    "        b, t, _, _ = idx.size() \n",
    "        \n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        # No need for tok_emb, pos_emb\n",
    "        # pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
    "        # forward the GPT model itself\n",
    "        # tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        # pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
    "        # x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        \n",
    "        x = idx.view(b, t, -1)\n",
    "        x = self.transformer.embedding_layer(x)\n",
    "        x = self.transformer.drop(x)\n",
    "    \n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "            \n",
    "        ## output (batch, num_passages, num_labels)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            # logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            # loss = None\n",
    "            \n",
    "            # inference time: going to foward on every position\n",
    "            logits = self.lm_head(x)\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    # No need for Compatibility Check \n",
    "    def crop_block_size(self, block_size):\n",
    "        # model surgery to decrease the block size if necessary\n",
    "        # e.g. we may load the GPT2 pretrained model checkpoint (block size 1024)\n",
    "        # but want to use a smaller block size for some smaller, simpler model\n",
    "        assert block_size <= self.config.block_size\n",
    "        self.config.block_size = block_size\n",
    "        \n",
    "        # No need for position encoding weights\n",
    "        # self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
    "        for block in self.transformer.h:\n",
    "            block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
    "    \n",
    "    # No need for Compatibility Check \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type, override_args=None):\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        override_args = override_args or {} # default to empty dict\n",
    "        # only dropout can be overridden see more notes below\n",
    "        assert all(k == 'dropout' for k in override_args)\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        config_args['bias'] = True # always True for GPT model checkpoints\n",
    "        # we can override the dropout rate, if desired\n",
    "        if 'dropout' in override_args:\n",
    "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
    "            config_args['dropout'] = override_args['dropout']\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    # Need for Compatibility Check \n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
    "        \"\"\"\n",
    "        This long function is unfortunately doing something very simple and is being very defensive:\n",
    "        We are separating out all parameters of the model into two buckets: those that will experience\n",
    "        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n",
    "        We are then returning the PyTorch optimizer object.\n",
    "        \"\"\"\n",
    "\n",
    "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (torch.nn.Linear, )\n",
    "        blacklist_weight_modules = (torch.nn.LayerNorm, LayerNorm, torch.nn.Embedding)\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "                # random note: because named_modules and named_parameters are recursive\n",
    "                # we will see the same tensors p many many times. but doing it this way\n",
    "                # allows us to know which parent module any tensor p belongs to...\n",
    "                if pn.endswith('bias'):\n",
    "                    # all biases will not be decayed\n",
    "                    no_decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    # weights of whitelist modules will be weight decayed\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    # weights of blacklist modules will NOT be weight decayed\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        # subtle: 'transformer.wte.weight' and 'lm_head.weight' are tied, so they\n",
    "        # will appear in the no_decay and decay sets respectively after the above.\n",
    "        # In addition, because named_parameters() doesn't return duplicates, it\n",
    "        # will only return the first occurence, key'd by 'transformer.wte.weight', below.\n",
    "        # so let's manually remove 'lm_head.weight' from decay set. This will include\n",
    "        # this tensor into optimization via transformer.wte.weight only, and not decayed.\n",
    "        # since we SentenceGPT does not use token embedding...\n",
    "        # decay.remove('lm_head.weight')\n",
    "\n",
    "        # validate that we considered every parameter\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                    % (str(param_dict.keys() - union_params), )\n",
    "\n",
    "        # create the pytorch optimizer object\n",
    "        optim_groups = [\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": weight_decay},\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        # new PyTorch nightly has a new 'fused' option for AdamW that is much faster\n",
    "        use_fused = (device_type == 'cuda') and ('fused' in inspect.signature(torch.optim.AdamW).parameters)\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
    "        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n",
    "        # first estimate the number of flops we do per iteration.\n",
    "        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
    "        N = self.get_num_params()\n",
    "        cfg = self.config\n",
    "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
    "        flops_per_token = 6*N + 12*L*H*Q*T\n",
    "        flops_per_fwdbwd = flops_per_token * T\n",
    "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
    "        # express our flops throughput as ratio of A100 bfloat16 peak flops\n",
    "        flops_achieved = flops_per_iter * (1.0/dt) # per second\n",
    "        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        return mfu\n",
    "    \n",
    "    # No need for Compatibility Check\n",
    "    # SenetenceGPT won't use generate function -> Ignore\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def inference(self, idx):\n",
    "        logits, _ = self(idx)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataTrainingArguments, CustomTrainingArguments)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac14362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, data_args, train_args = parser.parse_args_into_dataclasses([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(model_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(data_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(train_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05087b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.with_tracking = True\n",
    "train_args.report_to = 'wandb'\n",
    "train_args.wandb_project = 'decoder-sequential-classifier'\n",
    "train_args.run_name = 'sequential-decoder-classifier-testing'\n",
    "train_args.output_dir = '/scratch/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/decoder-sequentail-classifier-testing'\n",
    "train_args.seed = 42\n",
    "# train_args.num_layers = 2\n",
    "# train_args.drop_out_rate = 0.2\n",
    "# train_args.padding = -100\n",
    "# train_args.per_device_train_batch_size = 2\n",
    "# train_args.checkpointing_steps = '10'\n",
    "# train_args.num_train_epochs = 100\n",
    "# train_args.best_metric = 'f1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d730f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_args.learning_rate)\n",
    "# print(train_args.adam_beta1)\n",
    "# print(train_args.adam_beta2)\n",
    "# print(train_args.adam_epsilon)\n",
    "# print(train_args.gradient_accumulation_steps)\n",
    "# print(train_args.lr_scheduler_type)\n",
    "# print(train_args.num_warmup_steps)\n",
    "# print(train_args.max_train_steps)\n",
    "# print(train_args.class_weights)\n",
    "# print(train_args.train_loss_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b095ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args.embedding = 1024\n",
    "# model_args.max_seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cf07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args.model_architecture = \"SentenceTransformer\"\n",
    "# model_args.model_name_or_path = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc829f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_args.train_file = '/scratch/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/ctx100id_embedding_train_1_1.pickle'\n",
    "# data_args.eval_file = '/scratch/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/ctx100id_embedding_dev_1_1.pickle'\n",
    "# data_args.ref_train = ''\n",
    "# data_args.ref_eval = ''\n",
    "# data_args.dataset_class = 'EncoderSentenceClassificationDataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.report_to)\n",
    "# print(train_args.output_dir)\n",
    "train_args.output_dir = '/data/philhoon-relevance/decoder-classification/results/NQ-DEV-DPR/5-fold/1/testing-decoder'\n",
    "print(train_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(__name__)\n",
    "\n",
    "accelerator = (\n",
    "    Accelerator(log_with=train_args.report_to, logging_dir=train_args.output_dir) if train_args.with_tracking else Accelerator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f468628",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58093f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accelerator.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d037f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(accelerator.state, main_process_only=False)\n",
    "if accelerator.is_local_main_process:\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "if train_args.seed is not None:\n",
    "    set_seed(train_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accelerator.is_main_process)\n",
    "print(train_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process and train_args.output_dir is not None:\n",
    "    os.makedirs(train_args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a089b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_args.model_architecture in EMBEDDING_ARC_MAPPING:\n",
    "#     embedding_model = EMBEDDING_ARC_MAPPING[model_args.model_architecture](model_args.model_name_or_path)\n",
    "#     model_args.embedding = 384\n",
    "#     model_args.max_seq_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ce52c",
   "metadata": {},
   "source": [
    "## Initailizing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42549a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_context = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_gpt = SentenceGPTConfig()\n",
    "pprint(vars(config_gpt))\n",
    "config_gpt.block_size = n_context\n",
    "pprint(vars(config_gpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceGPT(config_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682c1d0",
   "metadata": {},
   "source": [
    "#### Changed filename due to error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbdb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/scratch/philhoon-relevance/decoder-classification/TQA-TEST-DPR/embedding'\n",
    "# path = Path(directory)\n",
    "# files_lst = list(path.glob('*'))\n",
    "# len('embedding')\n",
    "# for file in files_lst:\n",
    "#     old_name = str(file)\n",
    "#     new_name = file.stem[9:]\n",
    "#     new_file_name = str(file.parent) + '/' + new_name + '.pickle'\n",
    "# #     print(old_name)\n",
    "# #     print(new_file_name)\n",
    "#     os.rename(old_name, new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88b977",
   "metadata": {},
   "source": [
    "## Preparing Data - seperate pickle version\n",
    "    - mapping em and embedding by 'id'\n",
    "    - Create Dataset\n",
    "    - Testing on RTX server for RAM OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2105cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tq_path_train = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/embedding/train'\n",
    "# tq_path_dev = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/embedding/dev'\n",
    "\n",
    "# tq_ref_train = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/ctx100id_split_train_1.json'\n",
    "# tq_ref_dev = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/ctx100id_split_dev_1.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec46a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_context = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369a0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_ref_train = '/data/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/ctx100id_split_train_1.json'\n",
    "nq_ref_dev = '/data/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/ctx100id_split_dev_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c6bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nq_path_train = '/scratch/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/embedding/train'\n",
    "nq_path_dev = '/scratch/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1/embedding/dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5844ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa_ref_train = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/ctx100id_split_train_1.json'\n",
    "tqa_ref_dev = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/ctx100id_split_dev_1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ec51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa_path_train = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/embedding/train'\n",
    "tqa_path_dev = '/scratch/philhoon-relevance/decoder-classification/TQA-DEV-DPR/5-fold/1/embedding/dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb977de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd46d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nq_file in os.listdir(nq_path_dev):\n",
    "#     if 'pickle' in nq_file:\n",
    "#         nq_id = 'nq-' + nq_file.split('.')[0]\n",
    "#         print(nq_id)\n",
    "#         print(nq_path_dev + '/' + nq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for file in os.listdir(nq_path_dev):\n",
    "#     if 'pickle' in file:\n",
    "#         id_ = 'nq-' + file.split('.')[0]\n",
    "#         print(id_)\n",
    "# # print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tqa_file in os.listdir(tqa_path_dev):\n",
    "#     if 'pickle' in tqa_file:\n",
    "#         tqa_id = 'tqa-' + tqa_file.split('.')[0]\n",
    "#         print(tqa_id)\n",
    "#         print(tqa_path_dev + '/' + tqa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6e404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_label(em_pattern, n_context):\n",
    "    em_pattern = em_pattern[:n_context]\n",
    "    def_pos, def_neg, semi_pos, ini_zeros, semi_neg =(None, ) * 5\n",
    "    \n",
    "    def_pos, def_neg = get_definite_pos_neg(em_pattern)\n",
    "    semi_pos = get_semi_pos(em_pattern)\n",
    "    num_undecisive = len(em_pattern) - len(em_pattern.lstrip('0'))\n",
    "    ini_zeros = [_ for _ in range(0, num_undecisive)]\n",
    "    semi_neg = get_semi_neg(em_pattern, num_undecisive)\n",
    "    \n",
    "    label_em = [None] * n_context\n",
    "    \n",
    "    for indice in def_pos:\n",
    "        label_em[indice] = 4\n",
    "    \n",
    "    for indice in ini_zeros:\n",
    "        label_em[indice] = 3\n",
    "    \n",
    "    for indice in semi_pos:\n",
    "        label_em[indice] = 2\n",
    "    \n",
    "    for indice in semi_neg:\n",
    "        label_em[indice] = 1\n",
    "    \n",
    "    for indice in def_neg:\n",
    "        label_em[indice] = 0    \n",
    "\n",
    "    if any(x is None for x in label_em):\n",
    "        raise ValueError(\"There is None in new_label.\")\n",
    "    \n",
    "    new_em_pattern = ''.join([str(x) for x in label_em])\n",
    "    return new_em_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec7246d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCombinedSinlgeFiveLabelDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    DecoderCombinedSinlgeFourLabelDataset type merging NQ and TQA\n",
    "    'definite_pos' : 4\n",
    "    'initial_zeros' : 3\n",
    "    'semi-pos' : 2\n",
    "    'sem-neg' : 1\n",
    "    'definite_neg' : 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nq_path, tqa_path, nq_ref, tqa_ref, n_context):\n",
    "        self.nq_path = nq_path\n",
    "        self.tqa_path = tqa_path\n",
    "        self.nq_ref = utils.open_json(nq_ref)\n",
    "        self.tqa_ref = utils.open_json(tqa_ref)\n",
    "        self.n_context = n_context\n",
    "        self._get_file_ids_lst()\n",
    "        self._get_target()\n",
    "\n",
    "    def _get_file_ids_lst(self):\n",
    "        self.ids_lst = []\n",
    "        self.files = []\n",
    "\n",
    "        for nq_file in os.listdir(self.nq_path):\n",
    "            if 'pickle' in nq_file:\n",
    "                nq_id = 'nq-' + nq_file.split('.')[0]\n",
    "                self.ids_lst.append(nq_id)\n",
    "                self.files.append(self.nq_path + '/' + nq_file)\n",
    "\n",
    "        for tqa_file in os.listdir(self.tqa_path):\n",
    "            if 'pickle' in tqa_file:\n",
    "                tqa_id = 'tqa-' + tqa_file.split('.')[0]\n",
    "                self.ids_lst.append(tqa_id)\n",
    "                self.files.append(self.tqa_path + '/' + tqa_file)\n",
    "\n",
    "        print(f'self.files : {len(self.files)}')\n",
    "        print(f'self.ids_lst : {len(self.ids_lst)}')\n",
    "\n",
    "    def _get_target(self):\n",
    "        self.target = {}\n",
    "        self.new_target = {}\n",
    "        \n",
    "        for ref in self.nq_ref:\n",
    "            new_id = 'nq-' + str(ref['id'])\n",
    "            self.target[new_id] = ref['em_pattern']\n",
    "            self.new_target[new_id] = get_new_label(ref['em_pattern'], self.n_context)\n",
    "\n",
    "        for ref in self.tqa_ref:\n",
    "            new_id = 'tqa-' + str(ref['id'])\n",
    "            self.target[new_id] = ref['em_pattern']\n",
    "            self.new_target[new_id] = get_new_label(ref['em_pattern'], self.n_context)\n",
    "\n",
    "        print(f'self.target {len(self.target)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        id_ = self.ids_lst[index]\n",
    "\n",
    "        with open(file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        embedding_ = data['embedding'][:self.n_context, :, :]\n",
    "        em_pattern_ = self.new_target[id_][:self.n_context]\n",
    "        ori_em_pattern = self.target[id_][:self.n_context]\n",
    "\n",
    "        return {\n",
    "            'id': id_,\n",
    "            'embedding': embedding_,\n",
    "            'em_pattern': em_pattern_,\n",
    "            'or_em_pattern' : ori_em_pattern\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a943499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76d8d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.files : 14074\n",
      "self.ids_lst : 14074\n",
      "self.target 14074\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DecoderCombinedSinlgeFiveLabelDataset(nq_path_train, \n",
    "                                             tqa_path_train, \n",
    "                                             nq_ref_train, \n",
    "                                             tqa_ref_train,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d74ffbf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_lst = []\n",
    "# for instance in train_dataset:\n",
    "#     print(instance['or_em_pattern'])\n",
    "#     print(instance['em_pattern'])\n",
    "#     print('------')\n",
    "#     test_lst.append(instance['em_pattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2f5041ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_pos_reference_lst = test_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for em_str, ref, pred in zip(def_pos_reference_lst, reference_lst, prediction_lst):\n",
    "    pos_ind_lst, neg_ind_lst = get_definite_pos_neg(em_str)\n",
    "    if pos_ind_lst:\n",
    "        for pos_ind in pos_ind_lst:\n",
    "            def_pos_ref.append(ref[pos_ind])\n",
    "            def_pos_pre.append(pred[pos_ind])\n",
    "    if neg_ind_lst:\n",
    "        for neg_ind in neg_ind_lst:\n",
    "            def_neg_ref.append(ref[neg_ind])\n",
    "            def_neg_pre.append(pred[neg_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "42136c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERT_DICT = {\n",
    "    '4': '1', # definite_pos\n",
    "    '3': '0', # initial_zeros\n",
    "    '2': '1', # semi-pos\n",
    "    '1': '0', # semi-neg\n",
    "    '0': '0' # definite_neg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "05bc4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33333333333334222222'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "em_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4dfd432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33333333333333333333\n",
      "00000000000000000000\n",
      "33333333333333333333\n",
      "00000000000000000000\n",
      "33333333333333333333\n",
      "00000000000000000000\n",
      "33333333333333333333\n",
      "00000000000000000000\n",
      "33333333333334222222\n",
      "00000000000001111111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for em_str in def_pos_reference_lst:\n",
    "    converted_em_str = ''\n",
    "    for x in em_str:\n",
    "        converted_em_str += CONVERT_DICT[x]\n",
    "    print(em_str)\n",
    "    print(converted_em_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc55dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for em_str in def_pos_reference_lst:\n",
    "    \n",
    "    \n",
    "    pos_ind_lst, neg_ind_lst = get_definite_pos_neg(em_str)\n",
    "    #     pos_ind_lst, neg_ind_lst = get_definite_pos_neg(em_str)\n",
    "#     if pos_ind_lst:\n",
    "#         for pos_ind in pos_ind_lst:\n",
    "#             def_pos_ref.append(ref[pos_ind])\n",
    "#             def_pos_pre.append(pred[pos_ind])\n",
    "#     if neg_ind_lst:\n",
    "#         for neg_ind in neg_ind_lst:\n",
    "#             def_neg_ref.append(ref[neg_ind])\n",
    "#             def_neg_pre.append(pred[neg_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8f544f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ind_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "266af84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_ind_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad75860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37d5548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.tensor([[1,2,3],[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d18c86a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29299c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = k.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2a94dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2, 3]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b158ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df828b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61c5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e33b5f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.files : 14074\n",
      "self.ids_lst : 14074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-81-58627221d94d&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-76-d270e0788daf&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">18</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-76-d270e0788daf&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">45</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_target</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-74-42ba898a35bc&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_new_label</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>list assignment index out of range\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-81-58627221d94d>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-76-d270e0788daf>\u001b[0m:\u001b[94m18\u001b[0m in \u001b[92m__init__\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-76-d270e0788daf>\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92m_get_target\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-74-42ba898a35bc>\u001b[0m:\u001b[94m16\u001b[0m in \u001b[92mget_new_label\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mlist assignment index out of range\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = DecoderCombinedSinlgeFiveLabelDataset(nq_path_train, \n",
    "                                             tqa_path_train, \n",
    "                                             nq_ref_train, \n",
    "                                             tqa_ref_train,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = DecoderCombinedSinlgeFiveLabelDataset(nq_path_dev, \n",
    "                                             tqa_path_dev, \n",
    "                                             nq_ref_dev, \n",
    "                                             tqa_ref_dev,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13141222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000000001111111'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['em_pattern']\n",
    "train_dataset[0]['em_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75017b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0a710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bf122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407d2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2f546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4879f05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88100496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b8540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db88e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2fd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e22fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b366408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139585a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483dd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c9850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348a8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357f7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbb716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2354235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCombinedPositiveDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DecoderSinlgeDataset type merging NQ and TQA\n",
    "    \"\"\"\n",
    "    def __init__(self, nq_path, tqa_path, nq_ref, tqa_ref, n_context):\n",
    "        self.nq_path = nq_path\n",
    "        self.tqa_path = tqa_path\n",
    "        self.nq_ref = utils.open_json(nq_ref)\n",
    "        self.tqa_ref = utils.open_json(tqa_ref)\n",
    "        self.n_context = n_context\n",
    "        self._get_target()\n",
    "        self._get_file_ids_lst()\n",
    "        \n",
    "    def _get_target(self):\n",
    "        self.target = {}\n",
    "        for ref in self.nq_ref:\n",
    "            if '1' in ref['em_pattern'][:n_context]:\n",
    "                new_id = 'nq-' + str(ref['id'])\n",
    "                self.target[new_id] = ref['em_pattern']\n",
    "\n",
    "        for ref in self.tqa_ref:\n",
    "            if '1' in ref['em_pattern'][:n_context]:\n",
    "                new_id = 'tqa-' + str(ref['id'])\n",
    "                self.target[new_id] = ref['em_pattern']\n",
    "            \n",
    "        print(f'self.target {len(self.target)}')\n",
    "    \n",
    "    def _get_file_ids_lst(self):\n",
    "        self.ids_lst = []\n",
    "        self.files = []\n",
    "\n",
    "        for nq_file in os.listdir(self.nq_path):\n",
    "            if 'pickle' in nq_file:\n",
    "                nq_id = 'nq-' + nq_file.split('.')[0]\n",
    "                if nq_id in self.target:\n",
    "                    self.ids_lst.append(nq_id)\n",
    "                    self.files.append(self.nq_path + '/' + nq_file)\n",
    "\n",
    "        for tqa_file in os.listdir(self.tqa_path):\n",
    "            if 'pickle' in tqa_file:\n",
    "                tqa_id = 'tqa-' + tqa_file.split('.')[0]\n",
    "                if tqa_id in self.target:\n",
    "                    self.ids_lst.append(tqa_id)\n",
    "                    self.files.append(self.tqa_path + '/' + tqa_file)\n",
    "        \n",
    "        print(f'self.files : {len(self.files)}')\n",
    "        print(f'self.ids_lst : {len(self.ids_lst)}')\n",
    "        print(f'len(self.files) == len(self.ids_lst) : {len(self.files) == len(self.ids_lst)}')\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        id_ = self.ids_lst[index]\n",
    "        \n",
    "        with open(file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        embedding_ = data['embedding'][:self.n_context,:,:]\n",
    "        em_pattern_ = self.target[id_][:self.n_context]\n",
    "        \n",
    "        return {\n",
    "            'id' : id_,\n",
    "            'embedding' : embedding_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a9d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.target 9362\n",
      "self.files : 9362\n",
      "self.ids_lst : 9362\n",
      "len(self.files) == len(self.ids_lst) : True\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DecoderCombinedPositiveDataset(nq_path_train, \n",
    "                                             tqa_path_train, \n",
    "                                             nq_ref_train, \n",
    "                                             tqa_ref_train,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b9a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9510c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'embedding', 'em_pattern'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d515cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_label(em_pattern, n_context):\n",
    "    def_pos, def_neg, semi_pos, ini_zeros, semi_neg =(None, ) * 5\n",
    "    \n",
    "    def_pos, def_neg = get_definite_pos_neg(em_pattern)\n",
    "    semi_pos = get_semi_pos(em_pattern)\n",
    "    num_undecisive = len(em_pattern) - len(em_pattern.lstrip('0'))\n",
    "    ini_zeros = [_ for _ in range(0, num_undecisive)]\n",
    "    semi_neg = get_semi_neg(em_pattern, num_undecisive)\n",
    "    \n",
    "    label_em = [None] * n_context\n",
    "    \n",
    "    for indice in def_pos:\n",
    "        label_em[indice] = 4\n",
    "    \n",
    "    for indice in ini_zeros:\n",
    "        label_em[indice] = 3\n",
    "    \n",
    "    for indice in semi_pos:\n",
    "        label_em[indice] = 2\n",
    "    \n",
    "    for indice in semi_neg:\n",
    "        label_em[indice] = 1\n",
    "    \n",
    "    for indice in def_neg:\n",
    "        label_em[indice] = 0    \n",
    "    \n",
    "    if any(x is None for x in label_em):\n",
    "        raise ValueError(\"There is None in new_label.\")\n",
    "    \n",
    "    new_em_pattern = ''.join([str(x) for x in label_em])\n",
    "    return new_em_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fdc53b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01111111111111111111'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f64dec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_new_label(em_pattern, n_context)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0faca119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3ff3dc16f54075b7729aeb6096bc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for instance in tqdm(train_dataset):\n",
    "    em_pattern = instance['em_pattern']\n",
    "    \n",
    "    _ = get_new_label(em_pattern, n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d3209fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_pattern = check_data['em_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e8dfb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000001111111\n"
     ]
    }
   ],
   "source": [
    "print(em_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     'def_pos' : 4\n",
    "#     'ini_zeros' : 3\n",
    "#     'semi_pos' : 2\n",
    "#     'semi_neg' : 1\n",
    "#     'def_neg' : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfd71e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac725b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f0d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68076505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset1 = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = DecoderCombinedPositiveDataset(nq_path_dev, \n",
    "                                             tqa_path_dev, \n",
    "                                             nq_ref_dev, \n",
    "                                             tqa_ref_dev,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5912a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                              collate_fn= custom_collate_decoder,\n",
    "                              batch_size=5,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_obj = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f38db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a['ids'])\n",
    "print(a['embeddings'].shape)\n",
    "print(a['em_patterns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0cf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c9e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c170a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586697b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3b89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0caaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838ea49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408616e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df467ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63972135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcab55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88a197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCombinedSinlgeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DecoderSinlgeDataset type merging NQ and TQA\n",
    "    \"\"\"`\n",
    "    def __init__(self, nq_path, tqa_path, nq_ref, tqa_ref, n_context):\n",
    "        self.nq_path = nq_path\n",
    "        self.tqa_path = tqa_path\n",
    "        self.nq_ref = utils.open_json(nq_ref)\n",
    "        self.tqa_ref = utils.open_json(tqa_ref)\n",
    "        self.n_context = n_context\n",
    "        self._get_file_ids_lst()\n",
    "        self._get_target()\n",
    "\n",
    "    \n",
    "    def _get_file_ids_lst(self):\n",
    "        self.ids_lst = []\n",
    "        self.files = []\n",
    "        \n",
    "        for nq_file in os.listdir(self.nq_path):\n",
    "            if 'pickle' in nq_file:\n",
    "                nq_id = 'nq-' + nq_file.split('.')[0]\n",
    "                self.ids_lst.append(nq_id)\n",
    "                self.files.append(self.nq_path + '/' + nq_file)\n",
    "                \n",
    "        for tqa_file in os.listdir(self.tqa_path):\n",
    "            if 'pickle' in tqa_file:\n",
    "                tqa_id = 'tqa-' + tqa_file.split('.')[0]\n",
    "                self.ids_lst.append(tqa_id)\n",
    "                self.files.append(self.tqa_path + '/' + tqa_file)\n",
    "                \n",
    "        print(f'self.files : {len(self.files)}')\n",
    "        print(f'self.ids_lst : {len(self.ids_lst)}')\n",
    "    \n",
    "    def _get_target(self):\n",
    "        self.target = {}\n",
    "        for ref in self.nq_ref:\n",
    "            new_id = 'nq-' + str(ref['id'])\n",
    "            self.target[new_id] = ref['em_pattern']\n",
    "            \n",
    "        for ref in self.tqa_ref:\n",
    "            new_id = 'tqa-' + str(ref['id'])\n",
    "            self.target[new_id] = ref['em_pattern']\n",
    "            \n",
    "        print(f'self.target {len(self.target)}')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        id_ = self.ids_lst[index]\n",
    "        \n",
    "        with open(file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        embedding_ = data['embedding'][:self.n_context,:,:]\n",
    "        em_pattern_ = self.target[id_][:self.n_context]\n",
    "        \n",
    "        return {\n",
    "            'id' : id_,\n",
    "            'embedding' : embedding_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ab37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DecoderCombinedSinlgeDataset(nq_path_train, \n",
    "                                             tqa_path_train, \n",
    "                                             nq_ref_train, \n",
    "                                             tqa_ref_train,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db535769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = DecoderCombinedSinlgeDataset(nq_path_dev, \n",
    "                                             tqa_path_dev, \n",
    "                                             nq_ref_dev, \n",
    "                                             tqa_ref_dev,\n",
    "                                             n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b99385",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                              collate_fn= custom_collate_decoder,\n",
    "                              batch_size=5,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_obj = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4938de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e49803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a['ids'])\n",
    "print(a['embeddings'].shape)\n",
    "print(a['em_patterns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da54e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca318ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPositiveSinlgeDataset(Dataset):\n",
    "    def __init__(self, path, ref_file, n_context):\n",
    "        self.path = path\n",
    "        self.ref_data = utils.open_json(ref_file)\n",
    "        self.n_context = n_context\n",
    "        self._get_ids()\n",
    "        self._get_files()\n",
    "        \n",
    "    def _get_files(self):\n",
    "        self.files = []\n",
    "        candidate_files = set(os.listdir(self.path))\n",
    "        for id_ in self.ids_lst:\n",
    "            temp_file = f'{id_}.pickle'\n",
    "            if temp_file in candidate_files:\n",
    "                temp_path = self.path + '/' + temp_file\n",
    "                self.files.append(temp_path)\n",
    "        \n",
    "    def _get_ids(self):\n",
    "        self.ids_lst = []\n",
    "        self.target = {}\n",
    "        for ref in self.ref_data:\n",
    "            if '1' in ref['em_pattern'][:self.n_context]:\n",
    "                self.ids_lst.append(ref['id'])\n",
    "                self.target[ref['id']] = ref['em_pattern']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        with open(file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        id_ = data['id']\n",
    "        embedding_ = data['embedding'][:self.n_context,:,:]\n",
    "        em_pattern_ = self.target[int(id_)][:self.n_context]\n",
    "        \n",
    "        return {\n",
    "            'id' : id_,\n",
    "            'embedding' : embedding_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b43890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DecoderPositiveSinlgeDataset(nq_path_train, nq_ref_train, n_context)\n",
    "dev_dataset = DecoderPositiveSinlgeDataset(nq_path_dev, nq_ref_dev, n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa_train_dataset = DecoderPositiveSinlgeDataset(tqa_path_train, tqa_ref_train, n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tqa_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset.files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                              collate_fn= custom_collate_decoder,\n",
    "                              batch_size=5,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_obj = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd272e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a['ids'])\n",
    "print(a['embeddings'].shape)\n",
    "print(a['em_patterns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39e399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67fd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = utils.open_json(ref_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ref_data))\n",
    "print(ref_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f871b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_context = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lst = []\n",
    "cnt = 0\n",
    "for ref in ref_data:\n",
    "    if '1' in ref['em_pattern'][:n_context]:\n",
    "        id_lst.append(ref['id'])\n",
    "        cnt += 1\n",
    "print(f'total : {cnt}')\n",
    "print(id_lst)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(id_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lst = os.listdir('/scratch/philhoon-relevance/decoder-classification/NQ-DEV-DPR/5-fold/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(file_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7192d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSinlgeDataset(Dataset):\n",
    "    def __init__(self, path, ref_file, n_context):\n",
    "        self.files = [path + '/' + file for file in os.listdir(path)]\n",
    "        self.n_context = n_context\n",
    "        self.ref_file = ref_file\n",
    "        \n",
    "        # init self.ids\n",
    "#         self._get_ids()\n",
    "        \n",
    "        # init self.target \n",
    "        self._get_target()\n",
    "        \n",
    "#     def _get_ids(self):\n",
    "#         self.ids = []\n",
    "#         for file in self.files:\n",
    "#             id_ = str(file).split('/')[-1]\n",
    "#             id_ = id_.split('.')[0]\n",
    "#             self.ids.append(int(id_))\n",
    "        \n",
    "    def _get_target(self):\n",
    "        self.target = {}\n",
    "        ref_data = utils.open_json(self.ref_file)\n",
    "        for ins in ref_data:\n",
    "            self.target[ins['id']] = ins['em_pattern']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.files[index]\n",
    "        with open(file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        id_ = data['id']\n",
    "        embedding_ = data['embedding'][:self.n_context,:,:]\n",
    "        em_pattern_ = self.target[int(id_)][:self.n_context]\n",
    "        \n",
    "        return {\n",
    "            'id' : id_,\n",
    "            'embedding' : embedding_,\n",
    "            'em_pattern' : em_pattern_,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683e832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataset = DecoderSinlgeDataset(path_train, ref_train, n_context)\n",
    "dev_dataset = DecoderSinlgeDataset(path_dev, ref_dev, n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tq_train_dataset = DecoderSinlgeDataset(tq_path_train, tq_ref_train, n_context)\n",
    "# tq_dev_dataset = DecoderSinlgeDataset(tq_path_dev, tq_ref_dev, n_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363eeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dev_dataset.files))\n",
    "print(len(dev_dataset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73647c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset.files))\n",
    "print(len(train_dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d2077",
   "metadata": {},
   "source": [
    "### Testing OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(instance['id'])\n",
    "# print(len(instance['em_pattern']))\n",
    "# print(instance['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(0, 7000)):\n",
    "#     instance = train_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04008643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(instance['id']))\n",
    "# print(type(instance['embedding']))\n",
    "# print(type(instance['em_pattern']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f75e54",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_decoder(batch):\n",
    "    \n",
    "    # id_lst for later matching\n",
    "    # embedding -> turn into tensor\n",
    "    # em_pattern -> turn into tensor\n",
    "    id_lst = []\n",
    "    embeddings = []\n",
    "    em_patterns = []\n",
    "    for b in batch:\n",
    "        id_lst.append(b['id'])\n",
    "        embeddings.append(b['embedding'])\n",
    "        em_patterns.append(torch.tensor(list(map(float, map(int, b['em_pattern']))), dtype = torch.long))\n",
    "        \n",
    "    embeddings = torch.stack(embeddings)\n",
    "    em_patterns = torch.stack(em_patterns)\n",
    "    \n",
    "    return {\n",
    "        'ids' : id_lst,\n",
    "        'embeddings' : embeddings,\n",
    "        'em_patterns' : em_patterns\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe3776",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.per_device_train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c45f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                              collate_fn= custom_collate_decoder,\n",
    "                              batch_size=train_args.per_device_train_batch_size,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(dev_dataset,\n",
    "                              shuffle = False,\n",
    "                              collate_fn= custom_collate_decoder,\n",
    "                              batch_size=train_args.per_device_eval_batch_size,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8ebe9",
   "metadata": {},
   "source": [
    "## Testing OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2940e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     ids_ = batch['ids']\n",
    "#     print(ids_)\n",
    "#     print(batch['embeddings'].shape)\n",
    "#     print(batch['em_patterns'].shape)\n",
    "#     print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9fb77f",
   "metadata": {},
   "source": [
    "# Starts From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {\n",
    "#         \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#         \"weight_decay\": train_args.weight_decay,\n",
    "#     },\n",
    "#     {\n",
    "#         \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#         \"weight_decay\": 0.0,\n",
    "#     },\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.learning_rate)\n",
    "print(train_args.adam_beta1, train_args.adam_beta2)\n",
    "print(train_args.adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae14ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = model.configure_optimizers(weight_decay=1e-2, \n",
    "# learning_rate=1e-4, \n",
    "# betas=(0.9, 0.95), \n",
    "# device_type=device_type)\n",
    "\n",
    "# default config values designed to train a gpt2 (124M) on OpenWebText\n",
    "# adamw optimizer\n",
    "# learning_rate = 6e-4 # max learning rate\n",
    "# max_iters = 600000 # total number of training iterations\n",
    "# weight_decay = 1e-1\n",
    "# beta1 = 0.9\n",
    "# beta2 = 0.95\n",
    "# grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677068b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "optimizer = model.configure_optimizers(1e-1, 6e-4, (0.9, 0.95), device_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d84c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "#                               lr=train_args.learning_rate,\n",
    "#                               betas=(train_args.adam_beta1, train_args.adam_beta2),\n",
    "#                               eps=train_args.adam_epsilon,\n",
    "#                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6611e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1277e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.gradient_accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a77691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler and math around the number of training steps.\n",
    "overrode_max_train_steps = False\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / train_args.gradient_accumulation_steps)\n",
    "if train_args.max_train_steps is None:\n",
    "    train_args.max_train_steps = train_args.num_train_epochs * num_update_steps_per_epoch\n",
    "    overrode_max_train_steps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_update_steps_per_epoch)\n",
    "print(train_args.max_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfa7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.num_warmup_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.lr_scheduler_type)\n",
    "print(train_args.num_warmup_steps)\n",
    "print(train_args.max_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d598916",
   "metadata": {},
   "source": [
    "# need to figure out schedulerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler = get_scheduler(\n",
    "#     name=train_args.lr_scheduler_type,\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=train_args.num_warmup_steps,\n",
    "#     num_training_steps=train_args.max_train_steps,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e46e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "#     model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lst = []\n",
    "reference_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    print(batch.keys())\n",
    "    # list of integers\n",
    "    ids_ = batch['ids']\n",
    "    \n",
    "    # embeddings\n",
    "    embeddings = batch['embeddings'].to(device_type)\n",
    "    print(embeddings.shape)\n",
    "    \n",
    "    # empattern\n",
    "    empattern = batch['em_patterns'].to(device_type)\n",
    "    print(empattern.shape)\n",
    "    \n",
    "    logits, loss = model(embeddings, empattern)\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "    \n",
    "    prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "    reference_lst.extend(empattern.detach().cpu().tolist())\n",
    "    cnt += 1\n",
    "    if cnt == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e0ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4a60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_pos_reference_lst = [''.join([str(ref_) for ref_ in em]) for em in reference_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeaca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_pos_reference_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18085f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_pos_ref = []\n",
    "def_pos_pre = []\n",
    "\n",
    "\n",
    "def_neg_ref = []\n",
    "def_neg_pre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for em_str, ref, pred  in zip(def_pos_reference_lst, reference_lst, prediction_lst):\n",
    "    pos_ind_lst, neg_ind_lst = get_definite_pos_neg(em_str)\n",
    "    print(f'neg_ind_lst : {em_str}')\n",
    "    print(f'ref : {ref}')\n",
    "    print(f'pred : {pred}')\n",
    "    print(f'pos_ind_lst : {pos_ind_lst}')\n",
    "    print(f'neg_ind_lst : {neg_ind_lst}')\n",
    "    if pos_ind_lst:\n",
    "        for pos_ind in pos_ind_lst:\n",
    "            def_pos_ref.append(ref[pos_ind])\n",
    "            def_pos_pre.append(pred[pos_ind])\n",
    "    if neg_ind_lst:\n",
    "        for neg_ind in neg_ind_lst:\n",
    "            def_neg_ref.append(ref[neg_ind])\n",
    "            def_neg_pre.append(pred[neg_ind])\n",
    "    print(f'def_pos_ref : {def_pos_ref}')\n",
    "    print(f'def_pos_pre : {def_pos_pre}')\n",
    "    print(f'def_neg_ref : {def_neg_ref}')\n",
    "    print(f'def_neg_pre : {def_neg_pre}')\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19928cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(def_pos_ref)\n",
    "print(def_pos_pre)\n",
    "print(def_neg_ref)\n",
    "print(def_neg_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_def_pos = accuracy_score(def_pos_ref, def_pos_pre)\n",
    "precision_def_pos = precision_score(def_pos_ref, def_pos_pre)\n",
    "recall_def_pos = recall_score(def_pos_ref, def_pos_pre)\n",
    "f1_def_pos = f1_score(def_pos_ref, def_pos_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57377d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_def_pos)\n",
    "print(precision_def_pos) # -> not valid since reference is always 0\n",
    "print(recall_def_pos) # since references are all 1s, recall is important\n",
    "print(f1_def_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44072d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e87e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_neg_ref = list(map(lambda x: 0 if x == 1 else 1, def_neg_ref))\n",
    "def_neg_pre = list(map(lambda x: 0 if x == 1 else 1, def_neg_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(def_neg_ref)\n",
    "print(def_neg_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b46a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_def_neg = accuracy_score(def_neg_ref, def_neg_pre)\n",
    "precision_def_neg = precision_score(def_neg_ref, def_neg_pre)\n",
    "recall_def_neg = recall_score(def_neg_ref, def_neg_pre)\n",
    "f1_def_neg = f1_score(def_neg_ref, def_neg_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_def_neg)\n",
    "print(precision_def_neg) # -> not valid since reference is always 0\n",
    "print(recall_def_neg) # since references are all 1s, recall is important\n",
    "print(f1_def_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84a768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e1601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76e9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114188c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93a759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305fde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a27765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbfd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58929be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d83556",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_loss = loss.detach().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57461616",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss += cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a10ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5cc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f82d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# references = batch['em_patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d826875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a947103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predictions.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d108d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# references = batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, references = accelerator.gather((predictions, empattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [1,1,1,]\n",
    "references = [0,0,0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39780ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_f1.add_batch(\n",
    "                predictions=predictions,\n",
    "                references=references,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaaf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score = metric_f1.evaluate(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922a9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric_f1 = metric_f1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b806233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed1ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f5549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc699b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.to(torch.int32)\n",
    "references = references.to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0720330",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc.add_batch(\n",
    "    predictions=predictions,\n",
    "    references=empattern,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96679666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.dtype)\n",
    "print(references.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf737ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(references.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([0,1,1])\n",
    "test2 = torch.tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc.add_batch(predictions=test, references=test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([1,1,1])\n",
    "test2 = torch.tensor([1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5cb246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e81692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(predictions))\n",
    "print(type(references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa86987",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(references.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a04684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "782eabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERT_DICT = {\n",
    "    '4': 1,\n",
    "    '3': 0,\n",
    "    '2': 1,\n",
    "    '1': 0,\n",
    "    '0': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db8dd7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-136-402f313ca928&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-136-402f313ca928>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'4'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONVERT_DICT['4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1495b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a04aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            outputs = model(**batch)\n",
    "            if train_args.class_weights:\n",
    "                logits = outputs['logits']\n",
    "                criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean').cuda()\n",
    "                loss = criterion(logits, batch['labels'])\n",
    "            else:\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # We keep track of the loss at each epoch\n",
    "            if train_args.with_tracking:\n",
    "                cur_loss = loss.detach().float()\n",
    "                total_loss += cur_loss\n",
    "\n",
    "            loss = loss / train_args.gradient_accumulation_steps\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            if step % train_args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.update(1)\n",
    "                completed_steps += 1\n",
    "\n",
    "            if completed_steps % train_args.train_loss_steps == 0 and step % train_args.gradient_accumulation_steps == 0:\n",
    "                logger.info(f\"Train loss {cur_loss} at current step  {completed_steps}\")\n",
    "                train_loss_log = {\n",
    "                    \"train_loss\": cur_loss,\n",
    "                    \"step\": completed_steps,\n",
    "                }\n",
    "                if train_args.with_tracking:\n",
    "                    accelerator.log(\n",
    "                        train_loss_log,\n",
    "                        step=completed_steps,\n",
    "                    )\n",
    "\n",
    "            if isinstance(checkpointing_steps, int):\n",
    "                if completed_steps % checkpointing_steps == 0 and step % train_args.gradient_accumulation_steps == 0:\n",
    "                    output_dir = f\"step_{completed_steps}\"\n",
    "                    if train_args.output_dir is not None:\n",
    "                        output_dir = os.path.join(train_args.output_dir, output_dir)\n",
    "                        os.makedirs(output_dir, exist_ok=True)\n",
    "                    result_log, model_output_path = eval(model, eval_dataloader, accelerator, metric_acc,\n",
    "                         metric_pre, metric_re, metric_f1, train_args, epoch, completed_steps, output_dir, logger)\n",
    "                    accelerator.save_state(output_dir)\n",
    "\n",
    "                    key_best_metric = f'eval_{train_args.best_metric}'\n",
    "                    best_metric = result_log[key_best_metric]\n",
    "                    logger.info(f\"best_metric : {best_metric}\")\n",
    "                    heapq.heappush(model_heap, (best_metric, completed_steps, result_log, model_output_path))\n",
    "\n",
    "                    if len(model_heap) > train_args.save_max_limit:\n",
    "                        _, _, _ ,delete_path = heapq.heappop(model_heap)\n",
    "                        logger.info(f\"Deleting file for path : {delete_path}\")\n",
    "                        mydir = pathlib.Path(delete_path)\n",
    "                        shutil.rmtree(mydir)\n",
    "                    model.train()\n",
    "\n",
    "            if completed_steps >= train_args.max_train_steps:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7966d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03969a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b025b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ad735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3ae4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b14b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_update_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0df694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to recalculate our total training steps as the size of the training dataloader may have changed\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / train_args.gradient_accumulation_steps)\n",
    "if overrode_max_train_steps:\n",
    "    train_args.max_train_steps = train_args.num_train_epochs * num_update_steps_per_epoch\n",
    "# Afterwards we recalculate our number of training epochs\n",
    "train_args.num_train_epochs = math.ceil(train_args.max_train_steps / num_update_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8948d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.checkpointing_steps)\n",
    "train_args.checkpointing_steps = '1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointing_steps = train_args.checkpointing_steps\n",
    "if checkpointing_steps is not None and checkpointing_steps.isdigit():\n",
    "    checkpointing_steps = int(checkpointing_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe35d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_args.with_tracking:\n",
    "    experiment_config = vars(train_args)\n",
    "\n",
    "    accelerator.init_trackers(train_args.wandb_project, config=experiment_config,\n",
    "                              init_kwargs={\"wandb\": {\"name\": train_args.run_name}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b71c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "total_batch_size = train_args.per_device_train_batch_size * accelerator.num_processes * train_args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\"  Num Epochs = {train_args.num_train_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {train_args.per_device_train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {train_args.gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {train_args.max_train_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model_args, data_args, train_args\n",
    "train_dict = vars(train_args)\n",
    "logger.info(f\"  Saving training_args = {train_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, f\"train_args.json\"), \"w\") as f:\n",
    "    json.dump(train_dict, f)\n",
    "\n",
    "model_dict = vars(model_args)\n",
    "logger.info(f\"  Saving model_args = {model_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, f\"model_args.json\"), \"w\") as f:\n",
    "    json.dump(model_dict, f)\n",
    "\n",
    "data_dict = vars(data_args)\n",
    "logger.info(f\"  Saving data_args = {data_dict}\")\n",
    "with open(os.path.join(train_args.output_dir, f\"data_args.json\"), \"w\") as f:\n",
    "    json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(train_args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "starting_epoch = 0\n",
    "\n",
    "# Using heap for limiting number of saved models\n",
    "model_heap = []\n",
    "heapq.heapify(model_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, eval_dataloader, accelerator, metric_acc, metric_pre, metric_re, metric_f1, \n",
    "         train_args, epoch, steps, output_dir, logger):\n",
    "\n",
    "    eval_progress_bar = tqdm(range(len(eval_dataloader)), disable=not accelerator.is_local_main_process)\n",
    "\n",
    "    eval_loss = 0\n",
    "    model.eval()\n",
    "    samples_seen = 0\n",
    "    prediction_lst = []\n",
    "    reference_lst = []\n",
    "\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch['inputs'], batch['sequence_len'])\n",
    "            if train_args.class_weights:\n",
    "                criterion = torch.nn.CrossEntropyLoss(weight=class_weights, reduction='mean', ignore_index=-100).cuda()\n",
    "            else:\n",
    "                criterion = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda() \n",
    "            loss = criterion(logits.view(-1, logits.shape[-1]), batch['labels'].view(-1))\n",
    "        \n",
    "        if train_args.with_tracking:\n",
    "            eval_loss += loss.detach().float()\n",
    "\n",
    "        predictions = logits.argmax(dim=-1)\n",
    "        references = batch['labels']\n",
    "        \n",
    "        # Get mask for target values != padding index\n",
    "        nonpad_mask = references != train_args.padding\n",
    "        \n",
    "        # Slice out non-pad values\n",
    "        references = references[nonpad_mask]\n",
    "        predictions = predictions[nonpad_mask]\n",
    "        \n",
    "        predictions, references = accelerator.gather((predictions, references))\n",
    "        # If we are in a multiprocess environment, the last batch has duplicates\n",
    "        if accelerator.num_processes > 1:\n",
    "            if step == len(eval_dataloader) - 1:\n",
    "                predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "                references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            else:\n",
    "                samples_seen += references.shape[0]\n",
    "\n",
    "        metric_acc.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "        metric_pre.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "        metric_re.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "        metric_f1.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "        eval_progress_bar.update(1)\n",
    "        prediction_lst.extend(predictions.detach().cpu().tolist())\n",
    "        reference_lst.extend(references.detach().cpu().tolist())\n",
    "\n",
    "    eval_metric = metric_acc.compute()\n",
    "    eval_metric_pre = metric_pre.compute()\n",
    "    eval_metric_re = metric_re.compute()\n",
    "    eval_metric_f1 = metric_f1.compute()\n",
    "\n",
    "    logger.info(f\"Evaluation at Epoch : {epoch} Total Step : {steps}\")\n",
    "    logger.info(f\"Accuracy : {eval_metric['accuracy']} Precision : {eval_metric_pre['precision']}\")\n",
    "    logger.info(f\"Recall : {eval_metric_re['recall']} F1 : {eval_metric_f1['f1']}\")\n",
    "    logger.info(f\"Epoch : {epoch} Step : {steps}\")\n",
    "    logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "    result_log = {\n",
    "        \"eval_accuracy\": eval_metric['accuracy'],\n",
    "        \"eval_precision\": eval_metric_pre['precision'],\n",
    "        \"eval_recall\": eval_metric_re['recall'],\n",
    "        \"eval_f1\": eval_metric_f1['f1'],\n",
    "        \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "        \"epoch\": epoch,\n",
    "        \"step\": steps,\n",
    "    }\n",
    "\n",
    "    output_result_path = os.path.join(output_dir, f\"epoch{epoch}_steps{steps}_results.json\")\n",
    "    with open(output_result_path, \"w\") as f:\n",
    "        json.dump(result_log, f)\n",
    "\n",
    "    if train_args.with_tracking:\n",
    "        accelerator.log(\n",
    "            result_log,\n",
    "            step=steps,\n",
    "        )\n",
    "\n",
    "    ## Extra\n",
    "    prediction_np = np.array(prediction_lst)\n",
    "    reference_np = np.array(reference_lst)\n",
    "    y_actu = pd.Series(reference_np, name='Actual')\n",
    "    y_pred = pd.Series(prediction_np, name='Predicted')\n",
    "\n",
    "    reversey_pred = y_pred.map(lambda x: 0 if x == 1 else 1)\n",
    "    reversey_actu = y_actu.map(lambda x: 0 if x == 1 else 1)\n",
    "    rev_accuracy = accuracy_score(reversey_actu, reversey_pred)\n",
    "    rev_precision = precision_score(reversey_actu, reversey_pred)\n",
    "    rev_recall = recall_score(reversey_actu, reversey_pred)\n",
    "    rev_f1 = f1_score(reversey_actu, reversey_pred)\n",
    "\n",
    "    logger.info(f\"rev Evaluation at Epoch : {epoch} Total Step : {steps}\")\n",
    "    logger.info(f\"rev_Accuracy : {rev_accuracy} rev_Precision : {rev_precision}\")\n",
    "    logger.info(f\"rev_Recall : {rev_recall} rev_F1 : {rev_f1}\")\n",
    "    logger.info(f\"Epoch : {epoch} Step : {steps}\")\n",
    "    logger.info(f\"Eval_loss : {eval_loss.item() / len(eval_dataloader)}\")\n",
    "\n",
    "    result_rev_log = {\n",
    "        \"eval_rev_accuracy\": rev_accuracy,\n",
    "        \"eval_rev_precision\": rev_precision,\n",
    "        \"eval_rev_recall\": rev_recall,\n",
    "        \"eval_rev_f1\": rev_f1,\n",
    "        \"eval_loss\": eval_loss.item() / len(eval_dataloader),\n",
    "        \"epoch\": epoch,\n",
    "        \"step\": steps,\n",
    "    }\n",
    "\n",
    "    output_result_path = os.path.join(output_dir, f\"epoch{epoch}_steps{steps}_rev_results.json\")\n",
    "    with open(output_result_path, \"w\") as f:\n",
    "        json.dump(result_rev_log, f)\n",
    "\n",
    "    if train_args.with_tracking:\n",
    "        accelerator.log(\n",
    "            result_rev_log,\n",
    "            step=steps,\n",
    "        )\n",
    "\n",
    "    return result_log, output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0c0e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(starting_epoch, train_args.num_train_epochs):\n",
    "    model.train()\n",
    "    if train_args.with_tracking:\n",
    "        total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        logits = model(batch['inputs'], batch['sequence_len'])\n",
    "        \n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=-100).cuda() \n",
    "            \n",
    "        loss = criterion(logits.view(-1, logits.shape[-1]), batch['labels'].view(-1))\n",
    "\n",
    "        # We keep track of the loss at each epoch\n",
    "        if train_args.with_tracking:\n",
    "            cur_loss = loss.detach().float()\n",
    "            total_loss += cur_loss\n",
    "\n",
    "        loss = loss / train_args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        if step % train_args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps += 1\n",
    "\n",
    "        if completed_steps % train_args.train_loss_steps == 0 and step % train_args.gradient_accumulation_steps == 0:\n",
    "            logger.info(f\"Train loss {cur_loss} at current step  {completed_steps}\")\n",
    "            train_loss_log = {\n",
    "                \"train_loss\": cur_loss,\n",
    "                \"step\": completed_steps,\n",
    "            }\n",
    "            if train_args.with_tracking:\n",
    "                accelerator.log(\n",
    "                    train_loss_log,\n",
    "                    step=completed_steps,\n",
    "                )\n",
    "\n",
    "        if isinstance(checkpointing_steps, int):\n",
    "            if completed_steps % checkpointing_steps == 0 and step % train_args.gradient_accumulation_steps == 0:\n",
    "                output_dir = f\"step_{completed_steps}\"\n",
    "                if train_args.output_dir is not None:\n",
    "                    output_dir = os.path.join(train_args.output_dir, output_dir)\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                result_log, model_output_path = eval(model, eval_dataloader, accelerator, \n",
    "                                                     metric_acc, metric_pre, metric_re, metric_f1, \n",
    "                                                     train_args, epoch, completed_steps, output_dir, \n",
    "                                                     logger)\n",
    "                accelerator.save_state(output_dir)\n",
    "\n",
    "                key_best_metric = f'eval_{train_args.best_metric}'\n",
    "                best_metric = result_log[key_best_metric]\n",
    "                logger.info(f\"best_metric : {best_metric}\")\n",
    "                heapq.heappush(model_heap, (best_metric, completed_steps, result_log, model_output_path))\n",
    "\n",
    "                if len(model_heap) > train_args.save_max_limit:\n",
    "                    _, _, _ ,delete_path = heapq.heappop(model_heap)\n",
    "                    logger.info(f\"Deleting file for path : {delete_path}\")\n",
    "                    mydir = pathlib.Path(delete_path)\n",
    "                    shutil.rmtree(mydir)\n",
    "                model.train()\n",
    "\n",
    "        if completed_steps >= train_args.max_train_steps:\n",
    "            break\n",
    "    \n",
    "    output_dir = f\"epoch_{epoch}_step_{completed_steps}\"\n",
    "    if train_args.output_dir is not None:\n",
    "        output_dir = os.path.join(train_args.output_dir, output_dir)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    result_log, model_output_path = eval(model, eval_dataloader, accelerator, \n",
    "                                         metric_acc, metric_pre, metric_re, metric_f1, \n",
    "                                         train_args, epoch, completed_steps, output_dir, \n",
    "                                         logger)\n",
    "    accelerator.save_state(output_dir)\n",
    "\n",
    "    key_best_metric = f'eval_{train_args.best_metric}'\n",
    "    best_metric = result_log[key_best_metric]\n",
    "    logger.info(f\"best_metric : {best_metric}\")\n",
    "    heapq.heappush(model_heap, (best_metric, completed_steps, result_log, model_output_path))\n",
    "\n",
    "    if len(model_heap) > train_args.save_max_limit:\n",
    "        _, _, _ ,delete_path = heapq.heappop(model_heap)\n",
    "        logger.info(f\"Deleting file for path : {delete_path}\")\n",
    "        mydir = pathlib.Path(delete_path)\n",
    "        shutil.rmtree(mydir)\n",
    "            \n",
    "if train_args.with_tracking:\n",
    "    accelerator.end_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c1132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428f7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf81b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0f2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b2659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab9afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0927e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ed39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e125e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11528f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782523b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(vars(train_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42199a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41903e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f85ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e14c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e8162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb4027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc3f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdf488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f412c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a77035",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2a0d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer_grouped_parameters[0][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba674bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_type='linear'\n",
    "num_warmup_steps = 0\n",
    "# max_train_steps = \n",
    "num_train_epochs = 5\n",
    "gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81266a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8961a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "        name=lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=max_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d33b38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch_size = per_device_train_batch_size * accelerator.num_processes * gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c96172",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(max_train_steps), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b459680",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_epoch = 0\n",
    "with_tracking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897061",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointing_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(starting_epoch, num_train_epochs):\n",
    "    model.train()\n",
    "    if with_tracking:\n",
    "        total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        if with_tracking:\n",
    "            total_loss += loss.detach().float()\n",
    "            \n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        \n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps += 1\n",
    "            \n",
    "        if isinstance(checkpointing_steps, int):\n",
    "            if completed_steps % checkpointing_steps == 0:\n",
    "                output_dir = f\"step_{completed_steps }\"\n",
    "                if output_dir is not None:\n",
    "                    output_dir = os.path.join(args.output_dir, output_dir)\n",
    "                accelerator.save_state(output_dir)\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "                break\n",
    "                \n",
    "                \n",
    "    model.eval()\n",
    "    samples_seen = 0\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "         with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1) \n",
    "        predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n",
    "        \n",
    "        if accelerator.num_processes > 1:\n",
    "            if step == len(eval_dataloader) - 1:\n",
    "                predictions = predictions[: len(eval_dataloader.dataset) - samples_seen]\n",
    "                references = references[: len(eval_dataloader.dataset) - samples_seen]\n",
    "            else:\n",
    "                samples_seen += references.shape[0]\n",
    "        \n",
    "        metric.add_batch(\n",
    "                predictions=predictions,\n",
    "                references=references,\n",
    "            )\n",
    "        \n",
    "        eval_metric = metric.compute()\n",
    "        logger.info(f\"epoch {epoch}: {eval_metric}\")\n",
    "        \n",
    "        if args.with_tracking:\n",
    "            accelerator.log(\n",
    "                {\n",
    "                    \"accuracy\" : eval_metric,\n",
    "                    \"train_loss\": total_loss.item() / len(train_dataloader),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"step\": completed_steps,\n",
    "                },\n",
    "                step=completed_steps,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f588f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_pre = evaluate.load('precision')\n",
    "metric_re = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448447fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.num_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18636963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7522dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    ")\n",
    "args = [\"--model_name_or_path\", 'allenai/longformer-large-4096', '--output_dir', './']\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cccdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b309f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f31db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ebdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        num_labels=model_args.num_labels,\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    )\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df813504",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_args.do_train:\n",
    "    instances, cut_off, total_questions = preprocessing_data(\n",
    "        data_args.train_file, \n",
    "        data_args.sample_size, \n",
    "        data_args.position)\n",
    "    \n",
    "    train_instance = instances[data_args.dev_size:]\n",
    "    dev_instance = instances[:data_args.dev_size]\n",
    "    \n",
    "    train_dataset = CustomDataset(train_instance, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    dev_dataset = CustomDataset(train_instance, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    \n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "if training_args.do_eval:\n",
    "    instances, cut_off, total_questions = preprocessing_data(\n",
    "        data_args.test_file, \n",
    "        data_args.sample_size, \n",
    "        data_args.position)\n",
    "    \n",
    "    test_dataset = CustomDataset(instances, \n",
    "                               tokenizer, \n",
    "                               model_args.max_seq_length)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metric function\n",
    "metric = evaluate.load(\"xnli\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return metric.compute(predictions=preds, references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize Trainer\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer, \n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_train else None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=30)]\n",
    ")\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "    \n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "    max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7e951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fc78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df12bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.dataset_name = a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed523bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a498d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e978cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = HfArgumentParser(\n",
    "        (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "    )\n",
    "    \n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
