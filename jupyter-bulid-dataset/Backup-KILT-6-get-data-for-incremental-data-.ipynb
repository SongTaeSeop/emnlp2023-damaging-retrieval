{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86601ea",
   "metadata": {},
   "source": [
    "# KILT-6-get-data-for incremental test Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b5b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from util import utils\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f712c",
   "metadata": {},
   "source": [
    "## Get dataset for incremental Test\n",
    "- README.md method 2,3\n",
    "    - Method1 describes previous ranking system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744464e",
   "metadata": {},
   "source": [
    "## Definitions of Positive, Relevant, Damaging, Irrelevant  with respect to retriever (check out Meeting#3.ipynb)\n",
    "    - Previous Definition of relevant passages are vague.\n",
    "    - What is the definition of relevance?\n",
    "        - Passages are retrived from the step?\n",
    "    - Here we are going to dicuss the definition of each paradigm\n",
    "\n",
    "### Previous passages are divded into two categories with respect to query\n",
    "### Assumption \n",
    "    - higher the similarity score higher the the performance on downstream tasks\n",
    "        - similarity score has positive correlation with positive passage\n",
    "    - low similarity socre considered to be irrelevant degrades the output\n",
    "    - Therefore, retrieval is a process of extracting positive passage from the relevant set\n",
    "    - by shrinking the search space by top-k     \n",
    "####  1. Positive passages \n",
    "        : passages that include correct answer\n",
    "        : sometimes multiple passages are required\n",
    "#### 2. Relevant passages (Relevant set : R)\n",
    "        : passages have high possibilities in containing corret answer with repect to query/claim\n",
    "        : usually measured by similariy score\n",
    "#### 3. Irrelevant passages (Irrelevant set : I) \n",
    "        : passages have low probabilities in containing corret answer with repect to query/claim\n",
    "        : usually measured by similariy score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b120c5c",
   "metadata": {},
   "source": [
    "### New Definitions are now divided into three categories with respect to query\n",
    "\n",
    "### Assumption\n",
    "    - Previous works focus on the re-ranking of retrieved passages, which based on the assumption that taking top-k passages with higher similarity scores will show higher performance in the downstream tasks.\n",
    "    - ; however, we have been shown that among those retrieved passages with higher similarity scores actually downgrades the final output which could have been produce the correct answer without them.\n",
    "    - So those passages are what we called damaging passges that have to be removed not just re-ranked by its score.\n",
    "\n",
    "#### 1. Positive passages \n",
    "        : passages that produce correct inference on downstream task\n",
    "        : sometimes multiple passages are required\n",
    "        \n",
    "#### 2. Relevant passages = R1\n",
    "    : passages retrieved from query that does not present adversarial effect when previous inference is correct\n",
    "    : passages with high possibility inlucde corret answer with repect to query/claim\n",
    "    : usually measured by similariy score\n",
    "    : Subset of of R\n",
    "    \n",
    "#### 3. Damaging passages = D1\n",
    "    : passages retrieved from query that produce wrong output when preivous inference is correct\n",
    "    : passages with high possibility inlucde corret answer with repect to query/claim\n",
    "    : HOWEVER it degrades the inference output\n",
    "    : usually measured by similariy score\n",
    "    : Subset of of R\n",
    "    \n",
    "#### 4. Irrelevant passages\n",
    "    : passages retrieved from query that does not change the answer when previous inference is not corret\n",
    "    - Passages retrieved by retriever that have no impacts for inference\n",
    "    - usually measured by similariy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b45a1",
   "metadata": {},
   "source": [
    "## Incremental Testing Setting\n",
    "\n",
    "### 3 Method (Check out README.md)\n",
    "\n",
    "### Method 2 (2nd method of in README.md)\n",
    "    - The sooner, The better approach\n",
    "      - Keep the Positive Context in order\n",
    "    - Since we testing it, let's keep sample size of 5\n",
    "    - When there is no Exact Mathcing during the incremental inference e.g.) em_pattern = '00000'\n",
    "        - Keep the whole context so that those cases will have False on Exact Match values\n",
    "    \n",
    "    \n",
    "    - Two options : \n",
    "        - option1 : Remove Only damaging\n",
    "        - option2 : Remove damaging and irrelevant\n",
    "        \n",
    "    - Patterns: \n",
    "        - first 1 : positive\n",
    "        - first 0 : irrelevant \n",
    "            - we know that first is the positive context that includes answer\n",
    "            - with that perspective, it is relevant in theory\n",
    "            - ; however, dataset is created via BLEU score on two different corpus.\n",
    "            - If FiD does not correctly infer the output, \n",
    "            - context what we concieved of artificial positive context is actually irrelevant to the query.\n",
    "            - Also when realistic scenario, we don't know whether the first context contains the answer\n",
    "        - 01 pattern : Positive \n",
    "        - 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "        - 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "        - 10 pattern : Damaging\n",
    "        \n",
    "        - 11 pattern : relevant vs positive\n",
    "            Strict Positive\n",
    "                Under strict rule : consider it as relevant ?(or irrelevant?)\n",
    "                                in terms of strictly limiting the number of positive passages\n",
    "            Naive Positive\n",
    "                Under naive rule : consider it as positive\n",
    "                                in that this would increase the number of positive passages\n",
    "                \n",
    "        - A00 pattern : irrelevant vs damaging\n",
    "            if '1' does not occured in A, currnet passage is irrelevant\n",
    "            if '1' occurred in A, current passage is damaging either irrelevant \n",
    "                Strict Damaging\n",
    "                    Under strict rule : consider it as irrelevnat \n",
    "                                    in terms of strictly limiting the number of damaging passage\n",
    "                Naive Damaging\n",
    "                    Under naive rule : consider it as damaging \n",
    "                                    in that this would increase the number of damaging passages\n",
    "        \n",
    "    - Options1 : Removes only damaging\n",
    "    - Options2 : Removes damaging + irrelevant\n",
    "    - Options3 : Removes damaging + relevant\n",
    "    - Options4 : Removes damaging + irrelevant + relevnat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a4eb0",
   "metadata": {},
   "source": [
    "### Total Trials 16\n",
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging\n",
    "    6th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging\n",
    "    7th Trial - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging\n",
    "    8th Trial - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    9th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging\n",
    "    10th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging\n",
    "    11th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging\n",
    "    12th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    13th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging\n",
    "    14th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "    15th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "    16th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging\n",
    "        \n",
    "        \n",
    "    - Since Options4 removes  \"damaging + irrelevant + relevant\"\n",
    "        - there will be no difference between Strict Damaging and Naive Damaging\n",
    "\n",
    "    13, 14th Trial -> Options4(Removes damaging + irrelevant + relevant) + Strict Positive\n",
    "    15, 16th Trial -> Options4(Removes damaging + irrelevant + relevant) + Naive Positive\n",
    "    \n",
    "    - Since Options2 removes  \"damaging + irrelevant\"\n",
    "        - there will be no difference in terms of the input between Strict Damaging and Naive Damaging\n",
    "    5, 6th Trial -> Options2(Remove damaging + irrelevant) + Strict Positive -> new 5th\n",
    "    7, 8th Trial -> Options2(Remove damaging + irrelevant) + Naive Positive -> new 6th\n",
    "    - Since Options2 include both \"positive + relevant\"\n",
    "        - There will be no difference in terms of the input between Strict Positive and Naive Positive\n",
    "        - I found out during checking\n",
    "    new 5th, new 6th -> Options2(Remove damaging + irrelevant) \n",
    "    \n",
    "    - Options4(Removes damaging + irrelevant + relevant) + Strict Positive\n",
    "        - means one positive only thus same as \"pos1_ctx1\" -> nope there might be non-consecutives\n",
    "        - e.g.) 01011 -> 2 strict positive cases\n",
    "        - BUT \"pos1_ctx1\" = baseline could be our baselines\n",
    "    Options4(Removes damaging + irrelevant + relevant) + Strict Positive -> equal to \"pos1_ctx1\" \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1686d",
   "metadata": {},
   "source": [
    "    \n",
    "### Final Total Trials 11\n",
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging \n",
    "        - The one also represents other three cases\n",
    "            - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    6th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging\n",
    "    7th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging\n",
    "    8th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging\n",
    "    9th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    10th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "        - almost equal to \"pos1_ctx1\" e.g.) 01011 -> 2 strict positive cases\n",
    "        - \"pos1_ctx1\" = baseline could be our baselines\n",
    "        \n",
    "    11th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive    \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    \n",
    "### Estimation \n",
    "    - Since retrieved passages have high similarity score, retrieved passages are higly likely to form damaging \n",
    "    passages with repect to query. \n",
    "    - Minimizing the risk of exposing query to damaging passages would be favorabe to FiD\n",
    "    - The simplest way to reduce to the probability of such occurences is limiting the number of input passages\n",
    "\n",
    "    - I think below strategy will hold the best result \n",
    "        1) Options2(Remove damaging + irrelevant)\n",
    "            * As we saw from result from FiD result with Random Sampling, \n",
    "            * FiD is powerful distinguish the positive from irrelevants.\n",
    "            * Even though we loose stronger boundary that might be helpful to inference, \n",
    "            * It will be (frivolous/trivial/not consequential)\n",
    "        2) Strict Positive (relevant) \n",
    "            * Strict Positive puts a rigorous boundary for passages, meaning less positive passages\n",
    "        3) Naive Damaging(damaging) \n",
    "            * Unlike Strict Positive, we can set up a lenient standard for damaging to lessen the size of input. \n",
    "            * Increasing Damaging passages by definition results in decreasing number of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3305859",
   "metadata": {},
   "source": [
    "### Method2\n",
    "    - Same approach but in reciprocal order\n",
    "      - We know that FiD is order invariant but this is for checking \n",
    "      - don't need to test on whole trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3933d",
   "metadata": {},
   "source": [
    "# Input\n",
    "    - result from 5-1\n",
    "    - /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2e864",
   "metadata": {},
   "source": [
    "# 1st Trial\n",
    "    - Options1(Remove only Damaging) + Strict Positive + Strict Damaging\n",
    "    - Need to check FiD input when there are less ctxs than n_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2926bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = utils.open_json('/data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b33e7",
   "metadata": {},
   "source": [
    "### format\n",
    "```python\n",
    "{\n",
    "    'id' : str()\n",
    "    'answers' : list()\n",
    "    'ctxs' : list(dict)\n",
    "    'questions' : str()\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594cc4b",
   "metadata": {},
   "source": [
    "#### Test Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ee098",
   "metadata": {},
   "source": [
    "### Checking on Final Total Trials 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83095e97",
   "metadata": {},
   "source": [
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging (checked)\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging (checked)\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging (checked)\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging (checked)\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging (checked)\n",
    "        - The one also represents other three cases\n",
    "            - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging \n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging (checked)\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging \n",
    "    \n",
    "    6th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging (checked)\n",
    "    7th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging (checked)\n",
    "    8th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging (checked)\n",
    "    9th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging (checked)\n",
    "    \n",
    "    10th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive (checked)\n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging (checked)\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "        - almost equal to \"pos1_ctx1\" e.g.) 01011 -> 2 strict positive cases\n",
    "        - \"pos1_ctx1\" = baseline could be our baselines\n",
    "        \n",
    "    11th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive (checked)  \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging (checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51388434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # cnt_conv = 0\n",
    "# # empty_temp = {\n",
    "# #     'psg_id' : None,\n",
    "# #     'text' : None,\n",
    "# #     'title' : None\n",
    "# # }\n",
    "\n",
    "# output_format = []\n",
    "\n",
    "# # 'strict', 'naive'  \n",
    "# # i = 0\n",
    "# option_p = 'naive'\n",
    "# option_d = 'naive'\n",
    "# option = 'op4'\n",
    "\n",
    "# for instance in input_file:\n",
    "#     template_dict = {}\n",
    "#     template_dict['id'] = instance['id']\n",
    "#     template_dict['answers'] = instance['answers']\n",
    "#     template_dict['question'] = instance['question']\n",
    "#     template_dict['em_pattern'] = instance['em_pattern']\n",
    "                                   \n",
    "#     em_pattern = instance['em_pattern']\n",
    "    \n",
    "# #     i += 1\n",
    "# #     if i == 3000:\n",
    "# #         break\n",
    "#     print(f'em_pattern : {em_pattern}')\n",
    "#     # when there is at least one EM in the accumulated inference\n",
    "#     if em_pattern != '00000':   \n",
    "#         new_ctx = []\n",
    "        \n",
    "#         # relevant vs positive\n",
    "#         positve_ctx_lst = []\n",
    "#         relevant_ctx_lst = []\n",
    "        \n",
    "#         # irrelevant vs damaging\n",
    "#         damaging_ctx_lst = []\n",
    "#         irrelevant_ctx_lst = []\n",
    "        \n",
    "#         # print\n",
    "#         # matchint each em to ctx\n",
    "#         for ind_em, ctx in zip(em_pattern, instance['ctxs']):\n",
    "#             print(f'{ind_em} : \\t {ctx}')\n",
    "        \n",
    "#         for idx_, ctx in enumerate(instance['ctxs']):\n",
    "            \n",
    "#             # checking current em\n",
    "#             cur_em = em_pattern[idx_]\n",
    "#             pre_em_pattern = em_pattern[:idx_]\n",
    "# #             print('-----------')\n",
    "# #             print(f'em_pattern : {em_pattern}')\n",
    "# #             print(f'idx_ : {idx_}')\n",
    "# #             print(f'cur_em : {cur_em}')\n",
    "# #             print(f'pre_em_pattern : {pre_em_pattern}')\n",
    "# #             print(f'not pre_em_pattern : {not pre_em_pattern}')\n",
    "# #             print('-----------')\n",
    "            \n",
    "#             # first 1 : positive\n",
    "#             if not pre_em_pattern and cur_em == '1':\n",
    "#                 positve_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'1 first positive ctx : ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # first 0 : irrelevant\n",
    "#             elif not pre_em_pattern and cur_em == '0':\n",
    "#                 irrelevant_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'0 first irrelevant ctx : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 01 pattern : positive \n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '1':\n",
    "#                 positve_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'01 pattern : positive  : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 10 pattern : damaging\n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '0':\n",
    "#                 damaging_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'10 pattern : damaging : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '1':\n",
    "#                 if option_p == 'strict':\n",
    "#                     relevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'11 pattern : strict : relevant \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "                \n",
    "#                 elif option_p == 'naive':\n",
    "#                     positve_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'11 pattern : naive : positive \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "#                     break\n",
    "                    \n",
    "#             # 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '0':\n",
    "#                 # if '1' does not occured in A, currnet passage is irrelevant\n",
    "#                 if not '1' in pre_em_pattern:\n",
    "#                     irrelevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'00 pattern : 1 does not exist : irrelevant_ctx_lst \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "#                 # if '1' occurred in A, \n",
    "#                 else:\n",
    "#                     # strict : consider it as irrelevnat \n",
    "#                     if option_d == 'strict':\n",
    "#                         irrelevant_ctx_lst.append(ctx)\n",
    "#                         # print\n",
    "#                         print('-----------')\n",
    "#                         print(f'em_pattern : {em_pattern}')\n",
    "#                         print(f'idx_ : {idx_}')\n",
    "#                         print(f'cur_em : {cur_em}')\n",
    "#                         print(f'00 pattern : 1 exists : strict :irrelevant_ctx_lst \\t ')\n",
    "#                         pprint(ctx)\n",
    "#                         print('-----------')\n",
    "#                     # naive : consider it as damaging \n",
    "#                     elif option_d == 'naive':\n",
    "#                         damaging_ctx_lst.append(ctx)\n",
    "#                         # print\n",
    "#                         print('-----------')\n",
    "#                         print(f'em_pattern : {em_pattern}')\n",
    "#                         print(f'idx_ : {idx_}')\n",
    "#                         print(f'cur_em : {cur_em}')\n",
    "#                         print(f'00 pattern : 1 exists : naive :damaging_ctx_lst \\t ')\n",
    "#                         pprint(ctx)\n",
    "#                         print('-----------')\n",
    "#                     else:\n",
    "#                         print('option_d should be either \\'strict\\' or \\'naive\\'')\n",
    "#                         break\n",
    "                    \n",
    "#         # op1 removes damages only\n",
    "#         if option == 'op1':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(relevant_ctx_lst)\n",
    "#             new_ctx.extend(irrelevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes damages only')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op2 removes damaging + irrelevant\n",
    "#         elif option == 'op2':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(relevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + irrelevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'irrelevant')\n",
    "#             pprint(irrelevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op3 : Removes damaging + relevant\n",
    "#         elif option == 'op3':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(irrelevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + relevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'relevant_ctx_lst')\n",
    "#             pprint(relevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op4 : Removes damaging + irrelevant + relevant\n",
    "#         elif option == 'op4':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + irrelevant + relevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'irrelevant')\n",
    "#             pprint(irrelevant_ctx_lst)\n",
    "#             print(f'relevant_ctx_lst')\n",
    "#             pprint(relevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         else:\n",
    "#             print('option should be op1, op2, op3, op4')\n",
    "#             break\n",
    "        \n",
    "#         template_dict['ctxs'] = new_ctx\n",
    "#         output_format.append(template_dict)\n",
    "        \n",
    "#     # when there is no EM in the accumulated inference\n",
    "#     else:\n",
    "#         print(f'em_pattern == 00000')\n",
    "#         template_dict['ctxs']= instance['ctxs']\n",
    "#         output_format.append(template_dict)\n",
    "        \n",
    "    \n",
    "#     print('==============instance finished======================')\n",
    "# #         template_dict['ctxs']= new_ctx\n",
    "# #         output_format.append(template_dict)\n",
    "        \n",
    "# #     else:\n",
    "# #         template_dict['ctxs']= instance['ctxs']\n",
    "# #         output_format.append(template_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff2f1b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa293b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403cb45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16433262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trial1(input_file):\n",
    "    i = 0\n",
    "    cnt_conv = 0\n",
    "    output_format = []\n",
    "#     empty_temp = {\n",
    "#         'psg_id' : None,\n",
    "#         'text' : None,\n",
    "#         'title' : None\n",
    "#     }\n",
    "\n",
    "    for instance in input_file:\n",
    "        template_dict = {}\n",
    "        template_dict['id'] = instance['id']\n",
    "        template_dict['answers'] = instance['answers']\n",
    "        template_dict['question'] = instance['question']\n",
    "        template_dict['em_pattern'] = instance['em_pattern']\n",
    "\n",
    "        em_pattern = instance['em_pattern']\n",
    "\n",
    "        # Only doing this when there is answer in incremental setting\n",
    "        if em_pattern != '00000':   \n",
    "            new_ctx = []\n",
    "\n",
    "    #         print(f'em_pattern : {em_pattern}')\n",
    "    #         pprint(instance['ctxs'])\n",
    "            flag = 0\n",
    "            for idx_, ctx in enumerate(instance['ctxs']):\n",
    "\n",
    "                cur_em = em_pattern[idx_]\n",
    "                if idx_ > 0:\n",
    "                    pre_em = em_pattern[idx_-1]\n",
    "\n",
    "    #             if idx_ == 0:\n",
    "    #                 print(f'cur_em : {cur_em}')\n",
    "    #                 print('----')\n",
    "\n",
    "\n",
    "    #                 print(f'pre_em : {pre_em}')\n",
    "    #                 print(f'cur_em : {cur_em}')\n",
    "    #                 print('-----')\n",
    "    #             print(idx_ > 0 and cur_em == '0' and pre_em == '1')\n",
    "\n",
    "                # first 1 : positive\n",
    "                if idx_ == 0 and cur_em == '1':\n",
    "                    new_ctx.append(ctx)\n",
    "\n",
    "                # first 0 : irrelevant\n",
    "                elif idx_ == 0 and cur_em == '0':\n",
    "                    new_ctx.append(ctx)\n",
    "\n",
    "                # 01 pattern : positive \n",
    "                elif idx_ > 0 and pre_em == '0' and cur_em == '1':\n",
    "                    new_ctx.append(ctx)\n",
    "\n",
    "                # 11 pattern : irrelevant or positive \n",
    "                elif idx_ > 0 and pre_em == '1' and cur_em == '1':\n",
    "                    new_ctx.append(ctx)\n",
    "\n",
    "                # 00 pattern : irrelevant \n",
    "                elif idx_ > 0 and pre_em == '1' and cur_em == '0':\n",
    "                    new_ctx.append(ctx)\n",
    "\n",
    "                # 10 pattern : damaging\n",
    "                elif idx_ > 0 and pre_em == '1' and cur_em == '0':\n",
    "#                     new_ctx.append(empty_temp)\n",
    "                    flag = 1\n",
    "                    cnt_conv += 1\n",
    "\n",
    "            template_dict['ctxs']= new_ctx\n",
    "            output_format.append(template_dict)\n",
    "\n",
    "        else:\n",
    "            template_dict['ctxs']= instance['ctxs']\n",
    "            output_format.append(template_dict)\n",
    "    return output_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f447ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_1_instance = build_trial1(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391aa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(output_format[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/data/philhoon-relevance/FiD/open_domain_data/NQ_KILT_INCRE_TEST/M2_1st_RM_DAMAGING_ONLY/KILT_NQ_DEV_INCRE_TEST.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2189d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_json(output_format, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc1d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
