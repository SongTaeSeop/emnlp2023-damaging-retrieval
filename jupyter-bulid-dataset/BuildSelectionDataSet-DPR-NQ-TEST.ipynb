{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86601ea",
   "metadata": {},
   "source": [
    "# BuildSelectionDataSet-DPR-NQ-TEST\n",
    " - Making selection dataset from incremental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b5b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from util import utils\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f712c",
   "metadata": {},
   "source": [
    "## Get dataset for incremental Test\n",
    "- README.md method 2,3\n",
    "    - Method1 describes previous ranking system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744464e",
   "metadata": {},
   "source": [
    "## Definitions of Positive, Relevant, Damaging, Irrelevant  with respect to retriever (check out Meeting#3.ipynb)\n",
    "    - Previous Definition of relevant passages are vague.\n",
    "    - What is the definition of relevance?\n",
    "        - Passages are retrived from the step?\n",
    "    - Here we are going to dicuss the definition of each paradigm\n",
    "\n",
    "### Previous passages are divded into two categories with respect to query\n",
    "### Assumption \n",
    "    - higher the similarity score higher the the performance on downstream tasks\n",
    "        - similarity score has positive correlation with positive passage\n",
    "    - low similarity socre considered to be irrelevant degrades the output\n",
    "    - Therefore, retrieval is a process of extracting positive passage from the relevant set\n",
    "    - by shrinking the search space by top-k     \n",
    "####  1. Positive passages \n",
    "        : passages that include correct answer\n",
    "        : sometimes multiple passages are required\n",
    "#### 2. Relevant passages (Relevant set : R)\n",
    "        : passages have high possibilities in containing corret answer with repect to query/claim\n",
    "        : usually measured by similariy score\n",
    "#### 3. Irrelevant passages (Irrelevant set : I) \n",
    "        : passages have low probabilities in containing corret answer with repect to query/claim\n",
    "        : usually measured by similariy score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b120c5c",
   "metadata": {},
   "source": [
    "### New Definitions are now divided into three categories with respect to query\n",
    "\n",
    "### Assumption\n",
    "    - Previous works focus on the re-ranking of retrieved passages, which based on the assumption that taking top-k passages with higher similarity scores will show higher performance in the downstream tasks.\n",
    "    - ; however, we have been shown that among those retrieved passages with higher similarity scores actually downgrades the final output which could have been produce the correct answer without them.\n",
    "    - So those passages are what we called damaging passges that have to be removed not just re-ranked by its score.\n",
    "\n",
    "#### 1. Positive passages \n",
    "        : passages that produce correct inference on downstream task\n",
    "        : sometimes multiple passages are required\n",
    "        \n",
    "#### 2. Relevant passages = R1\n",
    "    : passages retrieved from query that does not present adversarial effect when previous inference is correct\n",
    "    : passages with high possibility inlucde corret answer with repect to query/claim\n",
    "    : usually measured by similariy score\n",
    "    : Subset of of R\n",
    "    \n",
    "#### 3. Damaging passages = D1\n",
    "    : passages retrieved from query that produce wrong output when preivous inference is correct\n",
    "    : passages with high possibility inlucde corret answer with repect to query/claim\n",
    "    : HOWEVER it degrades the inference output\n",
    "    : usually measured by similariy score\n",
    "    : Subset of of R\n",
    "    \n",
    "#### 4. Irrelevant passages\n",
    "    : passages retrieved from query that does not change the answer when previous inference is not correct\n",
    "    : when there is preivous inference result and current output is not correct, we call it irrelevant\n",
    "    - Passages retrieved by retriever that have no impacts for inference\n",
    "    - usually measured by similariy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b45a1",
   "metadata": {},
   "source": [
    "## Incremental Testing Setting\n",
    "\n",
    "### 3 Method (Check out README.md)\n",
    "\n",
    "### Method 2 (2nd method of in README.md)\n",
    "    - The sooner, The better approach\n",
    "      - Keep the Positive Context in order\n",
    "    - Since we testing it, let's keep sample size of 5\n",
    "    - When there is no Exact Mathcing during the incremental inference e.g.) em_pattern = '00000'\n",
    "        - Keep the whole context so that those cases will have False on Exact Match values\n",
    "        \n",
    "    - Patterns: \n",
    "        - first 1 : positive\n",
    "        - first 0 : irrelevant \n",
    "            - we know that first is the positive context that includes answer\n",
    "            - with that perspective, it is relevant in theory\n",
    "            - ; however, dataset is created via BLEU score on two different corpus.\n",
    "            - If FiD does not correctly infer the output, \n",
    "            - context what we concieved of artificial positive context is actually irrelevant to the query.\n",
    "            - Also when realistic scenario, we don't know whether the first context contains the answer\n",
    "        - 01 pattern : Positive \n",
    "        - 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "        - 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "        - 10 pattern : Damaging\n",
    "        \n",
    "        - 11 pattern : relevant vs positive\n",
    "            Strict Positive\n",
    "                Under strict rule : consider it as relevant ?(or irrelevant?)\n",
    "                                in terms of strictly limiting the number of positive passages\n",
    "            Naive Positive\n",
    "                Under naive rule : consider it as positive\n",
    "                                in that this would increase the number of positive passages\n",
    "                \n",
    "        - A00 pattern : irrelevant vs damaging\n",
    "            if '1' does not occured in A, currnet passage is irrelevant\n",
    "            if '1' occurred in A, current passage is damaging either irrelevant \n",
    "                Strict Damaging\n",
    "                    Under strict rule : consider it as irrelevnat \n",
    "                                    in terms of strictly limiting the number of damaging passage\n",
    "                Naive Damaging\n",
    "                    Under naive rule : consider it as damaging \n",
    "                                    in that this would increase the number of damaging passages\n",
    "        \n",
    "    - Options1 : Removes only damaging\n",
    "    - Options2 : Removes damaging + irrelevant\n",
    "    - Options3 : Removes damaging + relevant\n",
    "    - Options4 : Removes damaging + irrelevant + relevnat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c4818",
   "metadata": {},
   "source": [
    "### Total Trials 16\n",
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging\n",
    "    6th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging\n",
    "    7th Trial - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging\n",
    "    8th Trial - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    9th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging\n",
    "    10th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging\n",
    "    11th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging\n",
    "    12th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    13th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging\n",
    "    14th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "    15th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "    16th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging\n",
    "        \n",
    "        \n",
    "    - Since Options4 removes  \"damaging + irrelevant + relevant\"\n",
    "        - there will be no difference between Strict Damaging and Naive Damaging\n",
    "\n",
    "    13, 14th Trial -> Options4(Removes damaging + irrelevant + relevant) + Strict Positive\n",
    "    15, 16th Trial -> Options4(Removes damaging + irrelevant + relevant) + Naive Positive\n",
    "    \n",
    "    - Since Options2 removes  \"damaging + irrelevant\"\n",
    "        - there will be no difference in terms of the input between Strict Damaging and Naive Damaging\n",
    "    5, 6th Trial -> Options2(Remove damaging + irrelevant) + Strict Positive -> new 5th\n",
    "    7, 8th Trial -> Options2(Remove damaging + irrelevant) + Naive Positive -> new 6th\n",
    "    - Since Options2 include both \"positive + relevant\"\n",
    "        - There will be no difference in terms of the input between Strict Positive and Naive Positive\n",
    "        - I found out during checking\n",
    "    new 5th, new 6th -> Options2(Remove damaging + irrelevant) \n",
    "    \n",
    "    - Options4(Removes damaging + irrelevant + relevant) + Strict Positive\n",
    "        - means one positive only thus same as \"pos1_ctx1\" -> nope there might be non-consecutives\n",
    "        - e.g.) 01011 -> 2 strict positive cases\n",
    "        - BUT \"pos1_ctx1\" = baseline could be our baselines\n",
    "    Options4(Removes damaging + irrelevant + relevant) + Strict Positive -> equal to \"pos1_ctx1\" \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1686d",
   "metadata": {},
   "source": [
    "    \n",
    "### Final Total Trials 11\n",
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging \n",
    "        - The one also represents other three cases\n",
    "            - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    6th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging\n",
    "    7th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging\n",
    "    8th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging\n",
    "    9th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    10th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "        - almost equal to \"pos1_ctx1\" e.g.) 01011 -> 2 strict positive cases\n",
    "        - \"pos1_ctx1\" = baseline could be our baselines\n",
    "        \n",
    "    11th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive    \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging\n",
    "    \n",
    "    \n",
    "### Estimation \n",
    "    - Since retrieved passages have high similarity score, retrieved passages are higly likely to form damaging \n",
    "    passages with repect to query. \n",
    "    - Minimizing the risk of exposing query to damaging passages would be favorabe to FiD\n",
    "    - The simplest way to reduce to the probability of such occurences is limiting the number of input passages\n",
    "\n",
    "    - I think below strategy will hold the best result \n",
    "        1) Options2(Remove damaging + irrelevant)\n",
    "            * As we saw from result from FiD result with Random Sampling, \n",
    "            * FiD is powerful distinguish the positive from irrelevants.\n",
    "            * Even though we loose stronger boundary that might be helpful to inference, \n",
    "            * It will be (frivolous/trivial/not consequential)\n",
    "        2) Strict Positive (relevant) \n",
    "            * Strict Positive puts a rigorous boundary for passages, meaning less positive passages\n",
    "        3) Naive Damaging(damaging) \n",
    "            * Unlike Strict Positive, we can set up a lenient standard for damaging to lessen the size of input. \n",
    "            * Increasing Damaging passages by definition results in decreasing number of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3305859",
   "metadata": {},
   "source": [
    "### Method2\n",
    "    - Same approach but in reciprocal order\n",
    "      - We know that FiD is order invariant but this is for checking \n",
    "      - don't need to test on whole trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3933d",
   "metadata": {},
   "source": [
    "# Input\n",
    "    - result from 5-1\n",
    "    - /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2e864",
   "metadata": {},
   "source": [
    "# Trials\n",
    "    - Need to check FiD input when there are less ctxs than n_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c756692",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "input_file = f'/data/philhoon-relevance/FiD/results/NQ_DPR/TEST/incremental_result_100/ctx{sample_size}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2926bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = utils.open_json('/data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b33e7",
   "metadata": {},
   "source": [
    "### format\n",
    "```python\n",
    "{\n",
    "    'id' : str()\n",
    "    'answers' : list()\n",
    "    'ctxs' : list(dict)\n",
    "    'questions' : str()\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594cc4b",
   "metadata": {},
   "source": [
    "#### Test Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d4384",
   "metadata": {},
   "source": [
    "### Checking on Final Total Trials 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83095e97",
   "metadata": {},
   "source": [
    "    1st Trial - Options1(Remove only Damaging) + Strict Positive + Strict Damaging (checked)\n",
    "    2nd Trial - Options1(Remove only Damaging) + Strict Positive + Naive Damaging (checked)\n",
    "    3rd Trial - Options1(Remove only Damaging) + Naive Positive + Strict Damaging (checked)\n",
    "    4th Trial - Options1(Remove only Damaging) + Naive Positive + Naive Damaging (checked)\n",
    "    \n",
    "    5th Trial - Options2(Remove damaging + irrelevant) + Strict Positive + Strict Damaging (checked)\n",
    "        - The one also represents other three cases\n",
    "            - Options2(Remove damaging + irrelevant) + Strict Positive + Naive Damaging \n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Strict Damaging (checked)\n",
    "            - Options2(Remove damaging + irrelevant) + Naive Positive + Naive Damaging \n",
    "    \n",
    "    6th Trial - Options3(Removes damaging + relevant) + Strict Positive + Strict Damaging (checked)\n",
    "    7th Trial - Options3(Removes damaging + relevant) + Strict Positive + Naive Damaging (checked)\n",
    "    8th Trial - Options3(Removes damaging + relevant) + Naive Positive + Strict Damaging (checked)\n",
    "    9th Trial - Options3(Removes damaging + relevant) + Naive Positive + Naive Damaging (checked)\n",
    "    \n",
    "    10th Trial - Options4(Removes damaging + irrelevant + relevant) + Strict Positive (checked)\n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Strict Damaging (checked)\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Strict Positive + Naive Damaging\n",
    "        - almost equal to \"pos1_ctx1\" e.g.) 01011 -> 2 strict positive cases\n",
    "        - \"pos1_ctx1\" = baseline could be our baselines\n",
    "        \n",
    "    11th Trial - Options4(Removes damaging + irrelevant + relevant) + Naive Positive (checked)  \n",
    "        - The one represents cases \n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Strict Damaging\n",
    "            - Options4(Removes damaging + irrelevant + relevant) + Naive Positive + Naive Damaging (checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be52cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # cnt_conv = 0\n",
    "# # empty_temp = {\n",
    "# #     'psg_id' : None,\n",
    "# #     'text' : None,\n",
    "# #     'title' : None\n",
    "# # }\n",
    "\n",
    "# output_format = []\n",
    "\n",
    "# # 'strict', 'naive'  \n",
    "# # i = 0\n",
    "# option_p = 'naive'\n",
    "# option_d = 'naive'\n",
    "# option = 'op4'\n",
    "\n",
    "# for instance in input_file:\n",
    "#     template_dict = {}\n",
    "#     template_dict['id'] = instance['id']\n",
    "#     template_dict['answers'] = instance['answers']\n",
    "#     template_dict['question'] = instance['question']\n",
    "#     template_dict['em_pattern'] = instance['em_pattern']\n",
    "                                   \n",
    "#     em_pattern = instance['em_pattern']\n",
    "    \n",
    "# #     i += 1\n",
    "# #     if i == 3000:\n",
    "# #         break\n",
    "#     print(f'em_pattern : {em_pattern}')\n",
    "#     # when there is at least one EM in the accumulated inference\n",
    "#     if em_pattern != '00000':   \n",
    "#         new_ctx = []\n",
    "        \n",
    "#         # relevant vs positive\n",
    "#         positve_ctx_lst = []\n",
    "#         relevant_ctx_lst = []\n",
    "        \n",
    "#         # irrelevant vs damaging\n",
    "#         damaging_ctx_lst = []\n",
    "#         irrelevant_ctx_lst = []\n",
    "        \n",
    "#         # print\n",
    "#         # matchint each em to ctx\n",
    "#         for ind_em, ctx in zip(em_pattern, instance['ctxs']):\n",
    "#             print(f'{ind_em} : \\t {ctx}')\n",
    "        \n",
    "#         for idx_, ctx in enumerate(instance['ctxs']):\n",
    "            \n",
    "#             # checking current em\n",
    "#             cur_em = em_pattern[idx_]\n",
    "#             pre_em_pattern = em_pattern[:idx_]\n",
    "# #             print('-----------')\n",
    "# #             print(f'em_pattern : {em_pattern}')\n",
    "# #             print(f'idx_ : {idx_}')\n",
    "# #             print(f'cur_em : {cur_em}')\n",
    "# #             print(f'pre_em_pattern : {pre_em_pattern}')\n",
    "# #             print(f'not pre_em_pattern : {not pre_em_pattern}')\n",
    "# #             print('-----------')\n",
    "            \n",
    "#             # first 1 : positive\n",
    "#             if not pre_em_pattern and cur_em == '1':\n",
    "#                 positve_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'1 first positive ctx : ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # first 0 : irrelevant\n",
    "#             elif not pre_em_pattern and cur_em == '0':\n",
    "#                 irrelevant_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'0 first irrelevant ctx : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 01 pattern : positive \n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '1':\n",
    "#                 positve_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'01 pattern : positive  : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 10 pattern : damaging\n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '0':\n",
    "#                 damaging_ctx_lst.append(ctx)\n",
    "                \n",
    "#                 # print\n",
    "#                 print('-----------')\n",
    "#                 print(f'em_pattern : {em_pattern}')\n",
    "#                 print(f'idx_ : {idx_}')\n",
    "#                 print(f'cur_em : {cur_em}')\n",
    "#                 print(f'10 pattern : damaging : \\t ')\n",
    "#                 pprint(ctx)\n",
    "#                 print('-----------')\n",
    "                \n",
    "#             # 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '1':\n",
    "#                 if option_p == 'strict':\n",
    "#                     relevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'11 pattern : strict : relevant \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "                \n",
    "#                 elif option_p == 'naive':\n",
    "#                     positve_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'11 pattern : naive : positive \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "                    \n",
    "#                 else:\n",
    "#                     print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "#                     break\n",
    "                    \n",
    "#             # 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "#             elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '0':\n",
    "#                 # if '1' does not occured in A, currnet passage is irrelevant\n",
    "#                 if not '1' in pre_em_pattern:\n",
    "#                     irrelevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "#                     # print\n",
    "#                     print('-----------')\n",
    "#                     print(f'em_pattern : {em_pattern}')\n",
    "#                     print(f'idx_ : {idx_}')\n",
    "#                     print(f'cur_em : {cur_em}')\n",
    "#                     print(f'00 pattern : 1 does not exist : irrelevant_ctx_lst \\t ')\n",
    "#                     pprint(ctx)\n",
    "#                     print('-----------')\n",
    "#                 # if '1' occurred in A, \n",
    "#                 else:\n",
    "#                     # strict : consider it as irrelevnat \n",
    "#                     if option_d == 'strict':\n",
    "#                         irrelevant_ctx_lst.append(ctx)\n",
    "#                         # print\n",
    "#                         print('-----------')\n",
    "#                         print(f'em_pattern : {em_pattern}')\n",
    "#                         print(f'idx_ : {idx_}')\n",
    "#                         print(f'cur_em : {cur_em}')\n",
    "#                         print(f'00 pattern : 1 exists : strict :irrelevant_ctx_lst \\t ')\n",
    "#                         pprint(ctx)\n",
    "#                         print('-----------')\n",
    "#                     # naive : consider it as damaging \n",
    "#                     elif option_d == 'naive':\n",
    "#                         damaging_ctx_lst.append(ctx)\n",
    "#                         # print\n",
    "#                         print('-----------')\n",
    "#                         print(f'em_pattern : {em_pattern}')\n",
    "#                         print(f'idx_ : {idx_}')\n",
    "#                         print(f'cur_em : {cur_em}')\n",
    "#                         print(f'00 pattern : 1 exists : naive :damaging_ctx_lst \\t ')\n",
    "#                         pprint(ctx)\n",
    "#                         print('-----------')\n",
    "#                     else:\n",
    "#                         print('option_d should be either \\'strict\\' or \\'naive\\'')\n",
    "#                         break\n",
    "                    \n",
    "#         # op1 removes damages only\n",
    "#         if option == 'op1':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(relevant_ctx_lst)\n",
    "#             new_ctx.extend(irrelevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes damages only')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op2 removes damaging + irrelevant\n",
    "#         elif option == 'op2':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(relevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + irrelevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'irrelevant')\n",
    "#             pprint(irrelevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op3 : Removes damaging + relevant\n",
    "#         elif option == 'op3':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "#             new_ctx.extend(irrelevant_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + relevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'relevant_ctx_lst')\n",
    "#             pprint(relevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         # op4 : Removes damaging + irrelevant + relevant\n",
    "#         elif option == 'op4':\n",
    "#             new_ctx.extend(positve_ctx_lst)\n",
    "            \n",
    "#             print(f'option : {option}')\n",
    "#             print(f'removes removes damaging + irrelevant + relevant')\n",
    "#             print(f'damages')\n",
    "#             pprint(damaging_ctx_lst)\n",
    "#             print(f'irrelevant')\n",
    "#             pprint(irrelevant_ctx_lst)\n",
    "#             print(f'relevant_ctx_lst')\n",
    "#             pprint(relevant_ctx_lst)\n",
    "#             print(f'rest_ctx')\n",
    "#             pprint(new_ctx)\n",
    "            \n",
    "#         else:\n",
    "#             print('option should be op1, op2, op3, op4')\n",
    "#             break\n",
    "        \n",
    "#         template_dict['ctxs'] = new_ctx\n",
    "#         output_format.append(template_dict)\n",
    "        \n",
    "#     # when there is no EM in the accumulated inference\n",
    "#     else:\n",
    "#         print(f'em_pattern == 00000')\n",
    "#         template_dict['ctxs']= instance['ctxs']\n",
    "#         output_format.append(template_dict)\n",
    "        \n",
    "    \n",
    "#     print('==============instance finished======================')\n",
    "# #         template_dict['ctxs']= new_ctx\n",
    "# #         output_format.append(template_dict)\n",
    "        \n",
    "# #     else:\n",
    "# #         template_dict['ctxs']= instance['ctxs']\n",
    "# #         output_format.append(template_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a294aa",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa293b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(input_file, option, option_p, option_d, sample_size):\n",
    "    '''\n",
    "    input_file : incremental inference result from FiD from KILT-5-1\n",
    "        path : /data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json\n",
    "        \n",
    "    output : FiD input json format\n",
    "    \n",
    "    option(required) : removing strategies\n",
    "        op1 : removes damages only\n",
    "        op2 : removes damaging + irrelevant\n",
    "        op3 : removes damaging + relevant\n",
    "        op4 : removes damaging + irrelevant + relevant\n",
    "        \n",
    "    option_p(required) : positive passage selection options\n",
    "        strict : strict positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is relevant\n",
    "        naive : naive positive\n",
    "            e.g.) 11 pattern \n",
    "                1st '1' is positive, 2nd '1' is positive\n",
    "                \n",
    "    option_d(required) : damaging passage selection options\n",
    "        strict : strict negative\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is irrelevant\n",
    "        naive : naive damaging\n",
    "            e.g.) A00 pattern \n",
    "                if there is at least one '1' occurred in A, 2nd '0' is damaging\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    output_format = []\n",
    "    null_em = '0' * sample_size\n",
    "    \n",
    "    # 'strict', 'naive'  \n",
    "    # option_p = 'naive'\n",
    "    # option_d = 'naive'\n",
    "    # option = 'op4'\n",
    "\n",
    "    for id_, instance in enumerate(input_file,1):\n",
    "        template_dict = {}\n",
    "        if 'id' in instance.keys():\n",
    "            template_dict['id'] = instance['id']\n",
    "        else:\n",
    "            template_dict['id'] = str(id_)\n",
    "        template_dict['answers'] = instance['answers']\n",
    "        template_dict['question'] = instance['question']\n",
    "        template_dict['em_pattern'] = instance['em_pattern']\n",
    "\n",
    "        em_pattern = instance['em_pattern']\n",
    "\n",
    "        # when there is at least one EM in the accumulated inference\n",
    "        if em_pattern != null_em:   \n",
    "            new_ctx = []\n",
    "\n",
    "            # relevant vs positive\n",
    "            positve_ctx_lst = []\n",
    "            relevant_ctx_lst = []\n",
    "\n",
    "            # irrelevant vs damaging\n",
    "            damaging_ctx_lst = []\n",
    "            irrelevant_ctx_lst = []\n",
    "\n",
    "\n",
    "            for idx_, ctx in enumerate(instance['ctxs']):\n",
    "\n",
    "                # checking current em\n",
    "                cur_em = em_pattern[idx_]\n",
    "                pre_em_pattern = em_pattern[:idx_]\n",
    "\n",
    "\n",
    "                # first 1 : positive\n",
    "                if not pre_em_pattern and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # first 0 : irrelevant\n",
    "                elif not pre_em_pattern and cur_em == '0':\n",
    "                    irrelevant_ctx_lst.append(ctx)\n",
    "                    \n",
    "                # 01 pattern : positive \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '1':\n",
    "                    positve_ctx_lst.append(ctx)\n",
    "\n",
    "                # 10 pattern : damaging\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '0':\n",
    "                    damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                # 11 pattern : Strict Positive(relevant) or Naive Positive(positive)\n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '1' and cur_em == '1':\n",
    "                    if option_p == 'strict':\n",
    "                        relevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    elif option_p == 'naive':\n",
    "                        positve_ctx_lst.append(ctx)\n",
    "\n",
    "                    else:\n",
    "                        print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                        return \n",
    "\n",
    "                # 00 pattern : Strict Damaging(irrelevant) or Naive Damaging(damaging) \n",
    "                elif pre_em_pattern and pre_em_pattern[-1] == '0' and cur_em == '0':\n",
    "                    # if '1' does not occured in A, currnet passage is irrelevant\n",
    "                    if not '1' in pre_em_pattern:\n",
    "                        irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                    # if '1' occurred in A, \n",
    "                    else:\n",
    "                        # strict : consider it as irrelevnat \n",
    "                        if option_d == 'strict':\n",
    "                            irrelevant_ctx_lst.append(ctx)\n",
    "\n",
    "                        # naive : consider it as damaging \n",
    "                        elif option_d == 'naive':\n",
    "                            damaging_ctx_lst.append(ctx)\n",
    "\n",
    "                        else:\n",
    "                            print('option_p should be either \\'strict\\' or \\'naive\\'')\n",
    "                            return \n",
    "\n",
    "            # op1 removes damages only\n",
    "            if option == 'op1':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "\n",
    "            # op2 removes damaging + irrelevant\n",
    "            elif option == 'op2':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(relevant_ctx_lst)\n",
    "\n",
    "            # op3 : Removes damaging + relevant\n",
    "            elif option == 'op3':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "                new_ctx.extend(irrelevant_ctx_lst)\n",
    "\n",
    "            # op4 : Removes damaging + irrelevant + relevant\n",
    "            elif option == 'op4':\n",
    "                new_ctx.extend(positve_ctx_lst)\n",
    "\n",
    "            else:\n",
    "                print('option should be op1, op2, op3, op4')\n",
    "                return \n",
    "\n",
    "            template_dict['ctxs'] = new_ctx\n",
    "            output_format.append(template_dict)\n",
    "\n",
    "        # when there is no EM in the accumulated inference\n",
    "        else:\n",
    "            template_dict['ctxs']= instance['ctxs']\n",
    "            output_format.append(template_dict)\n",
    "    \n",
    "    print('==============instance finished======================')\n",
    "    return output_format\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9790bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option_dict = {\n",
    "#     'op1' : 'remove_damage',\n",
    "#     'op2' : 'remove_damage_irrelevant',\n",
    "#     'op3' : 'remove_damage_relevant',\n",
    "#     'op4' : 'remove_damage_irrelevant_relevant',\n",
    "# }\n",
    "# option = 'op4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op1, op2 are duplicates\n",
    "method_option_dict = {\n",
    "    'op3' : 'remove_damage_relevant',\n",
    "    'op4' : 'remove_damage_irrelevant_relevant',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_p_dict = {\n",
    "    'strict' : 'strict_positive',\n",
    "    'naive' : 'naive_positive',\n",
    "}\n",
    "# option_p = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_d_dict = {\n",
    "    'strict' : 'strict_damaging',\n",
    "    'naive' : 'naive_damaging',\n",
    "}\n",
    "# option_d = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = utils.open_json('/data/philhoon-relevance/FiD/results/KILT_BM25_NQ/incremental_result/pos1_ctx5.json')\n",
    "# output_path = '/data/philhoon-relevance/FiD/open_domain_data/NQ_KILT_BM25_SELECTION'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14baa2",
   "metadata": {},
   "source": [
    "## NQ TEST DPR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cb4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "input_file = f'/data/philhoon-relevance/FiD/results/NQ_DPR/TEST/incremental_result_{sample_size}/ctx{sample_size}.json'\n",
    "output_path = f'/data/philhoon-relevance/FiD/open_domain_data/NQ_TEST_DPR_SELECTION/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9746045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = utils.open_json(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45554375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/philhoon-relevance/FiD/open_domain_data/NQ_TEST_DPR_SELECTION/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a3c36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3610"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddebee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad569e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o_ in method_option_dict.keys():\n",
    "    for op in option_p_dict.keys():\n",
    "        for od in option_d_dict.keys():\n",
    "            option = o_\n",
    "            option_p = op\n",
    "            option_d = od\n",
    "            \n",
    "            if option == 'op4' and option_p == 'strict' and option_d == 'strict':\n",
    "                continue\n",
    "            if option == 'op4' and option_p == 'naive' and option_d == 'strict':\n",
    "                continue \n",
    "            \n",
    "            filename = f'{option_p_dict[option_p]}_{option_d_dict[option_d]}_{method_option_dict[option]}.json'\n",
    "\n",
    "            output_file = os.path.join(output_path, filename)\n",
    "            output_format = build_data(input_, option, option_p, option_d, sample_size)\n",
    "            \n",
    "            utils.save_json(output_format, output_file)\n",
    "            print(f'{filename} save on \\n {output_path}')\n",
    "#             print(f'option : {option}')\n",
    "#             print(f'option_p : {option_p}')\n",
    "#             print(f'option_d : {option_d}')\n",
    "#             print(f'filename : {filename}')\n",
    "#             print(f'output_file : {output_file}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d292b",
   "metadata": {},
   "source": [
    "# Method explanation\n",
    "- Redundancies in selection strategies -> remove them -> 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768e084",
   "metadata": {},
   "source": [
    "#### Method1. Include passages that corresponds to 1s\n",
    "- all __option2__ belong to this case\n",
    "- option4_naive_naive, option4_naive_strict\n",
    "\n",
    "'00011011000'  -> 000<span style=\"color:red\">1</span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span><span style=\"color:red\">1</span>000  \n",
    "- red 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffe64a",
   "metadata": {},
   "source": [
    "#### Method2. Include passages that corresponds to first 1s\n",
    "- option4_strict_naive, option4_strict_strcit \n",
    "\n",
    "'00011011000'  -> \n",
    "000<span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000  \n",
    "- red 1s\n",
    "- removing consecutive passages when the previous output is correct as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e48f2",
   "metadata": {},
   "source": [
    "#### Method3. Include passages that corresponds to 1s + Included First appeared consecutive 0s\n",
    "- option1_naive_naive, option1_strict_naive\n",
    "- option3_naive_naive\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>000  \n",
    "- red 1s and blue 0s\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80226855",
   "metadata": {},
   "source": [
    "#### Method4. Include passages that corresponds to first 1s + Included First appeared consecutive 0s\n",
    "- option3_strict_naive\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>1000  \n",
    "- red 1s and blue 0s\n",
    "- removing consecutive passages when the previous output is correct as well\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239a92",
   "metadata": {},
   "source": [
    "#### Method5. Include passages that corresponds to 1s + Remove only damaging\n",
    "- option1_naive_strict, option1_strict_strict\n",
    "- option3_naive_strict\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:red\">1</span></span><span style=\"color:red\">1</span>0<span style=\"color:blue\">0</span><span style=\"color:blue\"><span style=\"color:blue\">0</span><span style=\"color:blue\"> \n",
    "- red 1s and blue 0s\n",
    "- only removes damaging passages for comparison with Method3, Method4\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e22f7",
   "metadata": {},
   "source": [
    "#### Method6. Include passages that corresponds to first 1s  + Remove only damaging\n",
    "- option3_strict_strict\n",
    "\n",
    "'00011011000'  -> \n",
    "<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:blue\">0</span><span style=\"color:red\">1</span>10<span style=\"color:red\">1</span>10<span style=\"color:blue\">0</span><span style=\"color:blue\">0</span>\n",
    "- red 1s and blue 0s\n",
    "- removing consecutive passages when the previous output is correct as well\n",
    "- only removes damaging passages for comparison with Method3, Method4\n",
    "- usually top-retrieved results contain the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b546c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- option1, option2 are not needed\n",
    "- Method1 : option4_naive_naive\n",
    "- Method2 : option4_strict_naive \n",
    "- Method3 : option3_naive_naive\n",
    "- Method4 : option3_strict_naive\n",
    "- Method5 : option3_naive_strict\n",
    "- Method6 : option3_strict_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cad32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f004d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevance-kilt",
   "language": "python",
   "name": "relevance-kilt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
